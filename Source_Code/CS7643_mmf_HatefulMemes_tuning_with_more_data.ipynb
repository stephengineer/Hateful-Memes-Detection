{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tune mmf_hm_add_data2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwCc6zN1BkIE"
      },
      "source": [
        "# Setup Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUiCpSbDCxRE",
        "outputId": "deeafa71-88ba-4c8b-c700-e6dde2baf80a"
      },
      "source": [
        "# setup Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz9FOfH7GWgO"
      },
      "source": [
        "path = '/content/drive/MyDrive/School/CS7643/project'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7Eo9ZqTDW3I"
      },
      "source": [
        "## Download MMF\n",
        "\n",
        "In this section, we will download the MMF package and required dependencies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTvGiwu5aE91"
      },
      "source": [
        "### Prerequisites \n",
        "Please enable GPU in this notebook: Runtime > Change runtime type > Hardware Accelerator > Set to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxh_vli1Drky"
      },
      "source": [
        "First we will install the MMF package and required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JrgCvqorS2j8",
        "outputId": "36046bc4-fc86-4090-8a08-033ffb4babdb"
      },
      "source": [
        "# !pip install --pre --upgrade mmf\n",
        "\n",
        "# run the next two line when first time running the notebook\n",
        "# ! mkdir \"$path\"mmf\n",
        "# !git clone https://github.com/facebookresearch/mmf.git \"$path\"/mmf\n",
        "os.chdir(path + \"/mmf\")\n",
        "!pip install --editable ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/drive/MyDrive/School/CS7643/project/mmf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting demjson==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/67/6db789e2533158963d4af689f961b644ddd9200615b8ce92d6cad695c65a/demjson-2.2.4.tar.gz (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.19.5)\n",
            "Requirement already satisfied: editdistance==0.5.3 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.5.3)\n",
            "Requirement already satisfied: pycocotools==2.0.2 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.0.2)\n",
            "Collecting torchtext==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.7MB/s \n",
            "\u001b[?25hCollecting torchvision<=0.9.1,>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/8a/82062a33b5eb7f696bf23f8ccf04bf6fc81d1a4972740fb21c2569ada0a6/torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4MB 258kB/s \n",
            "\u001b[?25hCollecting torch<=1.8.1,>=1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/74/6fc9dee50f7c93d6b7d9644554bdc9692f3023fa5d1de779666e6bf8ae76/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1MB 22kB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn==0.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (0.0)\n",
            "Collecting omegaconf==2.0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/eb/9d63ce09dd8aa85767c65668d5414958ea29648a0eec80a4a7d311ec2684/omegaconf-2.0.6-py3-none-any.whl\n",
            "Collecting fasttext==0.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/61/2e01f1397ec533756c1d893c22d9d5ed3fce3a6e4af1976e0d86bb13ea97/fasttext-0.9.1.tar.gz (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/3d/db9a6b3c83c9511301152dbb64a029c3a4313c86eaef12c237b13ecf91d6/matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6MB 41.4MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning==1.2.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/13/fb401b8f9d9c5e2aa08769d230bb401bf11dee0bc93e069d7337a4201ec8/pytorch_lightning-1.2.7-py3-none-any.whl (830kB)\n",
            "\u001b[K     |████████████████████████████████| 839kB 35.6MB/s \n",
            "\u001b[?25hCollecting tqdm<4.50.0,>=4.43.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/d5/f220e0c69b2f346b5649b66abebb391df1a00a59997a7ccf823325bd7a3e/tqdm-4.49.0-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25hCollecting lmdb==0.98\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/5c/d56dbc2532ecf14fa004c543927500c0f645eaca8bd7ec39420c7546396a/lmdb-0.98.tar.gz (869kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 34.5MB/s \n",
            "\u001b[?25hCollecting iopath==0.1.7\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/d5/1c70fea7632640e8a9fb5a176676e555238119b3e7ee8b6dc49980ec5769/iopath-0.1.7-py3-none-any.whl\n",
            "Collecting transformers==3.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 30.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (1.1.0)\n",
            "Requirement already satisfied: requests==2.23.0 in /usr/local/lib/python3.7/dist-packages (from mmf==1.0.0rc12) (2.23.0)\n",
            "Collecting GitPython==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/2f/6a366d56c9b1355b0880be9ea66b166cb3536392638d8d91413ec66305ad/GitPython-3.1.0-py3-none-any.whl (450kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 41.0MB/s \n",
            "\u001b[?25hCollecting datasets==1.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/9b/d097f2238fc3c028495cf5f8c65378972b9f1b2cbb27f3c57c7219195aa9/datasets-1.2.1-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 43.5MB/s \n",
            "\u001b[?25hCollecting ftfy==5.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0.2->mmf==1.0.0rc12) (0.29.22)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0.2->mmf==1.0.0rc12) (56.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->mmf==1.0.0rc12) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 28.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision<=0.9.1,>=0.7.0->mmf==1.0.0rc12) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.8.1,>=1.6.0->mmf==1.0.0rc12) (3.7.4.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn==0.0->mmf==1.0.0rc12) (0.22.2.post1)\n",
            "Collecting PyYAML>=5.1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext==0.9.1->mmf==1.0.0rc12) (2.6.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.4->mmf==1.0.0rc12) (2.8.1)\n",
            "Collecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/91/2ef649137816850fa4f4c97c6f2eabb1a79bf0aa2c8ed198e387e373455e/fsspec-2021.4.0-py3-none-any.whl (108kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 52.1MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 46.4MB/s \n",
            "\u001b[?25hCollecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/99/dc59248df9a50349d537ffb3403c1bdc1fa69077109d46feaa0843488001/torchmetrics-0.3.1-py3-none-any.whl (271kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.2.7->mmf==1.0.0rc12) (2.4.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (20.9)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (3.12.4)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/e7/edf655ae34925aeaefb7b7fcc3dd0887d2a1203ee6b0df4d1170d1a19d4f/tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 42.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->mmf==1.0.0rc12) (3.0.12)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.23.0->mmf==1.0.0rc12) (3.0.4)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (0.3.3)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 35.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (0.70.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (1.1.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets==1.2.1->mmf==1.0.0rc12) (3.10.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy==5.8->mmf==1.0.0rc12) (0.2.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn==0.0->mmf==1.0.0rc12) (1.4.1)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 40.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.32.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.28.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.4.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.4.0->mmf==1.0.0rc12) (7.1.2)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.2.1->mmf==1.0.0rc12) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets==1.2.1->mmf==1.0.0rc12) (3.4.1)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 42.4MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 43.3MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (20.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning==1.2.7->mmf==1.0.0rc12) (3.1.0)\n",
            "Building wheels for collected packages: demjson, nltk, fasttext, lmdb, ftfy, future\n",
            "  Building wheel for demjson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for demjson: filename=demjson-2.2.4-cp37-none-any.whl size=73546 sha256=f20d1f45c65fd025ee6e2e1e78080216ce8630e88db6b02abfea9af88744db34\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/d2/ab/a54fb5ea53ac3badba098160e8452fa126a51febda80440ded\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449906 sha256=62035d037804d25418212a1f4ed9aedfee911a839ee7524f5c582d9d886c149b\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.1-cp37-cp37m-linux_x86_64.whl size=2462618 sha256=984448e1ec3bb559563ef5374e6daddcea7ff49544e7ff2df78ed19d83c07b0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f0/04/caa82c912aee89ce76358ff954f3f0729b7577c8ff23a292e3\n",
            "  Building wheel for lmdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lmdb: filename=lmdb-0.98-cp37-cp37m-linux_x86_64.whl size=219684 sha256=72d25f20c780e61ee7f2dde367da96e63ac8f2d38edf8eb729b33bbb08ac10cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/97/8c/7721e4b6b0ac723c6cc45ecca60599a80f75e2367330647390\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp37-none-any.whl size=45613 sha256=bc2b3cb42ff0b0ef4d6f48b7175f017b71a987ab0644c23edccebbe74165dec2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491058 sha256=3e7593ec0ea8adfb4fd634450253b5c4eee27a092848d9e6c5bf9578d213a98e\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built demjson nltk fasttext lmdb ftfy future\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytorch-lightning 1.2.7 has requirement PyYAML!=5.4.*,>=5.1, but you'll have pyyaml 5.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: demjson, torch, tqdm, sentencepiece, torchtext, torchvision, nltk, PyYAML, omegaconf, fasttext, matplotlib, multidict, yarl, async-timeout, aiohttp, fsspec, future, torchmetrics, pytorch-lightning, lmdb, portalocker, iopath, tokenizers, sacremoses, transformers, smmap, gitdb, GitPython, xxhash, datasets, ftfy, mmf\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: lmdb 0.99\n",
            "    Uninstalling lmdb-0.99:\n",
            "      Successfully uninstalled lmdb-0.99\n",
            "  Running setup.py develop for mmf\n",
            "Successfully installed GitPython-3.1.0 PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 datasets-1.2.1 demjson-2.2.4 fasttext-0.9.1 fsspec-2021.4.0 ftfy-5.8 future-0.18.2 gitdb-4.0.7 iopath-0.1.7 lmdb-0.98 matplotlib-3.3.4 mmf multidict-5.1.0 nltk-3.4.5 omegaconf-2.0.6 portalocker-2.3.0 pytorch-lightning-1.2.7 sacremoses-0.0.45 sentencepiece-0.1.95 smmap-4.0.0 tokenizers-0.9.2 torch-1.8.1 torchmetrics-0.3.1 torchtext-0.5.0 torchvision-0.9.1 tqdm-4.49.0 transformers-3.4.0 xxhash-2.0.2 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KgiwC7A3BwG",
        "outputId": "d84a8378-7017-4851-ce6c-3c428d0ff942"
      },
      "source": [
        "# run if run into PyYAML version error   \n",
        "!pip install PyYAML==5.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyYAML==5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 11.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 102kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 112kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 122kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 143kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 153kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 163kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 174kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 184kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 194kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 204kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 225kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 235kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 245kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 256kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 5.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: PyYAML\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyYAML: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44074 sha256=dfe20df6a8d637aeb718f8dbb40bf6653209833c8dba994a626f4bc0c118ef37\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n",
            "Successfully built PyYAML\n",
            "Installing collected packages: PyYAML\n",
            "  Found existing installation: PyYAML 5.4.1\n",
            "    Uninstalling PyYAML-5.4.1:\n",
            "      Successfully uninstalled PyYAML-5.4.1\n",
            "Successfully installed PyYAML-5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYyXt9dzEBEU"
      },
      "source": [
        "## Download dataset\n",
        "\n",
        "We will now download the Hateful Memes dataset. You will require two things to download the datasets: (i) URL (ii) Password to the zip file. To get both of these follow these steps:\n",
        "\n",
        "1. Go to [DrivenData challenge page](https://www.drivendata.org/competitions/64/hateful-memes/)\n",
        "2. Register, read and acknowledge the agreements for data access.\n",
        "3. Go to the [data page](https://www.drivendata.org/competitions/64/hateful-memes/data), right click on the \"Hateful Memes challenge dataset\" link and \"Copy Link Address\" as shown in the image. This will copy the URL for the zip file to your clipboard which you will use in the next step.\n",
        "![data](https://i.imgur.com/JQx2hPm.png)\n",
        "4. Also, note the password provided in the description.\n",
        "5. Run the next code block, fill in the URL and the zipfile's password when prompted.\n",
        "\n",
        "The code blocks after that will download, convert and visualize the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulosPHAE-eto"
      },
      "source": [
        "# from getpass import getpass, getuser\n",
        "# url = getpass(\"Enter the Hateful Memes data URL:\")\n",
        "# password = getpass(\"Enter ZIP file's Password:\")\n",
        "url = 'https://drivendata-competition-fb-hateful-memes-data.s3.amazonaws.com/XjiOc5ycDBRRNwbhRlgH.zip?AWSAccessKeyId=AKIARVBOBDCY4MWEDJKS&Signature=ey9vLRX9%2FMRFZRKyFOIlJiJtjmo%3D&Expires=1620143289'\n",
        "password = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiux2MWzFRPz"
      },
      "source": [
        "This will actually download the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2WeHHISHCpo",
        "outputId": "104e4ac9-b03e-463c-b328-ea6eff419c65"
      },
      "source": [
        "!curl -o \"$path\"/hateful-memes.zip \"$url\" -H 'Referer: https://www.drivendata.org/competitions/64/hateful-memes/data/' --compressed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 4029M  100 4029M    0     0  74.7M      0  0:00:53  0:00:53 --:--:-- 91.3M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPYBxsyRFUUb"
      },
      "source": [
        "The next command will convert the zip file into required MMF format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsMmmOB3_rdY",
        "outputId": "40dc68b6-73b0-4065-dc50-16643f1fe877"
      },
      "source": [
        "!mmf_convert_hm --zip_file \"$path\"/hateful-memes.zip --password $password --bypass_checksum 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-03 01:10:11.341263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Data folder is /root/.cache/torch/mmf/data\n",
            "Zip path is /content/drive/MyDrive/School/CS7643/project/hateful-memes.zip\n",
            "Copying /content/drive/MyDrive/School/CS7643/project/hateful-memes.zip\n",
            "Unzipping /content/drive/MyDrive/School/CS7643/project/hateful-memes.zip\n",
            "Extracting the zip can take time. Sit back and relax.\n",
            "Moving train.jsonl\n",
            "Moving dev_seen.jsonl\n",
            "Moving test_seen.jsonl\n",
            "Moving dev_unseen.jsonl\n",
            "Moving test_unseen.jsonl\n",
            "Moving img\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAd-MVddTud0",
        "outputId": "81502940-6ff7-45e8-c170-ac18f4cd053a"
      },
      "source": [
        "# Check how many images we have in total\n",
        "!ls /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4N_fMV1-Zgk"
      },
      "source": [
        "#!rm -rf /root/.cache/torch/mmf/data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-BovIPc85vR"
      },
      "source": [
        "# Free up the disk by removing .zip, .tar files\n",
        "# !rm -rf \"$path\"hateful-memes.zip\n",
        "# !rm -rf /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/hateful-memes.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ihtTpgVWhSa"
      },
      "source": [
        "## Download Kaggle Memotion dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GhgweNIW0VF"
      },
      "source": [
        "Check out the official documentation to get more information on Kaggle API and how to create a Kaggle API Key:\n",
        "- [Link#1](https://github.com/Kaggle/kaggle-api#api-credentials)\n",
        "- [Link#2](https://www.kaggle.com/docs/api)\n",
        "\n",
        "The API Key is stored in a file named `kaggle.jsonl`, which has the folowing line inside: \n",
        "`{\"username\":\"your_user_name\",\"key\":\"some_values_here\"}`\n",
        "\n",
        "> Upload the `kaggle.json` file to your `$path` directory and run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEngXAcDWoR_",
        "outputId": "4301e8b9-f838-402f-baed-264270483bfd"
      },
      "source": [
        "# # Install kaggle library\n",
        "# !pip install -q kaggle\n",
        "# # Create a directory where API key will be stored\n",
        "# !mkdir -p ~/.kaggle\n",
        "# # Move the API key to where Kaggle expects it to be\n",
        "# !mv \"$path\"/kaggle.json ~/.kaggle/\n",
        "# # Give according rights to the file\n",
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "# # Finally, download the dataset (.zip file)\n",
        "# !kaggle datasets download -d williamscott701/memotion-dataset-7k\n",
        "# # Unzip the data \n",
        "# !unzip -qq memotion-dataset-7k.zip -d \"$path\"/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat '/content/drive/MyDrive/School/CS7643/project/kaggle.json': No such file or directory\n",
            "Downloading memotion-dataset-7k.zip to /content/drive/MyDrive/School/CS7643/project\n",
            " 98% 681M/695M [00:06<00:00, 87.0MB/s]\n",
            "100% 695M/695M [00:06<00:00, 117MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sujl4iPRcXIt"
      },
      "source": [
        "## Label Kaggle Memotion dataset\n",
        "The following cell can be run to clone a repository which includes helpful scripts for the project such as; a script for labeling the Memotion Dataset and saving the data in the same format as the Hateful Memes Dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SWLfDix6WoWT"
      },
      "source": [
        "import os\n",
        "os.chdir(path)\n",
        "#!git clone https://github.com/rizavelioglu/hateful_memes-hate_detectron.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pcvA7ZJQirzs"
      },
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "# read the .jsonl file and get the img column\n",
        "labeled_memo_samples = pd.read_json(os.path.join(path, \"hateful_memes-hate_detectron/utils/label_memotion.jsonl\"), lines=True)['img']\n",
        "# parse the img entries and get the image names\n",
        "labeled_memo_samples = [i.split('/')[1] for i in list(labeled_memo_samples)]\n",
        "\n",
        "img_dir = os.path.join(path, f\"memotion_dataset_7k/images/\")\n",
        "for img in labeled_memo_samples:\n",
        "    shutil.copy(f\"{img_dir+img}\", f\"/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/{img}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ej98CYQalvyB",
        "outputId": "f5a1873a-b613-4416-fa5f-732ee2cb27bb"
      },
      "source": [
        "# Check how many images we have in total\n",
        "!ls /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6TlER1K7B2x"
      },
      "source": [
        "## Merging the two datasets to get a larger training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pC6yr7dvmDMR"
      },
      "source": [
        "!python \"$path\"/hateful_memes-hate_detectron/utils/concat_memotion-hm.py --home $path/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDDnTlQZV46f"
      },
      "source": [
        "## Train an existing model\n",
        "\n",
        "We will use MMF to train an existing baseline from MMF's model zoo on the Hateful Memes dataset. Run the next code cell to start training MMBT-Grid model on the dataset. You can adjust the batch size, maximum number of updates, log and evaluation interval among other things by using command line overrides. Read more about MMF's configuration system at https://mmf.readthedocs.io/en/latest/notes/configuration.html."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nwebqtdWOfZ"
      },
      "source": [
        "# !mmf_run config=projects/hateful_memes/configs/mmbt/defaults.yaml \\\n",
        "#   model=mmbt \\\n",
        "#   dataset=hateful_memes \\\n",
        "#   training.log_interval=50 \\\n",
        "#   training.max_updates=3000 \\\n",
        "#   training.batch_size=16 \\\n",
        "#   training.evaluation_interval=500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE5JjsZMyUbN",
        "outputId": "fd85dfa2-b763-41df-e78f-33528d6ecdbe"
      },
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
        "model=visual_bert \\\n",
        "dataset=hateful_memes \\\n",
        "training.batch_size=32 \\\n",
        "env.save_dir=\"$path\"/visual_bert_coco_more_data_tune1 \\\n",
        "training.tensorboard=True \\\n",
        "training.checkpoint_interval=50 \\\n",
        "training.evaluation_interval=50 \\\n",
        "training.max_updates=4000 \\\n",
        "training.log_interval=100 \\\n",
        "training.lr_ratio=0.6 \\\n",
        "training.use_warmup=True \\\n",
        "optimizer.params.lr=5.0e-05 \\\n",
        "evaluation.predict=true \\\n",
        "checkpoint.resume_zoo=visual_bert.pretrained.cc.full \\\n",
        "checkpoint.max_to_keep=1 \\\n",
        "scheduler.params.num_warmup_steps=500 \\\n",
        "scheduler.type=warmup_cosine \\\n",
        "scheduler.params.num_training_steps=5000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-25 19:46:10.750246: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/hateful_memes/configs/visual_bert/from_coco.yaml\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option training.batch_size to 32\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option env.save_dir to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune1\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option training.tensorboard to True\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option training.checkpoint_interval to 50\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option training.evaluation_interval to 50\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option training.max_updates to 4000\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option training.log_interval to 100\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option training.lr_ratio to 0.6\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option training.use_warmup to True\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option optimizer.params.lr to 5.0e-05\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_zoo to visual_bert.pretrained.cc.full\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.max_to_keep to 1\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option scheduler.params.num_warmup_steps to 500\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option scheduler.type to warmup_cosine\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.configuration: \u001b[0mOverriding option scheduler.params.num_training_steps to 5000\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf: \u001b[0mLogging to: /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune1/train.log\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/visual_bert/from_coco.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'training.batch_size=32', 'env.save_dir=/content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune1', 'training.tensorboard=True', 'training.checkpoint_interval=50', 'training.evaluation_interval=50', 'training.max_updates=4000', 'training.log_interval=100', 'training.lr_ratio=0.6', 'training.use_warmup=True', 'optimizer.params.lr=5.0e-05', 'evaluation.predict=true', 'checkpoint.resume_zoo=visual_bert.pretrained.cc.full', 'checkpoint.max_to_keep=1', 'scheduler.params.num_warmup_steps=500', 'scheduler.type=warmup_cosine', 'scheduler.params.num_training_steps=5000'])\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf_cli.run: \u001b[0mTorch version: 1.8.1+cu102\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla P100-PCIE-16GB\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf_cli.run: \u001b[0mUsing seed 49652155\n",
            "\u001b[32m2021-04-25T19:46:49 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz ]\n",
            "Downloading features.tar.gz: 100% 10.3G/10.3G [03:48<00:00, 45.1MB/s]\n",
            "[ Starting checksum for features.tar.gz]\n",
            "[ Checksum successful for features.tar.gz]\n",
            "Unpacking features.tar.gz\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:00<00:00, 605kB/s] \n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "\u001b[32m2021-04-25T19:55:29 | filelock: \u001b[0mLock 139643566144272 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "Downloading: 100% 433/433 [00:00<00:00, 442kB/s]\n",
            "\u001b[32m2021-04-25T19:55:29 | filelock: \u001b[0mLock 139643566144272 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "\u001b[32m2021-04-25T19:55:30 | filelock: \u001b[0mLock 139644381099600 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 950kB/s]\n",
            "\u001b[32m2021-04-25T19:55:30 | filelock: \u001b[0mLock 139644381099600 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "\u001b[32m2021-04-25T19:55:30 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-25T19:55:30 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-25T19:55:30 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-25T19:55:30 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "\u001b[32m2021-04-25T19:55:30 | filelock: \u001b[0mLock 139643559520784 acquired on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "Downloading: 100% 440M/440M [00:11<00:00, 39.5MB/s]\n",
            "\u001b[32m2021-04-25T19:55:42 | filelock: \u001b[0mLock 139643559520784 released on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2021-04-25T19:55:51 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2021-04-25T19:55:51 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-25T19:55:52 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-25T19:55:52 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[32m2021-04-25T19:55:52 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/models/visual_bert/visual_bert.pretrained.cc_full.tar.gz to /root/.cache/torch/mmf/data/models/visual_bert.pretrained.cc.full/visual_bert.pretrained.cc_full.tar.gz ]\n",
            "Downloading visual_bert.pretrained.cc_full.tar.gz: 100% 415M/415M [00:05<00:00, 72.0MB/s]\n",
            "[ Starting checksum for visual_bert.pretrained.cc_full.tar.gz]\n",
            "[ Checksum successful for visual_bert.pretrained.cc_full.tar.gz]\n",
            "Unpacking visual_bert.pretrained.cc_full.tar.gz\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-25T19:56:04 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-25T19:56:04 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-25T19:56:04 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-25T19:56:04 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.weight from model.bert.pooler.dense.weight\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.bias from model.bert.pooler.dense.bias\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mPretrained model loaded\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 0\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 0\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 0\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
            "  (model): VisualBERTForClassification(\n",
            "    (bert): VisualBERTBase(\n",
            "      (embeddings): BertVisioLinguisticEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (token_type_embeddings_visual): Embedding(2, 768)\n",
            "        (position_embeddings_visual): Embedding(512, 768)\n",
            "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
            "\u001b[32m2021-04-25T19:56:04 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2021-04-25T19:58:22 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T19:58:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:01:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:02:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:02:00 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:02:01 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:02:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:02:55 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:03:25 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:03:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:03:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/4000, val/hateful_memes/cross_entropy: 0.6592, val/total_loss: 0.6592, val/hateful_memes/accuracy: 0.6315, val/hateful_memes/binary_f1: 0.0100, val/hateful_memes/roc_auc: 0.5588, num_updates: 50, epoch: 1, iterations: 50, max_updates: 4000, val_time: 01m 43s 415ms, best_update: 50, best_iteration: 50, best_val/hateful_memes/roc_auc: 0.558779\n",
            "\u001b[32m2021-04-25T20:05:41 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:05:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:06:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:06:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:06:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/4000, train/hateful_memes/cross_entropy: 0.7006, train/hateful_memes/cross_entropy/avg: 0.7006, train/total_loss: 0.7006, train/total_loss/avg: 0.7006, max mem: 9224.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 4000, lr: 0.00001, ups: 0.70, time: 02m 22s 030ms, time_since_start: 10m 13s 374ms, eta: 02h 03m 42s 500ms\n",
            "\u001b[32m2021-04-25T20:06:05 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:06:05 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:06:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:06:44 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:06:58 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:07:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:07:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/4000, val/hateful_memes/cross_entropy: 0.6728, val/total_loss: 0.6728, val/hateful_memes/accuracy: 0.6333, val/hateful_memes/binary_f1: 0.0833, val/hateful_memes/roc_auc: 0.5810, num_updates: 100, epoch: 1, iterations: 100, max_updates: 4000, val_time: 01m 08s 142ms, best_update: 100, best_iteration: 100, best_val/hateful_memes/roc_auc: 0.581044\n",
            "\u001b[32m2021-04-25T20:09:13 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:09:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:09:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:09:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:09:30 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:09:30 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:10:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:10:14 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:10:25 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:10:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:10:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/4000, val/hateful_memes/cross_entropy: 0.6797, val/total_loss: 0.6797, val/hateful_memes/accuracy: 0.6148, val/hateful_memes/binary_f1: 0.2353, val/hateful_memes/roc_auc: 0.6061, num_updates: 150, epoch: 1, iterations: 150, max_updates: 4000, val_time: 01m 11s 219ms, best_update: 150, best_iteration: 150, best_val/hateful_memes/roc_auc: 0.606132\n",
            "\u001b[32m2021-04-25T20:12:38 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:12:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:12:59 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:13:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:13:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/4000, train/hateful_memes/cross_entropy: 0.4897, train/hateful_memes/cross_entropy/avg: 0.5952, train/total_loss: 0.4897, train/total_loss/avg: 0.5952, max mem: 9224.0, experiment: run, epoch: 1, num_updates: 200, iterations: 200, max_updates: 4000, lr: 0.00002, ups: 0.69, time: 02m 25s 563ms, time_since_start: 17m 14s 751ms, eta: 02h 03m 32s 105ms\n",
            "\u001b[32m2021-04-25T20:13:06 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:13:06 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:13:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:13:50 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:14:01 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:14:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:14:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/4000, val/hateful_memes/cross_entropy: 0.6733, val/total_loss: 0.6733, val/hateful_memes/accuracy: 0.6315, val/hateful_memes/binary_f1: 0.1233, val/hateful_memes/roc_auc: 0.6160, num_updates: 200, epoch: 1, iterations: 200, max_updates: 4000, val_time: 01m 11s 010ms, best_update: 200, best_iteration: 200, best_val/hateful_memes/roc_auc: 0.616029\n",
            "\u001b[32m2021-04-25T20:16:19 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:16:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:16:26 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:16:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:16:37 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:16:37 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:17:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:17:19 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:17:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:17:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:17:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/4000, val/hateful_memes/cross_entropy: 0.6684, val/total_loss: 0.6684, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.3976, val/hateful_memes/roc_auc: 0.6302, num_updates: 250, epoch: 1, iterations: 250, max_updates: 4000, val_time: 01m 09s 424ms, best_update: 250, best_iteration: 250, best_val/hateful_memes/roc_auc: 0.630176\n",
            "\u001b[32m2021-04-25T20:19:25 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:19:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:19:41 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:19:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:19:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/4000, train/hateful_memes/cross_entropy: 0.4897, train/hateful_memes/cross_entropy/avg: 0.5173, train/total_loss: 0.4897, train/total_loss/avg: 0.5173, max mem: 9224.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 4000, lr: 0.00003, ups: 0.81, time: 02m 03s 044ms, time_since_start: 23m 57s 297ms, eta: 01h 41m 40s 532ms\n",
            "\u001b[32m2021-04-25T20:19:49 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:19:49 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:20:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:20:31 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:20:44 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:20:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:20:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/4000, val/hateful_memes/cross_entropy: 0.9493, val/total_loss: 0.9493, val/hateful_memes/accuracy: 0.6370, val/hateful_memes/binary_f1: 0.1901, val/hateful_memes/roc_auc: 0.6348, num_updates: 300, epoch: 2, iterations: 300, max_updates: 4000, val_time: 01m 08s 134ms, best_update: 300, best_iteration: 300, best_val/hateful_memes/roc_auc: 0.634838\n",
            "\u001b[32m2021-04-25T20:22:54 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:22:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:23:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:23:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:23:09 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:23:09 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:23:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:23:53 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:24:05 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:24:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:24:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/4000, val/hateful_memes/cross_entropy: 0.7104, val/total_loss: 0.7104, val/hateful_memes/accuracy: 0.6407, val/hateful_memes/binary_f1: 0.2868, val/hateful_memes/roc_auc: 0.6536, num_updates: 350, epoch: 2, iterations: 350, max_updates: 4000, val_time: 01m 11s 640ms, best_update: 350, best_iteration: 350, best_val/hateful_memes/roc_auc: 0.653618\n",
            "\u001b[32m2021-04-25T20:26:17 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:26:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:26:35 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:26:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:26:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/4000, train/hateful_memes/cross_entropy: 0.4093, train/hateful_memes/cross_entropy/avg: 0.4903, train/total_loss: 0.4093, train/total_loss/avg: 0.4903, max mem: 9224.0, experiment: run, epoch: 2, num_updates: 400, iterations: 400, max_updates: 4000, lr: 0.00004, ups: 0.70, time: 02m 22s 076ms, time_since_start: 30m 51s 055ms, eta: 01h 54m 13s 787ms\n",
            "\u001b[32m2021-04-25T20:26:43 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:26:43 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:27:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:27:24 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:27:36 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:27:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:27:56 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/4000, val/hateful_memes/cross_entropy: 0.6517, val/total_loss: 0.6517, val/hateful_memes/accuracy: 0.6556, val/hateful_memes/binary_f1: 0.3586, val/hateful_memes/roc_auc: 0.6990, num_updates: 400, epoch: 2, iterations: 400, max_updates: 4000, val_time: 01m 13s 388ms, best_update: 400, best_iteration: 400, best_val/hateful_memes/roc_auc: 0.698985\n",
            "\u001b[32m2021-04-25T20:29:48 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:29:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:29:54 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:30:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:30:04 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:30:04 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:30:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:30:51 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:31:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:31:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/4000, val/hateful_memes/cross_entropy: 0.8025, val/total_loss: 0.8025, val/hateful_memes/accuracy: 0.6574, val/hateful_memes/binary_f1: 0.2802, val/hateful_memes/roc_auc: 0.6959, num_updates: 450, epoch: 2, iterations: 450, max_updates: 4000, val_time: 01m 798ms, best_update: 400, best_iteration: 400, best_val/hateful_memes/roc_auc: 0.698985\n",
            "\u001b[32m2021-04-25T20:32:57 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:32:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:33:16 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:33:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:33:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/4000, train/hateful_memes/cross_entropy: 0.4093, train/hateful_memes/cross_entropy/avg: 0.4684, train/total_loss: 0.4093, train/total_loss/avg: 0.4684, max mem: 9224.0, experiment: run, epoch: 2, num_updates: 500, iterations: 500, max_updates: 4000, lr: 0.00005, ups: 0.74, time: 02m 16s 013ms, time_since_start: 37m 29s 378ms, eta: 01h 46m 19s 012ms\n",
            "\u001b[32m2021-04-25T20:33:21 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:33:21 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:33:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:33:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:34:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:34:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/4000, val/hateful_memes/cross_entropy: 0.6522, val/total_loss: 0.6522, val/hateful_memes/accuracy: 0.6537, val/hateful_memes/binary_f1: 0.3574, val/hateful_memes/roc_auc: 0.6842, num_updates: 500, epoch: 2, iterations: 500, max_updates: 4000, val_time: 44s 999ms, best_update: 400, best_iteration: 400, best_val/hateful_memes/roc_auc: 0.698985\n",
            "\u001b[32m2021-04-25T20:35:45 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:35:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:35:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:36:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:36:02 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:36:02 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:36:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:36:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:36:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:36:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/4000, val/hateful_memes/cross_entropy: 1.0582, val/total_loss: 1.0582, val/hateful_memes/accuracy: 0.6704, val/hateful_memes/binary_f1: 0.2880, val/hateful_memes/roc_auc: 0.6860, num_updates: 550, epoch: 3, iterations: 550, max_updates: 4000, val_time: 36s 102ms, best_update: 400, best_iteration: 400, best_val/hateful_memes/roc_auc: 0.698985\n",
            "\u001b[32m2021-04-25T20:38:26 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:38:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:38:39 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:38:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:38:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/4000, train/hateful_memes/cross_entropy: 0.3942, train/hateful_memes/cross_entropy/avg: 0.4560, train/total_loss: 0.3942, train/total_loss/avg: 0.4560, max mem: 9224.0, experiment: run, epoch: 3, num_updates: 600, iterations: 600, max_updates: 4000, lr: 0.00005, ups: 0.79, time: 02m 07s 018ms, time_since_start: 42m 53s 072ms, eta: 01h 36m 26s 976ms\n",
            "\u001b[32m2021-04-25T20:38:45 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:38:45 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:38:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:39:01 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:39:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:39:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/4000, val/hateful_memes/cross_entropy: 0.7813, val/total_loss: 0.7813, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.4437, val/hateful_memes/roc_auc: 0.6877, num_updates: 600, epoch: 3, iterations: 600, max_updates: 4000, val_time: 33s 782ms, best_update: 400, best_iteration: 400, best_val/hateful_memes/roc_auc: 0.698985\n",
            "\u001b[32m2021-04-25T20:41:08 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:41:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:41:24 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:41:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:41:31 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:41:31 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:41:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:41:50 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:42:05 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:42:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:42:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/4000, val/hateful_memes/cross_entropy: 0.7064, val/total_loss: 0.7064, val/hateful_memes/accuracy: 0.6926, val/hateful_memes/binary_f1: 0.4679, val/hateful_memes/roc_auc: 0.7142, num_updates: 650, epoch: 3, iterations: 650, max_updates: 4000, val_time: 54s 337ms, best_update: 650, best_iteration: 650, best_val/hateful_memes/roc_auc: 0.714176\n",
            "\u001b[32m2021-04-25T20:44:09 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:44:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:44:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:44:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:44:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/4000, train/hateful_memes/cross_entropy: 0.3942, train/hateful_memes/cross_entropy/avg: 0.4342, train/total_loss: 0.3942, train/total_loss/avg: 0.4342, max mem: 9224.0, experiment: run, epoch: 3, num_updates: 700, iterations: 700, max_updates: 4000, lr: 0.00005, ups: 0.79, time: 02m 07s 601ms, time_since_start: 48m 41s 689ms, eta: 01h 34m 02s 549ms\n",
            "\u001b[32m2021-04-25T20:44:33 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:44:33 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:44:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:44:44 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:45:05 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:45:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:45:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/4000, val/hateful_memes/cross_entropy: 0.6623, val/total_loss: 0.6623, val/hateful_memes/accuracy: 0.7056, val/hateful_memes/binary_f1: 0.5444, val/hateful_memes/roc_auc: 0.7188, num_updates: 700, epoch: 3, iterations: 700, max_updates: 4000, val_time: 44s 563ms, best_update: 700, best_iteration: 700, best_val/hateful_memes/roc_auc: 0.718838\n",
            "\u001b[32m2021-04-25T20:47:06 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:47:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:47:11 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:47:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:47:21 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:47:21 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:47:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:47:38 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:47:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:48:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:48:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/4000, val/hateful_memes/cross_entropy: 0.6561, val/total_loss: 0.6561, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.3944, val/hateful_memes/roc_auc: 0.7254, num_updates: 750, epoch: 3, iterations: 750, max_updates: 4000, val_time: 51s 892ms, best_update: 750, best_iteration: 750, best_val/hateful_memes/roc_auc: 0.725368\n",
            "\u001b[32m2021-04-25T20:50:02 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:50:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:50:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:50:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:50:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/4000, train/hateful_memes/cross_entropy: 0.3808, train/hateful_memes/cross_entropy/avg: 0.3921, train/total_loss: 0.3808, train/total_loss/avg: 0.3921, max mem: 9224.0, experiment: run, epoch: 4, num_updates: 800, iterations: 800, max_updates: 4000, lr: 0.00005, ups: 0.78, time: 02m 09s 010ms, time_since_start: 54m 30s 516ms, eta: 01h 32m 11s 978ms\n",
            "\u001b[32m2021-04-25T20:50:22 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:50:22 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:50:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:50:40 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:50:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:50:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/4000, val/hateful_memes/cross_entropy: 0.8553, val/total_loss: 0.8553, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4070, val/hateful_memes/roc_auc: 0.7151, num_updates: 800, epoch: 4, iterations: 800, max_updates: 4000, val_time: 34s 925ms, best_update: 750, best_iteration: 750, best_val/hateful_memes/roc_auc: 0.725368\n",
            "\u001b[32m2021-04-25T20:52:19 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:52:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:52:25 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:52:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:52:38 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:52:38 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:52:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:52:52 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:53:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:53:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:53:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/4000, val/hateful_memes/cross_entropy: 0.8274, val/total_loss: 0.8274, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.5179, val/hateful_memes/roc_auc: 0.7308, num_updates: 850, epoch: 4, iterations: 850, max_updates: 4000, val_time: 52s 468ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.730809\n",
            "\u001b[32m2021-04-25T20:55:12 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:55:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:55:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:55:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:55:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/4000, train/hateful_memes/cross_entropy: 0.3942, train/hateful_memes/cross_entropy/avg: 0.3936, train/total_loss: 0.3942, train/total_loss/avg: 0.3936, max mem: 9224.0, experiment: run, epoch: 4, num_updates: 900, iterations: 900, max_updates: 4000, lr: 0.00005, ups: 0.79, time: 02m 06s 812ms, time_since_start: 59m 45s 821ms, eta: 01h 27m 47s 772ms\n",
            "\u001b[32m2021-04-25T20:55:38 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:55:38 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:55:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:55:52 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:56:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:56:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/4000, val/hateful_memes/cross_entropy: 1.1997, val/total_loss: 1.1997, val/hateful_memes/accuracy: 0.7130, val/hateful_memes/binary_f1: 0.4404, val/hateful_memes/roc_auc: 0.7179, num_updates: 900, epoch: 4, iterations: 900, max_updates: 4000, val_time: 34s 277ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.730809\n",
            "\u001b[32m2021-04-25T20:57:50 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T20:57:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:58:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:58:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:58:15 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T20:58:15 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T20:58:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T20:58:32 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T20:58:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T20:59:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T20:59:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/4000, val/hateful_memes/cross_entropy: 0.9131, val/total_loss: 0.9131, val/hateful_memes/accuracy: 0.6963, val/hateful_memes/binary_f1: 0.5287, val/hateful_memes/roc_auc: 0.7409, num_updates: 950, epoch: 4, iterations: 950, max_updates: 4000, val_time: 46s 820ms, best_update: 950, best_iteration: 950, best_val/hateful_memes/roc_auc: 0.740868\n",
            "\u001b[32m2021-04-25T21:00:49 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:00:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:00:55 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:01:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:01:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/4000, train/hateful_memes/cross_entropy: 0.3808, train/hateful_memes/cross_entropy/avg: 0.3692, train/total_loss: 0.3808, train/total_loss/avg: 0.3692, max mem: 9224.0, experiment: run, epoch: 4, num_updates: 1000, iterations: 1000, max_updates: 4000, lr: 0.00005, ups: 0.81, time: 02m 03s 865ms, time_since_start: 01h 05m 14s 342ms, eta: 01h 22m 59s 377ms\n",
            "\u001b[32m2021-04-25T21:01:06 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:01:06 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:01:11 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:01:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:01:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:01:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/4000, val/hateful_memes/cross_entropy: 0.9180, val/total_loss: 0.9180, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.4255, val/hateful_memes/roc_auc: 0.7304, num_updates: 1000, epoch: 4, iterations: 1000, max_updates: 4000, val_time: 33s 719ms, best_update: 950, best_iteration: 950, best_val/hateful_memes/roc_auc: 0.740868\n",
            "\u001b[32m2021-04-25T21:03:24 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:03:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:03:39 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:03:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:03:46 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:03:46 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:03:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:04:01 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:04:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:04:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/4000, val/hateful_memes/cross_entropy: 1.1993, val/total_loss: 1.1993, val/hateful_memes/accuracy: 0.7167, val/hateful_memes/binary_f1: 0.4778, val/hateful_memes/roc_auc: 0.7114, num_updates: 1050, epoch: 4, iterations: 1050, max_updates: 4000, val_time: 31s 726ms, best_update: 950, best_iteration: 950, best_val/hateful_memes/roc_auc: 0.740868\n",
            "\u001b[32m2021-04-25T21:05:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:05:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:05:41 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:05:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:05:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/4000, train/hateful_memes/cross_entropy: 0.3808, train/hateful_memes/cross_entropy/avg: 0.3478, train/total_loss: 0.3808, train/total_loss/avg: 0.3478, max mem: 9224.0, experiment: run, epoch: 5, num_updates: 1100, iterations: 1100, max_updates: 4000, lr: 0.00005, ups: 1.10, time: 01m 31s 506ms, time_since_start: 01h 09m 57s 095ms, eta: 59m 15s 941ms\n",
            "\u001b[32m2021-04-25T21:05:49 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:05:49 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:05:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:06:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:06:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:06:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/4000, val/hateful_memes/cross_entropy: 1.1210, val/total_loss: 1.1210, val/hateful_memes/accuracy: 0.6981, val/hateful_memes/binary_f1: 0.4725, val/hateful_memes/roc_auc: 0.7222, num_updates: 1100, epoch: 5, iterations: 1100, max_updates: 4000, val_time: 34s 661ms, best_update: 950, best_iteration: 950, best_val/hateful_memes/roc_auc: 0.740868\n",
            "\u001b[32m2021-04-25T21:07:55 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:07:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:08:12 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:08:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:08:17 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:08:17 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:08:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:08:37 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:08:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:08:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/4000, val/hateful_memes/cross_entropy: 1.1419, val/total_loss: 1.1419, val/hateful_memes/accuracy: 0.7074, val/hateful_memes/binary_f1: 0.5000, val/hateful_memes/roc_auc: 0.7198, num_updates: 1150, epoch: 5, iterations: 1150, max_updates: 4000, val_time: 33s 203ms, best_update: 950, best_iteration: 950, best_val/hateful_memes/roc_auc: 0.740868\n",
            "\u001b[32m2021-04-25T21:10:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:10:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:10:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:11:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:11:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/4000, train/hateful_memes/cross_entropy: 0.3615, train/hateful_memes/cross_entropy/avg: 0.3262, train/total_loss: 0.3615, train/total_loss/avg: 0.3262, max mem: 9224.0, experiment: run, epoch: 5, num_updates: 1200, iterations: 1200, max_updates: 4000, lr: 0.00005, ups: 0.77, time: 02m 10s 179ms, time_since_start: 01h 15m 09s 047ms, eta: 01h 21m 24s 337ms\n",
            "\u001b[32m2021-04-25T21:11:01 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:11:01 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:11:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:11:12 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:11:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:11:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/4000, val/hateful_memes/cross_entropy: 1.2270, val/total_loss: 1.2270, val/hateful_memes/accuracy: 0.7093, val/hateful_memes/binary_f1: 0.5476, val/hateful_memes/roc_auc: 0.7187, num_updates: 1200, epoch: 5, iterations: 1200, max_updates: 4000, val_time: 31s 758ms, best_update: 950, best_iteration: 950, best_val/hateful_memes/roc_auc: 0.740868\n",
            "\u001b[32m2021-04-25T21:13:19 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:13:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:13:39 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:13:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:13:51 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:13:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:13:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:14:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:14:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:14:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/4000, val/hateful_memes/cross_entropy: 1.3111, val/total_loss: 1.3111, val/hateful_memes/accuracy: 0.7148, val/hateful_memes/binary_f1: 0.4539, val/hateful_memes/roc_auc: 0.7202, num_updates: 1250, epoch: 5, iterations: 1250, max_updates: 4000, val_time: 29s 137ms, best_update: 950, best_iteration: 950, best_val/hateful_memes/roc_auc: 0.740868\n",
            "\u001b[32m2021-04-25T21:16:12 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:16:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:16:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:16:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:16:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/4000, train/hateful_memes/cross_entropy: 0.3615, train/hateful_memes/cross_entropy/avg: 0.3164, train/total_loss: 0.3615, train/total_loss/avg: 0.3164, max mem: 9224.0, experiment: run, epoch: 5, num_updates: 1300, iterations: 1300, max_updates: 4000, lr: 0.00005, ups: 0.71, time: 02m 21s 038ms, time_since_start: 01h 20m 49s 042ms, eta: 01h 25m 02s 765ms\n",
            "\u001b[32m2021-04-25T21:16:41 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:16:41 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:16:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:16:58 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-25T21:17:11 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:17:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:17:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/4000, val/hateful_memes/cross_entropy: 1.0213, val/total_loss: 1.0213, val/hateful_memes/accuracy: 0.7130, val/hateful_memes/binary_f1: 0.4884, val/hateful_memes/roc_auc: 0.7499, num_updates: 1300, epoch: 5, iterations: 1300, max_updates: 4000, val_time: 51s 311ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:19:06 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:19:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:19:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:19:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:19:28 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:19:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:19:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:19:41 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:20:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:20:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/4000, val/hateful_memes/cross_entropy: 1.5468, val/total_loss: 1.5468, val/hateful_memes/accuracy: 0.7019, val/hateful_memes/binary_f1: 0.4311, val/hateful_memes/roc_auc: 0.7332, num_updates: 1350, epoch: 6, iterations: 1350, max_updates: 4000, val_time: 33s 190ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:21:30 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:21:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:21:42 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:21:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:21:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/4000, train/hateful_memes/cross_entropy: 0.3035, train/hateful_memes/cross_entropy/avg: 0.2957, train/total_loss: 0.3035, train/total_loss/avg: 0.2957, max mem: 9224.0, experiment: run, epoch: 6, num_updates: 1400, iterations: 1400, max_updates: 4000, lr: 0.00005, ups: 0.93, time: 01m 48s 350ms, time_since_start: 01h 25m 57s 720ms, eta: 01h 02m 54s 936ms\n",
            "\u001b[32m2021-04-25T21:21:49 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:21:49 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:21:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:22:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:22:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:22:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/4000, val/hateful_memes/cross_entropy: 1.3909, val/total_loss: 1.3909, val/hateful_memes/accuracy: 0.7130, val/hateful_memes/binary_f1: 0.4710, val/hateful_memes/roc_auc: 0.7352, num_updates: 1400, epoch: 6, iterations: 1400, max_updates: 4000, val_time: 31s 336ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:24:02 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:24:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:24:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:24:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:24:24 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:24:24 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:24:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:24:42 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:24:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:24:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/4000, val/hateful_memes/cross_entropy: 1.0618, val/total_loss: 1.0618, val/hateful_memes/accuracy: 0.7222, val/hateful_memes/binary_f1: 0.5342, val/hateful_memes/roc_auc: 0.7411, num_updates: 1450, epoch: 6, iterations: 1450, max_updates: 4000, val_time: 34s 314ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:26:44 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:26:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:27:01 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:27:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:27:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/4000, train/hateful_memes/cross_entropy: 0.3035, train/hateful_memes/cross_entropy/avg: 0.2782, train/total_loss: 0.3035, train/total_loss/avg: 0.2782, max mem: 9224.0, experiment: run, epoch: 6, num_updates: 1500, iterations: 1500, max_updates: 4000, lr: 0.00004, ups: 0.74, time: 02m 15s 131ms, time_since_start: 01h 31m 21s 645ms, eta: 01h 15m 26s 891ms\n",
            "\u001b[32m2021-04-25T21:27:13 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:27:13 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:27:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:27:29 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:27:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:27:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/4000, val/hateful_memes/cross_entropy: 1.4713, val/total_loss: 1.4713, val/hateful_memes/accuracy: 0.7056, val/hateful_memes/binary_f1: 0.4854, val/hateful_memes/roc_auc: 0.7261, num_updates: 1500, epoch: 6, iterations: 1500, max_updates: 4000, val_time: 30s 623ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:29:37 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:29:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:29:55 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:30:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:30:09 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:30:09 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:30:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:30:23 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:30:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:30:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/4000, val/hateful_memes/cross_entropy: 1.1676, val/total_loss: 1.1676, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.5172, val/hateful_memes/roc_auc: 0.7148, num_updates: 1550, epoch: 6, iterations: 1550, max_updates: 4000, val_time: 32s 560ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:32:26 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:32:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:32:40 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:32:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:32:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/4000, train/hateful_memes/cross_entropy: 0.1979, train/hateful_memes/cross_entropy/avg: 0.2656, train/total_loss: 0.1979, train/total_loss/avg: 0.2656, max mem: 9224.0, experiment: run, epoch: 7, num_updates: 1600, iterations: 1600, max_updates: 4000, lr: 0.00004, ups: 0.78, time: 02m 09s 171ms, time_since_start: 01h 36m 59s 333ms, eta: 01h 09m 14s 154ms\n",
            "\u001b[32m2021-04-25T21:32:51 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:32:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:32:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:33:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:33:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:33:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/4000, val/hateful_memes/cross_entropy: 1.1442, val/total_loss: 1.1442, val/hateful_memes/accuracy: 0.7056, val/hateful_memes/binary_f1: 0.5077, val/hateful_memes/roc_auc: 0.7122, num_updates: 1600, epoch: 7, iterations: 1600, max_updates: 4000, val_time: 31s 618ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:34:55 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:34:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:35:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:35:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:35:14 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:35:14 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:35:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:35:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:35:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:35:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/4000, val/hateful_memes/cross_entropy: 1.4587, val/total_loss: 1.4587, val/hateful_memes/accuracy: 0.7111, val/hateful_memes/binary_f1: 0.5215, val/hateful_memes/roc_auc: 0.7190, num_updates: 1650, epoch: 7, iterations: 1650, max_updates: 4000, val_time: 32s 770ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:37:26 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:37:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:37:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:37:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:37:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/4000, train/hateful_memes/cross_entropy: 0.1979, train/hateful_memes/cross_entropy/avg: 0.2581, train/total_loss: 0.1979, train/total_loss/avg: 0.2581, max mem: 9224.0, experiment: run, epoch: 7, num_updates: 1700, iterations: 1700, max_updates: 4000, lr: 0.00004, ups: 0.80, time: 02m 05s 265ms, time_since_start: 01h 42m 617ms, eta: 01h 04m 20s 683ms\n",
            "\u001b[32m2021-04-25T21:37:52 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:37:52 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:38:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:38:11 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:38:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:38:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/4000, val/hateful_memes/cross_entropy: 1.4898, val/total_loss: 1.4898, val/hateful_memes/accuracy: 0.7093, val/hateful_memes/binary_f1: 0.4952, val/hateful_memes/roc_auc: 0.7197, num_updates: 1700, epoch: 7, iterations: 1700, max_updates: 4000, val_time: 33s 267ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:40:14 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:40:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:40:32 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:40:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:40:40 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:40:40 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:40:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:41:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:41:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:41:15 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/4000, val/hateful_memes/cross_entropy: 1.1007, val/total_loss: 1.1007, val/hateful_memes/accuracy: 0.7204, val/hateful_memes/binary_f1: 0.5746, val/hateful_memes/roc_auc: 0.7403, num_updates: 1750, epoch: 7, iterations: 1750, max_updates: 4000, val_time: 34s 782ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:43:12 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:43:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:43:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:43:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:43:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/4000, train/hateful_memes/cross_entropy: 0.1500, train/hateful_memes/cross_entropy/avg: 0.2464, train/total_loss: 0.1500, train/total_loss/avg: 0.2464, max mem: 9224.0, experiment: run, epoch: 7, num_updates: 1800, iterations: 1800, max_updates: 4000, lr: 0.00004, ups: 0.71, time: 02m 21s 419ms, time_since_start: 01h 47m 44s 372ms, eta: 01h 09m 29s 037ms\n",
            "\u001b[32m2021-04-25T21:43:36 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:43:36 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:43:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:43:57 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:44:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:44:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/4000, val/hateful_memes/cross_entropy: 1.3244, val/total_loss: 1.3244, val/hateful_memes/accuracy: 0.7093, val/hateful_memes/binary_f1: 0.5169, val/hateful_memes/roc_auc: 0.7144, num_updates: 1800, epoch: 7, iterations: 1800, max_updates: 4000, val_time: 34s 042ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:46:01 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:46:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:46:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:46:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:46:32 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:46:32 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:46:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:46:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:47:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:47:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/4000, val/hateful_memes/cross_entropy: 1.1172, val/total_loss: 1.1172, val/hateful_memes/accuracy: 0.7148, val/hateful_memes/binary_f1: 0.5549, val/hateful_memes/roc_auc: 0.7351, num_updates: 1850, epoch: 7, iterations: 1850, max_updates: 4000, val_time: 31s 393ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:48:27 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:48:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:48:36 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:48:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:48:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/4000, train/hateful_memes/cross_entropy: 0.1500, train/hateful_memes/cross_entropy/avg: 0.2341, train/total_loss: 0.1500, train/total_loss/avg: 0.2341, max mem: 9224.0, experiment: run, epoch: 8, num_updates: 1900, iterations: 1900, max_updates: 4000, lr: 0.00004, ups: 1.02, time: 01m 38s 684ms, time_since_start: 01h 52m 49s 923ms, eta: 46m 16s 972ms\n",
            "\u001b[32m2021-04-25T21:48:42 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:48:42 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:48:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:49:04 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:49:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:49:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/4000, val/hateful_memes/cross_entropy: 1.6744, val/total_loss: 1.6744, val/hateful_memes/accuracy: 0.7185, val/hateful_memes/binary_f1: 0.5065, val/hateful_memes/roc_auc: 0.7293, num_updates: 1900, epoch: 8, iterations: 1900, max_updates: 4000, val_time: 36s 118ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:51:02 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:51:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:51:16 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:51:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:51:27 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:51:27 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:51:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:51:45 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:52:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:52:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/4000, val/hateful_memes/cross_entropy: 1.2620, val/total_loss: 1.2620, val/hateful_memes/accuracy: 0.7259, val/hateful_memes/binary_f1: 0.5595, val/hateful_memes/roc_auc: 0.7343, num_updates: 1950, epoch: 8, iterations: 1950, max_updates: 4000, val_time: 32s 521ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:53:47 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:53:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:54:04 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:54:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:54:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/4000, train/hateful_memes/cross_entropy: 0.1372, train/hateful_memes/cross_entropy/avg: 0.2258, train/total_loss: 0.1372, train/total_loss/avg: 0.2258, max mem: 9224.0, experiment: run, epoch: 8, num_updates: 2000, iterations: 2000, max_updates: 4000, lr: 0.00004, ups: 0.75, time: 02m 13s 938ms, time_since_start: 01h 58m 21s 872ms, eta: 59m 49s 544ms\n",
            "\u001b[32m2021-04-25T21:54:14 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:54:14 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:54:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:54:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:54:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:54:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/4000, val/hateful_memes/cross_entropy: 1.5026, val/total_loss: 1.5026, val/hateful_memes/accuracy: 0.7074, val/hateful_memes/binary_f1: 0.4968, val/hateful_memes/roc_auc: 0.7323, num_updates: 2000, epoch: 8, iterations: 2000, max_updates: 4000, val_time: 33s 233ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:56:37 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:56:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:56:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:57:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:57:05 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T21:57:05 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T21:57:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:57:22 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T21:57:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T21:57:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/4000, val/hateful_memes/cross_entropy: 1.2551, val/total_loss: 1.2551, val/hateful_memes/accuracy: 0.7037, val/hateful_memes/binary_f1: 0.5000, val/hateful_memes/roc_auc: 0.7303, num_updates: 2050, epoch: 8, iterations: 2050, max_updates: 4000, val_time: 36s 647ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T21:59:35 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T21:59:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T21:59:55 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:00:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:00:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/4000, train/hateful_memes/cross_entropy: 0.1342, train/hateful_memes/cross_entropy/avg: 0.2152, train/total_loss: 0.1342, train/total_loss/avg: 0.2152, max mem: 9224.0, experiment: run, epoch: 8, num_updates: 2100, iterations: 2100, max_updates: 4000, lr: 0.00004, ups: 0.71, time: 02m 20s 096ms, time_since_start: 02h 04m 10s 191ms, eta: 59m 26s 851ms\n",
            "\u001b[32m2021-04-25T22:00:02 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:00:02 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:00:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:00:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:00:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:00:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/4000, val/hateful_memes/cross_entropy: 1.4826, val/total_loss: 1.4826, val/hateful_memes/accuracy: 0.7037, val/hateful_memes/binary_f1: 0.5062, val/hateful_memes/roc_auc: 0.7276, num_updates: 2100, epoch: 8, iterations: 2100, max_updates: 4000, val_time: 36s 938ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:02:10 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:02:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:02:23 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:02:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:02:28 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:02:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:02:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:02:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:03:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:03:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/4000, val/hateful_memes/cross_entropy: 1.5503, val/total_loss: 1.5503, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.5371, val/hateful_memes/roc_auc: 0.7189, num_updates: 2150, epoch: 9, iterations: 2150, max_updates: 4000, val_time: 33s 512ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:04:42 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:04:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:04:59 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:05:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:05:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/4000, train/hateful_memes/cross_entropy: 0.0972, train/hateful_memes/cross_entropy/avg: 0.2055, train/total_loss: 0.0972, train/total_loss/avg: 0.2055, max mem: 9224.0, experiment: run, epoch: 9, num_updates: 2200, iterations: 2200, max_updates: 4000, lr: 0.00003, ups: 0.82, time: 02m 02s 507ms, time_since_start: 02h 09m 12s 607ms, eta: 49m 14s 888ms\n",
            "\u001b[32m2021-04-25T22:05:04 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:05:04 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:05:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:05:21 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:05:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:05:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/4000, val/hateful_memes/cross_entropy: 1.7575, val/total_loss: 1.7575, val/hateful_memes/accuracy: 0.7148, val/hateful_memes/binary_f1: 0.5032, val/hateful_memes/roc_auc: 0.7349, num_updates: 2200, epoch: 9, iterations: 2200, max_updates: 4000, val_time: 32s 501ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:07:21 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:07:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:07:39 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:07:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:07:53 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:07:53 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:07:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:08:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:08:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:08:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/4000, val/hateful_memes/cross_entropy: 1.6162, val/total_loss: 1.6162, val/hateful_memes/accuracy: 0.7074, val/hateful_memes/binary_f1: 0.5460, val/hateful_memes/roc_auc: 0.7241, num_updates: 2250, epoch: 9, iterations: 2250, max_updates: 4000, val_time: 28s 294ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:10:13 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:10:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:10:31 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:10:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:10:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/4000, train/hateful_memes/cross_entropy: 0.0885, train/hateful_memes/cross_entropy/avg: 0.1966, train/total_loss: 0.0885, train/total_loss/avg: 0.1966, max mem: 9224.0, experiment: run, epoch: 9, num_updates: 2300, iterations: 2300, max_updates: 4000, lr: 0.00003, ups: 0.71, time: 02m 21s 553ms, time_since_start: 02h 14m 51s 505ms, eta: 53m 44s 590ms\n",
            "\u001b[32m2021-04-25T22:10:43 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:10:43 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:10:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:11:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:11:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:11:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/4000, val/hateful_memes/cross_entropy: 1.6000, val/total_loss: 1.6000, val/hateful_memes/accuracy: 0.7148, val/hateful_memes/binary_f1: 0.5389, val/hateful_memes/roc_auc: 0.7212, num_updates: 2300, epoch: 9, iterations: 2300, max_updates: 4000, val_time: 33s 291ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:13:09 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:13:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:13:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:13:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:13:37 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:13:37 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:13:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:13:52 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:14:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:14:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/4000, val/hateful_memes/cross_entropy: 1.4423, val/total_loss: 1.4423, val/hateful_memes/accuracy: 0.7148, val/hateful_memes/binary_f1: 0.5127, val/hateful_memes/roc_auc: 0.7275, num_updates: 2350, epoch: 9, iterations: 2350, max_updates: 4000, val_time: 33s 308ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:15:55 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:15:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:16:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:16:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:16:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/4000, train/hateful_memes/cross_entropy: 0.0776, train/hateful_memes/cross_entropy/avg: 0.1885, train/total_loss: 0.0776, train/total_loss/avg: 0.1885, max mem: 9224.0, experiment: run, epoch: 10, num_updates: 2400, iterations: 2400, max_updates: 4000, lr: 0.00003, ups: 0.79, time: 02m 06s 491ms, time_since_start: 02h 20m 24s 639ms, eta: 45m 11s 975ms\n",
            "\u001b[32m2021-04-25T22:16:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:16:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:16:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:16:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:16:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:16:44 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/4000, val/hateful_memes/cross_entropy: 1.6460, val/total_loss: 1.6460, val/hateful_memes/accuracy: 0.7093, val/hateful_memes/binary_f1: 0.4886, val/hateful_memes/roc_auc: 0.7238, num_updates: 2400, epoch: 10, iterations: 2400, max_updates: 4000, val_time: 28s 071ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:18:08 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:18:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:18:14 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:18:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:18:25 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:18:25 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:18:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:18:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:19:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:19:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/4000, val/hateful_memes/cross_entropy: 1.7097, val/total_loss: 1.7097, val/hateful_memes/accuracy: 0.7241, val/hateful_memes/binary_f1: 0.5443, val/hateful_memes/roc_auc: 0.7375, num_updates: 2450, epoch: 10, iterations: 2450, max_updates: 4000, val_time: 36s 695ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:20:40 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:20:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:20:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:21:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:21:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/4000, train/hateful_memes/cross_entropy: 0.0678, train/hateful_memes/cross_entropy/avg: 0.1814, train/total_loss: 0.0678, train/total_loss/avg: 0.1814, max mem: 9224.0, experiment: run, epoch: 10, num_updates: 2500, iterations: 2500, max_updates: 4000, lr: 0.00003, ups: 0.84, time: 01m 59s 043ms, time_since_start: 02h 25m 08s 982ms, eta: 39m 52s 766ms\n",
            "\u001b[32m2021-04-25T22:21:01 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:21:01 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:21:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:21:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:21:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:21:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/4000, val/hateful_memes/cross_entropy: 1.6660, val/total_loss: 1.6660, val/hateful_memes/accuracy: 0.7204, val/hateful_memes/binary_f1: 0.5296, val/hateful_memes/roc_auc: 0.7356, num_updates: 2500, epoch: 10, iterations: 2500, max_updates: 4000, val_time: 36s 281ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:23:23 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:23:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:23:41 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:23:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:23:51 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:23:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:23:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:24:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:24:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:24:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/4000, val/hateful_memes/cross_entropy: 1.6086, val/total_loss: 1.6086, val/hateful_memes/accuracy: 0.7167, val/hateful_memes/binary_f1: 0.5433, val/hateful_memes/roc_auc: 0.7351, num_updates: 2550, epoch: 10, iterations: 2550, max_updates: 4000, val_time: 31s 628ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:26:15 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:26:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:26:36 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:26:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:26:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/4000, train/hateful_memes/cross_entropy: 0.0483, train/hateful_memes/cross_entropy/avg: 0.1745, train/total_loss: 0.0483, train/total_loss/avg: 0.1745, max mem: 9224.0, experiment: run, epoch: 10, num_updates: 2600, iterations: 2600, max_updates: 4000, lr: 0.00003, ups: 0.69, time: 02m 25s 017ms, time_since_start: 02h 30m 56s 295ms, eta: 45m 20s 522ms\n",
            "\u001b[32m2021-04-25T22:26:48 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:26:48 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:26:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:27:03 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:27:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:27:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/4000, val/hateful_memes/cross_entropy: 1.8479, val/total_loss: 1.8479, val/hateful_memes/accuracy: 0.7241, val/hateful_memes/binary_f1: 0.5115, val/hateful_memes/roc_auc: 0.7395, num_updates: 2600, epoch: 10, iterations: 2600, max_updates: 4000, val_time: 28s 626ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:29:15 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:29:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:29:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:29:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:29:46 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:29:46 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:29:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:30:01 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:30:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:30:20 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/4000, val/hateful_memes/cross_entropy: 1.9517, val/total_loss: 1.9517, val/hateful_memes/accuracy: 0.7111, val/hateful_memes/binary_f1: 0.5000, val/hateful_memes/roc_auc: 0.7311, num_updates: 2650, epoch: 10, iterations: 2650, max_updates: 4000, val_time: 34s 018ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:31:40 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:31:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:31:50 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:31:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:31:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/4000, train/hateful_memes/cross_entropy: 0.0320, train/hateful_memes/cross_entropy/avg: 0.1680, train/total_loss: 0.0320, train/total_loss/avg: 0.1680, max mem: 9224.0, experiment: run, epoch: 11, num_updates: 2700, iterations: 2700, max_updates: 4000, lr: 0.00003, ups: 1.01, time: 01m 39s 425ms, time_since_start: 02h 36m 07s 456ms, eta: 28m 51s 997ms\n",
            "\u001b[32m2021-04-25T22:31:59 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:31:59 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:32:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:32:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:32:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:32:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/4000, val/hateful_memes/cross_entropy: 2.1146, val/total_loss: 2.1146, val/hateful_memes/accuracy: 0.7222, val/hateful_memes/binary_f1: 0.5192, val/hateful_memes/roc_auc: 0.7264, num_updates: 2700, epoch: 11, iterations: 2700, max_updates: 4000, val_time: 32s 113ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:34:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:34:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:34:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:34:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:34:26 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:34:26 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:34:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:34:39 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:35:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:35:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/4000, val/hateful_memes/cross_entropy: 1.7867, val/total_loss: 1.7867, val/hateful_memes/accuracy: 0.7074, val/hateful_memes/binary_f1: 0.5587, val/hateful_memes/roc_auc: 0.7283, num_updates: 2750, epoch: 11, iterations: 2750, max_updates: 4000, val_time: 34s 765ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:36:48 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:36:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:37:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:37:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:37:06 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/4000, train/hateful_memes/cross_entropy: 0.0277, train/hateful_memes/cross_entropy/avg: 0.1620, train/total_loss: 0.0277, train/total_loss/avg: 0.1620, max mem: 9224.0, experiment: run, epoch: 11, num_updates: 2800, iterations: 2800, max_updates: 4000, lr: 0.00002, ups: 0.80, time: 02m 05s 112ms, time_since_start: 02h 41m 13s 883ms, eta: 33m 31s 812ms\n",
            "\u001b[32m2021-04-25T22:37:06 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:37:06 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:37:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:37:22 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:37:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:37:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/4000, val/hateful_memes/cross_entropy: 1.9576, val/total_loss: 1.9576, val/hateful_memes/accuracy: 0.7111, val/hateful_memes/binary_f1: 0.5032, val/hateful_memes/roc_auc: 0.7228, num_updates: 2800, epoch: 11, iterations: 2800, max_updates: 4000, val_time: 31s 293ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:39:30 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:39:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:39:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:40:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:40:02 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:40:02 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:40:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:40:16 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:40:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:40:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/4000, val/hateful_memes/cross_entropy: 1.7437, val/total_loss: 1.7437, val/hateful_memes/accuracy: 0.7130, val/hateful_memes/binary_f1: 0.5171, val/hateful_memes/roc_auc: 0.7213, num_updates: 2850, epoch: 11, iterations: 2850, max_updates: 4000, val_time: 32s 333ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:42:29 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:42:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:42:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:42:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:42:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/4000, train/hateful_memes/cross_entropy: 0.0232, train/hateful_memes/cross_entropy/avg: 0.1572, train/total_loss: 0.0232, train/total_loss/avg: 0.1572, max mem: 9224.0, experiment: run, epoch: 11, num_updates: 2900, iterations: 2900, max_updates: 4000, lr: 0.00002, ups: 0.69, time: 02m 24s 352ms, time_since_start: 02h 47m 06s 565ms, eta: 35m 27s 759ms\n",
            "\u001b[32m2021-04-25T22:42:58 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:42:58 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:43:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:43:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:43:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:43:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/4000, val/hateful_memes/cross_entropy: 1.8416, val/total_loss: 1.8416, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.4740, val/hateful_memes/roc_auc: 0.7127, num_updates: 2900, epoch: 11, iterations: 2900, max_updates: 4000, val_time: 34s 070ms, best_update: 1300, best_iteration: 1300, best_val/hateful_memes/roc_auc: 0.749937\n",
            "\u001b[32m2021-04-25T22:45:03 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-25T22:45:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:45:14 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-25T22:45:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-25T22:45:27 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-25T22:45:27 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-25T22:45:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-25T22:45:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 372, in save\n",
            "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 491, in _save\n",
            "    zip_file.write_record(name, storage.data_ptr(), num_bytes)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/mmf_run\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('mmf', 'console_scripts', 'mmf_run')())\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf_cli/run.py\", line 133, in run\n",
            "    main(configuration, predict=predict)\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf_cli/run.py\", line 56, in main\n",
            "    trainer.train()\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/trainers/mmf_trainer.py\", line 141, in train\n",
            "    self.training_loop()\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/trainers/core/training_loop.py\", line 33, in training_loop\n",
            "    self.run_training_epoch()\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/trainers/core/training_loop.py\", line 146, in run_training_epoch\n",
            "    report=report, meter=meter\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/trainers/callbacks/early_stopping.py\", line 39, in on_validation_end\n",
            "    self.trainer.num_updates, self.trainer.current_iteration, kwargs[\"meter\"]\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/utils/early_stopping.py\", line 84, in __call__\n",
            "    self.checkpoint.save(update, iteration, update_best=False)\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/utils/checkpoint.py\", line 542, in save\n",
            "    self.save_func(ckpt, f)\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/utils/checkpoint.py\", line 465, in save_func\n",
            "    return xm.save(*args) if is_xla() else torch.save(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 373, in save\n",
            "    return\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 259, in __exit__\n",
            "    self.file_like.write_end_of_file()\n",
            "RuntimeError: [enforce fail at inline_container.cc:274] . unexpected pos 1146536256 vs 1146536144\n",
            "terminate called after throwing an instance of 'c10::Error'\n",
            "  what():  [enforce fail at inline_container.cc:274] . unexpected pos 1146536256 vs 1146536144\n",
            "frame #0: c10::ThrowEnforceNotMet(char const*, int, char const*, std::string const&, void const*) + 0x47 (0x7f01e0c6f0e7 in /usr/local/lib/python3.7/dist-packages/torch/lib/libc10.so)\n",
            "frame #1: <unknown function> + 0x206a420 (0x7f0222c59420 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #2: <unknown function> + 0x20665f3 (0x7f0222c555f3 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #3: caffe2::serialize::PyTorchStreamWriter::writeRecord(std::string const&, void const*, unsigned long, bool) + 0xa9 (0x7f0222c59d99 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #4: caffe2::serialize::PyTorchStreamWriter::writeEndOfFile() + 0xe1 (0x7f0222c5a8d1 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #5: caffe2::serialize::PyTorchStreamWriter::~PyTorchStreamWriter() + 0x115 (0x7f0222c5b0c5 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so)\n",
            "frame #6: <unknown function> + 0x741603 (0x7f023388f603 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #7: <unknown function> + 0x36a338 (0x7f02334b8338 in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #8: <unknown function> + 0x36b63e (0x7f02334b963e in /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_python.so)\n",
            "frame #9: <unknown function> + 0x139328 (0x556a88716328 in /usr/bin/python3)\n",
            "frame #10: <unknown function> + 0x1cead7 (0x556a887abad7 in /usr/bin/python3)\n",
            "frame #11: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #12: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #13: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #14: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #15: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #16: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #17: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #18: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #19: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #20: <unknown function> + 0x1ceaed (0x556a887abaed in /usr/bin/python3)\n",
            "frame #21: <unknown function> + 0x24d571 (0x556a8882a571 in /usr/bin/python3)\n",
            "frame #22: PyDict_SetItemString + 0x74 (0x556a88730bd4 in /usr/bin/python3)\n",
            "frame #23: PyImport_Cleanup + 0x9d (0x556a8879abad in /usr/bin/python3)\n",
            "frame #24: Py_FinalizeEx + 0x64 (0x556a88843dc4 in /usr/bin/python3)\n",
            "frame #25: <unknown function> + 0x240f37 (0x556a8881df37 in /usr/bin/python3)\n",
            "frame #26: _Py_UnixMain + 0x3c (0x556a8881ddac in /usr/bin/python3)\n",
            "frame #27: __libc_start_main + 0xe7 (0x7f023768fbf7 in /lib/x86_64-linux-gnu/libc.so.6)\n",
            "frame #28: _start + 0x2a (0x556a8881dc8a in /usr/bin/python3)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eowmdLtFNiac",
        "outputId": "09c5a065-8212-4743-d110-24eb478df40a"
      },
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
        "model=visual_bert \\\n",
        "dataset=hateful_memes \\\n",
        "training.batch_size=48 \\\n",
        "env.save_dir=\"$path\"/visual_bert_coco_more_data_tune3 \\\n",
        "training.tensorboard=True \\\n",
        "training.checkpoint_interval=50 \\\n",
        "training.evaluation_interval=50 \\\n",
        "training.max_updates=3000 \\\n",
        "training.log_interval=100 \\\n",
        "training.lr_ratio=0.6 \\\n",
        "training.use_warmup=True \\\n",
        "optimizer.params.lr=5.0e-05 \\\n",
        "evaluation.predict=true \\\n",
        "checkpoint.resume_zoo=visual_bert.pretrained.cc.full \\\n",
        "checkpoint.max_to_keep=1 \\\n",
        "scheduler.params.num_warmup_steps=1000 \\\n",
        "scheduler.type=warmup_cosine \\\n",
        "scheduler.params.num_training_steps=5000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-26 16:50:26.503488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/hateful_memes/configs/visual_bert/from_coco.yaml\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option training.batch_size to 48\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option env.save_dir to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune3\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option training.tensorboard to True\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option training.checkpoint_interval to 50\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option training.evaluation_interval to 50\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option training.max_updates to 3000\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option training.log_interval to 100\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option training.lr_ratio to 0.6\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option training.use_warmup to True\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option optimizer.params.lr to 5.0e-05\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_zoo to visual_bert.pretrained.cc.full\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.max_to_keep to 1\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option scheduler.params.num_warmup_steps to 1000\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option scheduler.type to warmup_cosine\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.configuration: \u001b[0mOverriding option scheduler.params.num_training_steps to 5000\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf: \u001b[0mLogging to: /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune3/train.log\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/visual_bert/from_coco.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'training.batch_size=48', 'env.save_dir=/content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune3', 'training.tensorboard=True', 'training.checkpoint_interval=50', 'training.evaluation_interval=50', 'training.max_updates=3000', 'training.log_interval=100', 'training.lr_ratio=0.6', 'training.use_warmup=True', 'optimizer.params.lr=5.0e-05', 'evaluation.predict=true', 'checkpoint.resume_zoo=visual_bert.pretrained.cc.full', 'checkpoint.max_to_keep=1', 'scheduler.params.num_warmup_steps=1000', 'scheduler.type=warmup_cosine', 'scheduler.params.num_training_steps=5000'])\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf_cli.run: \u001b[0mTorch version: 1.8.1+cu102\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla P100-PCIE-16GB\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf_cli.run: \u001b[0mUsing seed 13575765\n",
            "\u001b[32m2021-04-26T16:51:13 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz ]\n",
            "Downloading features.tar.gz: 100% 10.3G/10.3G [02:33<00:00, 66.9MB/s]\n",
            "[ Starting checksum for features.tar.gz]\n",
            "[ Checksum successful for features.tar.gz]\n",
            "Unpacking features.tar.gz\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:00<00:00, 467kB/s]\n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "\u001b[32m2021-04-26T16:57:45 | filelock: \u001b[0mLock 139687567154832 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "Downloading: 100% 433/433 [00:00<00:00, 360kB/s]\n",
            "\u001b[32m2021-04-26T16:57:45 | filelock: \u001b[0mLock 139687567154832 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "\u001b[32m2021-04-26T16:57:46 | filelock: \u001b[0mLock 139687562026768 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 902kB/s]\n",
            "\u001b[32m2021-04-26T16:57:46 | filelock: \u001b[0mLock 139687562026768 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "\u001b[32m2021-04-26T16:57:46 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-26T16:57:46 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-26T16:57:46 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-26T16:57:46 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "\u001b[32m2021-04-26T16:57:46 | filelock: \u001b[0mLock 139687560543184 acquired on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "Downloading: 100% 440M/440M [00:08<00:00, 54.8MB/s]\n",
            "\u001b[32m2021-04-26T16:57:55 | filelock: \u001b[0mLock 139687560543184 released on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2021-04-26T16:58:05 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2021-04-26T16:58:05 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-26T16:58:05 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-26T16:58:05 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[32m2021-04-26T16:58:05 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/models/visual_bert/visual_bert.pretrained.cc_full.tar.gz to /root/.cache/torch/mmf/data/models/visual_bert.pretrained.cc.full/visual_bert.pretrained.cc_full.tar.gz ]\n",
            "Downloading visual_bert.pretrained.cc_full.tar.gz: 100% 415M/415M [00:06<00:00, 63.5MB/s]\n",
            "[ Starting checksum for visual_bert.pretrained.cc_full.tar.gz]\n",
            "[ Checksum successful for visual_bert.pretrained.cc_full.tar.gz]\n",
            "Unpacking visual_bert.pretrained.cc_full.tar.gz\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-26T16:58:18 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-26T16:58:18 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-26T16:58:18 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-26T16:58:18 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.weight from model.bert.pooler.dense.weight\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.bias from model.bert.pooler.dense.bias\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mPretrained model loaded\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 0\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 0\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 0\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
            "  (model): VisualBERTForClassification(\n",
            "    (bert): VisualBERTBase(\n",
            "      (embeddings): BertVisioLinguisticEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (token_type_embeddings_visual): Embedding(2, 768)\n",
            "        (position_embeddings_visual): Embedding(512, 768)\n",
            "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
            "\u001b[32m2021-04-26T16:58:18 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2021-04-26T17:01:40 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:01:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:05:29 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:05:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:05:38 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:05:42 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:06:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:06:34 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:06:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:07:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:07:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/3000, val/hateful_memes/cross_entropy: 0.6536, val/total_loss: 0.6536, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0000, val/hateful_memes/roc_auc: 0.5643, num_updates: 50, epoch: 1, iterations: 50, max_updates: 3000, val_time: 01m 24s 581ms, best_update: 50, best_iteration: 50, best_val/hateful_memes/roc_auc: 0.564279\n",
            "\u001b[32m2021-04-26T17:10:02 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:10:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:10:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:10:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:10:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/3000, train/hateful_memes/cross_entropy: 0.6542, train/hateful_memes/cross_entropy/avg: 0.6542, train/total_loss: 0.6542, train/total_loss/avg: 0.6542, max mem: 12854.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 3000, lr: 0.00001, ups: 0.51, time: 03m 16s 807ms, time_since_start: 12m 14s 697ms, eta: 01h 57m 57s 204ms\n",
            "\u001b[32m2021-04-26T17:10:19 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:10:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:11:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:11:15 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:11:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:11:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:11:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/3000, val/hateful_memes/cross_entropy: 0.6513, val/total_loss: 0.6513, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.0385, val/hateful_memes/roc_auc: 0.5776, num_updates: 100, epoch: 1, iterations: 100, max_updates: 3000, val_time: 01m 26s 990ms, best_update: 100, best_iteration: 100, best_val/hateful_memes/roc_auc: 0.577603\n",
            "\u001b[32m2021-04-26T17:14:42 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:14:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:15:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:15:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:15:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:15:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:15:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:15:57 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:16:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:16:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:16:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/3000, val/hateful_memes/cross_entropy: 0.6923, val/total_loss: 0.6923, val/hateful_memes/accuracy: 0.6315, val/hateful_memes/binary_f1: 0.0100, val/hateful_memes/roc_auc: 0.5935, num_updates: 150, epoch: 1, iterations: 150, max_updates: 3000, val_time: 01m 08s 867ms, best_update: 150, best_iteration: 150, best_val/hateful_memes/roc_auc: 0.593515\n",
            "\u001b[32m2021-04-26T17:18:53 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:18:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:18:59 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:19:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:19:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/3000, train/hateful_memes/cross_entropy: 0.5524, train/hateful_memes/cross_entropy/avg: 0.6033, train/total_loss: 0.5524, train/total_loss/avg: 0.6033, max mem: 12854.0, experiment: run, epoch: 2, num_updates: 200, iterations: 200, max_updates: 3000, lr: 0.00001, ups: 0.61, time: 02m 45s 052ms, time_since_start: 21m 05s 033ms, eta: 01h 35m 30s 641ms\n",
            "\u001b[32m2021-04-26T17:19:10 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:19:10 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:19:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:20:00 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:20:11 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:20:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:20:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/3000, val/hateful_memes/cross_entropy: 0.6871, val/total_loss: 0.6871, val/hateful_memes/accuracy: 0.6389, val/hateful_memes/binary_f1: 0.1558, val/hateful_memes/roc_auc: 0.6126, num_updates: 200, epoch: 2, iterations: 200, max_updates: 3000, val_time: 01m 21s 363ms, best_update: 200, best_iteration: 200, best_val/hateful_memes/roc_auc: 0.612647\n",
            "\u001b[32m2021-04-26T17:23:18 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:23:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:23:45 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:23:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:23:52 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:23:52 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:24:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:24:33 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:24:47 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:25:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:25:04 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/3000, val/hateful_memes/cross_entropy: 0.6823, val/total_loss: 0.6823, val/hateful_memes/accuracy: 0.6593, val/hateful_memes/binary_f1: 0.3381, val/hateful_memes/roc_auc: 0.6452, num_updates: 250, epoch: 2, iterations: 250, max_updates: 3000, val_time: 01m 11s 390ms, best_update: 250, best_iteration: 250, best_val/hateful_memes/roc_auc: 0.645176\n",
            "\u001b[32m2021-04-26T17:27:54 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:27:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:28:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:28:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:28:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/3000, train/hateful_memes/cross_entropy: 0.5524, train/hateful_memes/cross_entropy/avg: 0.5690, train/total_loss: 0.5524, train/total_loss/avg: 0.5690, max mem: 12854.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 3000, lr: 0.00002, ups: 0.54, time: 03m 06s 804ms, time_since_start: 30m 05s 595ms, eta: 01h 44m 14s 208ms\n",
            "\u001b[32m2021-04-26T17:28:10 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:28:10 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:28:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:29:04 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:29:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:29:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:29:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/3000, val/hateful_memes/cross_entropy: 0.8705, val/total_loss: 0.8705, val/hateful_memes/accuracy: 0.6444, val/hateful_memes/binary_f1: 0.2195, val/hateful_memes/roc_auc: 0.6580, num_updates: 300, epoch: 2, iterations: 300, max_updates: 3000, val_time: 01m 23s 379ms, best_update: 300, best_iteration: 300, best_val/hateful_memes/roc_auc: 0.657956\n",
            "\u001b[32m2021-04-26T17:32:27 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:32:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:32:40 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:32:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:32:52 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:32:52 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:33:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:33:29 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:33:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:33:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/3000, val/hateful_memes/cross_entropy: 0.7645, val/total_loss: 0.7645, val/hateful_memes/accuracy: 0.6389, val/hateful_memes/binary_f1: 0.2471, val/hateful_memes/roc_auc: 0.6501, num_updates: 350, epoch: 2, iterations: 350, max_updates: 3000, val_time: 49s 937ms, best_update: 300, best_iteration: 300, best_val/hateful_memes/roc_auc: 0.657956\n",
            "\u001b[32m2021-04-26T17:35:44 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:35:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:36:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:36:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:36:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/3000, train/hateful_memes/cross_entropy: 0.5004, train/hateful_memes/cross_entropy/avg: 0.4790, train/total_loss: 0.5004, train/total_loss/avg: 0.4790, max mem: 12854.0, experiment: run, epoch: 3, num_updates: 400, iterations: 400, max_updates: 3000, lr: 0.00002, ups: 0.69, time: 02m 25s 088ms, time_since_start: 38m 02s 233ms, eta: 01h 17m 57s 656ms\n",
            "\u001b[32m2021-04-26T17:36:07 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:36:07 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:36:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:36:42 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:36:54 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:37:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:37:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/3000, val/hateful_memes/cross_entropy: 0.7616, val/total_loss: 0.7616, val/hateful_memes/accuracy: 0.6574, val/hateful_memes/binary_f1: 0.3813, val/hateful_memes/roc_auc: 0.6960, num_updates: 400, epoch: 3, iterations: 400, max_updates: 3000, val_time: 01m 02s 751ms, best_update: 400, best_iteration: 400, best_val/hateful_memes/roc_auc: 0.696000\n",
            "\u001b[32m2021-04-26T17:39:54 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:39:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:40:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:40:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:40:19 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:40:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:40:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:40:30 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:40:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:41:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:41:01 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/3000, val/hateful_memes/cross_entropy: 0.7103, val/total_loss: 0.7103, val/hateful_memes/accuracy: 0.6611, val/hateful_memes/binary_f1: 0.3441, val/hateful_memes/roc_auc: 0.6986, num_updates: 450, epoch: 3, iterations: 450, max_updates: 3000, val_time: 41s 781ms, best_update: 450, best_iteration: 450, best_val/hateful_memes/roc_auc: 0.698647\n",
            "\u001b[32m2021-04-26T17:43:45 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:43:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:43:52 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:44:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:44:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/3000, train/hateful_memes/cross_entropy: 0.5004, train/hateful_memes/cross_entropy/avg: 0.4477, train/total_loss: 0.5004, train/total_loss/avg: 0.4477, max mem: 12854.0, experiment: run, epoch: 3, num_updates: 500, iterations: 500, max_updates: 3000, lr: 0.00003, ups: 0.53, time: 03m 09s 303ms, time_since_start: 46m 05s 534ms, eta: 01h 37m 48s 423ms\n",
            "\u001b[32m2021-04-26T17:44:10 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:44:10 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:44:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:44:28 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:44:41 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:45:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:45:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/3000, val/hateful_memes/cross_entropy: 0.6815, val/total_loss: 0.6815, val/hateful_memes/accuracy: 0.6685, val/hateful_memes/binary_f1: 0.4281, val/hateful_memes/roc_auc: 0.7106, num_updates: 500, epoch: 3, iterations: 500, max_updates: 3000, val_time: 49s 921ms, best_update: 500, best_iteration: 500, best_val/hateful_memes/roc_auc: 0.710603\n",
            "\u001b[32m2021-04-26T17:47:15 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:47:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:47:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:47:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:47:40 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:47:46 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:47:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:48:00 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:48:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:48:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:48:33 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/3000, val/hateful_memes/cross_entropy: 0.7556, val/total_loss: 0.7556, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4830, val/hateful_memes/roc_auc: 0.7287, num_updates: 550, epoch: 4, iterations: 550, max_updates: 3000, val_time: 52s 293ms, best_update: 550, best_iteration: 550, best_val/hateful_memes/roc_auc: 0.728662\n",
            "\u001b[32m2021-04-26T17:51:01 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:51:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:51:23 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:51:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:51:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/3000, train/hateful_memes/cross_entropy: 0.3963, train/hateful_memes/cross_entropy/avg: 0.4391, train/total_loss: 0.3963, train/total_loss/avg: 0.4391, max mem: 12854.0, experiment: run, epoch: 4, num_updates: 600, iterations: 600, max_updates: 3000, lr: 0.00003, ups: 0.55, time: 03m 02s 992ms, time_since_start: 53m 31s 053ms, eta: 01h 30m 45s 846ms\n",
            "\u001b[32m2021-04-26T17:51:36 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:51:36 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:51:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:51:48 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T17:52:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:52:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:52:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/3000, val/hateful_memes/cross_entropy: 0.6802, val/total_loss: 0.6802, val/hateful_memes/accuracy: 0.7130, val/hateful_memes/binary_f1: 0.5455, val/hateful_memes/roc_auc: 0.7305, num_updates: 600, epoch: 4, iterations: 600, max_updates: 3000, val_time: 45s 453ms, best_update: 600, best_iteration: 600, best_val/hateful_memes/roc_auc: 0.730515\n",
            "\u001b[32m2021-04-26T17:55:04 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:55:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:55:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:55:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:55:32 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:55:32 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:55:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:55:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:55:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:55:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/3000, val/hateful_memes/cross_entropy: 0.8138, val/total_loss: 0.8138, val/hateful_memes/accuracy: 0.6648, val/hateful_memes/binary_f1: 0.4180, val/hateful_memes/roc_auc: 0.7197, num_updates: 650, epoch: 4, iterations: 650, max_updates: 3000, val_time: 25s 100ms, best_update: 600, best_iteration: 600, best_val/hateful_memes/roc_auc: 0.730515\n",
            "\u001b[32m2021-04-26T17:58:45 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T17:58:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:59:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:59:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:59:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/3000, train/hateful_memes/cross_entropy: 0.3963, train/hateful_memes/cross_entropy/avg: 0.4127, train/total_loss: 0.3963, train/total_loss/avg: 0.4127, max mem: 12854.0, experiment: run, epoch: 4, num_updates: 700, iterations: 700, max_updates: 3000, lr: 0.00003, ups: 0.50, time: 03m 21s 771ms, time_since_start: 01h 01m 13s 866ms, eta: 01h 35m 54s 531ms\n",
            "\u001b[32m2021-04-26T17:59:19 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T17:59:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T17:59:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T17:59:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T17:59:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T17:59:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/3000, val/hateful_memes/cross_entropy: 0.7435, val/total_loss: 0.7435, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4122, val/hateful_memes/roc_auc: 0.7138, num_updates: 700, epoch: 4, iterations: 700, max_updates: 3000, val_time: 30s 234ms, best_update: 600, best_iteration: 600, best_val/hateful_memes/roc_auc: 0.730515\n",
            "\u001b[32m2021-04-26T18:01:37 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:01:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:01:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:02:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:02:08 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:02:08 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:02:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:02:22 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:02:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:02:42 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/3000, val/hateful_memes/cross_entropy: 0.7517, val/total_loss: 0.7517, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4800, val/hateful_memes/roc_auc: 0.7151, num_updates: 750, epoch: 5, iterations: 750, max_updates: 3000, val_time: 33s 743ms, best_update: 600, best_iteration: 600, best_val/hateful_memes/roc_auc: 0.730515\n",
            "\u001b[32m2021-04-26T18:05:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:05:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:05:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:05:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:05:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/3000, train/hateful_memes/cross_entropy: 0.3225, train/hateful_memes/cross_entropy/avg: 0.3821, train/total_loss: 0.3225, train/total_loss/avg: 0.3821, max mem: 12854.0, experiment: run, epoch: 5, num_updates: 800, iterations: 800, max_updates: 3000, lr: 0.00004, ups: 0.56, time: 02m 59s 246ms, time_since_start: 01h 07m 36s 597ms, eta: 01h 21m 29s 857ms\n",
            "\u001b[32m2021-04-26T18:05:41 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:05:41 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:05:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:06:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:06:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:06:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/3000, val/hateful_memes/cross_entropy: 0.8522, val/total_loss: 0.8522, val/hateful_memes/accuracy: 0.6759, val/hateful_memes/binary_f1: 0.4648, val/hateful_memes/roc_auc: 0.7260, num_updates: 800, epoch: 5, iterations: 800, max_updates: 3000, val_time: 34s 912ms, best_update: 600, best_iteration: 600, best_val/hateful_memes/roc_auc: 0.730515\n",
            "\u001b[32m2021-04-26T18:09:07 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:09:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:09:31 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:09:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:09:42 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:09:42 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:10:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:10:14 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T18:10:25 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:10:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:10:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/3000, val/hateful_memes/cross_entropy: 0.7553, val/total_loss: 0.7553, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.5326, val/hateful_memes/roc_auc: 0.7428, num_updates: 850, epoch: 5, iterations: 850, max_updates: 3000, val_time: 58s 945ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.742838\n",
            "\u001b[32m2021-04-26T18:13:22 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:13:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:13:35 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:13:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:13:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/3000, train/hateful_memes/cross_entropy: 0.3225, train/hateful_memes/cross_entropy/avg: 0.3553, train/total_loss: 0.3225, train/total_loss/avg: 0.3553, max mem: 12854.0, experiment: run, epoch: 6, num_updates: 900, iterations: 900, max_updates: 3000, lr: 0.00005, ups: 0.56, time: 03m 372ms, time_since_start: 01h 15m 36s 141ms, eta: 01h 18m 16s 891ms\n",
            "\u001b[32m2021-04-26T18:13:41 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:13:41 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:13:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:14:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:14:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:14:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/3000, val/hateful_memes/cross_entropy: 1.1406, val/total_loss: 1.1406, val/hateful_memes/accuracy: 0.6926, val/hateful_memes/binary_f1: 0.4713, val/hateful_memes/roc_auc: 0.7210, num_updates: 900, epoch: 6, iterations: 900, max_updates: 3000, val_time: 31s 811ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.742838\n",
            "\u001b[32m2021-04-26T18:16:33 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:16:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:16:39 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:16:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:16:59 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:16:59 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:17:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:17:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:17:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:17:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/3000, val/hateful_memes/cross_entropy: 1.1197, val/total_loss: 1.1197, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4422, val/hateful_memes/roc_auc: 0.7186, num_updates: 950, epoch: 6, iterations: 950, max_updates: 3000, val_time: 26s 186ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.742838\n",
            "\u001b[32m2021-04-26T18:20:11 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:20:11 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:20:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:20:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:20:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/3000, train/hateful_memes/cross_entropy: 0.3169, train/hateful_memes/cross_entropy/avg: 0.3515, train/total_loss: 0.3169, train/total_loss/avg: 0.3515, max mem: 12854.0, experiment: run, epoch: 6, num_updates: 1000, iterations: 1000, max_updates: 3000, lr: 0.00005, ups: 0.50, time: 03m 20s 360ms, time_since_start: 01h 22m 41s 002ms, eta: 01h 22m 48s 939ms\n",
            "\u001b[32m2021-04-26T18:20:46 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:20:46 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:20:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:21:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:21:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:21:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/3000, val/hateful_memes/cross_entropy: 0.9228, val/total_loss: 0.9228, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.5404, val/hateful_memes/roc_auc: 0.7253, num_updates: 1000, epoch: 6, iterations: 1000, max_updates: 3000, val_time: 32s 140ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.742838\n",
            "\u001b[32m2021-04-26T18:24:10 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:24:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:24:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:24:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:24:41 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:24:41 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:25:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:25:07 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:25:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:25:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/3000, val/hateful_memes/cross_entropy: 0.9590, val/total_loss: 0.9590, val/hateful_memes/accuracy: 0.6963, val/hateful_memes/binary_f1: 0.5233, val/hateful_memes/roc_auc: 0.7208, num_updates: 1050, epoch: 6, iterations: 1050, max_updates: 3000, val_time: 38s 051ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.742838\n",
            "\u001b[32m2021-04-26T18:27:13 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:27:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:27:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:27:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:27:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/3000, train/hateful_memes/cross_entropy: 0.3169, train/hateful_memes/cross_entropy/avg: 0.3240, train/total_loss: 0.3169, train/total_loss/avg: 0.3240, max mem: 12854.0, experiment: run, epoch: 7, num_updates: 1100, iterations: 1100, max_updates: 3000, lr: 0.00005, ups: 0.69, time: 02m 25s 370ms, time_since_start: 01h 29m 40s 094ms, eta: 57m 04s 920ms\n",
            "\u001b[32m2021-04-26T18:27:45 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:27:45 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:27:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:28:01 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:28:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:28:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/3000, val/hateful_memes/cross_entropy: 1.1672, val/total_loss: 1.1672, val/hateful_memes/accuracy: 0.7167, val/hateful_memes/binary_f1: 0.5263, val/hateful_memes/roc_auc: 0.7380, num_updates: 1100, epoch: 7, iterations: 1100, max_updates: 3000, val_time: 32s 430ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.742838\n",
            "\u001b[32m2021-04-26T18:30:56 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:30:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:31:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:31:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:31:27 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:31:27 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:31:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:31:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:32:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:32:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/3000, val/hateful_memes/cross_entropy: 1.1032, val/total_loss: 1.1032, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4319, val/hateful_memes/roc_auc: 0.7309, num_updates: 1150, epoch: 7, iterations: 1150, max_updates: 3000, val_time: 33s 327ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.742838\n",
            "\u001b[32m2021-04-26T18:34:57 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:34:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:35:21 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:35:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:35:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/3000, train/hateful_memes/cross_entropy: 0.2543, train/hateful_memes/cross_entropy/avg: 0.3022, train/total_loss: 0.2543, train/total_loss/avg: 0.3022, max mem: 12854.0, experiment: run, epoch: 7, num_updates: 1200, iterations: 1200, max_updates: 3000, lr: 0.00005, ups: 0.47, time: 03m 33s 961ms, time_since_start: 01h 37m 29s 277ms, eta: 01h 19m 35s 630ms\n",
            "\u001b[32m2021-04-26T18:35:34 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:35:34 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:35:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:36:01 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T18:36:12 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:36:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:36:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/3000, val/hateful_memes/cross_entropy: 0.9977, val/total_loss: 0.9977, val/hateful_memes/accuracy: 0.7074, val/hateful_memes/binary_f1: 0.5298, val/hateful_memes/roc_auc: 0.7460, num_updates: 1200, epoch: 7, iterations: 1200, max_updates: 3000, val_time: 57s 612ms, best_update: 1200, best_iteration: 1200, best_val/hateful_memes/roc_auc: 0.745956\n",
            "\u001b[32m2021-04-26T18:39:14 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:39:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:39:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:39:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:39:33 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:39:33 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:39:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:39:48 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:40:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:40:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/3000, val/hateful_memes/cross_entropy: 1.0887, val/total_loss: 1.0887, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.5150, val/hateful_memes/roc_auc: 0.7177, num_updates: 1250, epoch: 8, iterations: 1250, max_updates: 3000, val_time: 29s 375ms, best_update: 1200, best_iteration: 1200, best_val/hateful_memes/roc_auc: 0.745956\n",
            "\u001b[32m2021-04-26T18:42:16 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:42:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:42:22 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:42:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:42:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/3000, train/hateful_memes/cross_entropy: 0.2543, train/hateful_memes/cross_entropy/avg: 0.2818, train/total_loss: 0.2543, train/total_loss/avg: 0.2818, max mem: 12854.0, experiment: run, epoch: 8, num_updates: 1300, iterations: 1300, max_updates: 3000, lr: 0.00005, ups: 0.63, time: 02m 38s 669ms, time_since_start: 01h 44m 36s 348ms, eta: 55m 44s 763ms\n",
            "\u001b[32m2021-04-26T18:42:41 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:42:41 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:42:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:42:54 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:43:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:43:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/3000, val/hateful_memes/cross_entropy: 1.1149, val/total_loss: 1.1149, val/hateful_memes/accuracy: 0.7074, val/hateful_memes/binary_f1: 0.5537, val/hateful_memes/roc_auc: 0.7321, num_updates: 1300, epoch: 8, iterations: 1300, max_updates: 3000, val_time: 25s 766ms, best_update: 1200, best_iteration: 1200, best_val/hateful_memes/roc_auc: 0.745956\n",
            "\u001b[32m2021-04-26T18:45:54 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:45:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:46:15 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:46:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:46:20 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:46:20 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:46:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:46:36 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:46:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:46:53 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/3000, val/hateful_memes/cross_entropy: 1.2979, val/total_loss: 1.2979, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.5700, val/hateful_memes/roc_auc: 0.7234, num_updates: 1350, epoch: 8, iterations: 1350, max_updates: 3000, val_time: 32s 340ms, best_update: 1200, best_iteration: 1200, best_val/hateful_memes/roc_auc: 0.745956\n",
            "\u001b[32m2021-04-26T18:49:51 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:49:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:50:15 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:50:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:50:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/3000, train/hateful_memes/cross_entropy: 0.2089, train/hateful_memes/cross_entropy/avg: 0.2650, train/total_loss: 0.2089, train/total_loss/avg: 0.2650, max mem: 12854.0, experiment: run, epoch: 8, num_updates: 1400, iterations: 1400, max_updates: 3000, lr: 0.00005, ups: 0.48, time: 03m 30s 388ms, time_since_start: 01h 52m 18s 439ms, eta: 01h 09m 34s 100ms\n",
            "\u001b[32m2021-04-26T18:50:23 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:50:23 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:50:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:50:48 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:50:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:50:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/3000, val/hateful_memes/cross_entropy: 1.1250, val/total_loss: 1.1250, val/hateful_memes/accuracy: 0.7019, val/hateful_memes/binary_f1: 0.5413, val/hateful_memes/roc_auc: 0.7287, num_updates: 1400, epoch: 8, iterations: 1400, max_updates: 3000, val_time: 35s 158ms, best_update: 1200, best_iteration: 1200, best_val/hateful_memes/roc_auc: 0.745956\n",
            "\u001b[32m2021-04-26T18:53:05 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:53:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:53:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:53:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:53:28 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:53:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:53:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:53:48 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:54:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:54:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/3000, val/hateful_memes/cross_entropy: 1.3956, val/total_loss: 1.3956, val/hateful_memes/accuracy: 0.7093, val/hateful_memes/binary_f1: 0.4952, val/hateful_memes/roc_auc: 0.7178, num_updates: 1450, epoch: 9, iterations: 1450, max_updates: 3000, val_time: 32s 356ms, best_update: 1200, best_iteration: 1200, best_val/hateful_memes/roc_auc: 0.745956\n",
            "\u001b[32m2021-04-26T18:56:41 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T18:56:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:57:05 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:57:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:57:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/3000, train/hateful_memes/cross_entropy: 0.2089, train/hateful_memes/cross_entropy/avg: 0.2527, train/total_loss: 0.2089, train/total_loss/avg: 0.2527, max mem: 12854.0, experiment: run, epoch: 9, num_updates: 1500, iterations: 1500, max_updates: 3000, lr: 0.00005, ups: 0.53, time: 03m 09s 985ms, time_since_start: 01h 59m 05s 511ms, eta: 58m 53s 732ms\n",
            "\u001b[32m2021-04-26T18:57:10 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T18:57:10 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T18:57:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T18:57:29 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T18:57:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T18:57:45 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/3000, val/hateful_memes/cross_entropy: 1.3517, val/total_loss: 1.3517, val/hateful_memes/accuracy: 0.7204, val/hateful_memes/binary_f1: 0.5354, val/hateful_memes/roc_auc: 0.7366, num_updates: 1500, epoch: 9, iterations: 1500, max_updates: 3000, val_time: 34s 756ms, best_update: 1200, best_iteration: 1200, best_val/hateful_memes/roc_auc: 0.745956\n",
            "\u001b[32m2021-04-26T19:00:41 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T19:00:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:01:04 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:01:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:01:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T19:01:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T19:01:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:01:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:01:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:01:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/3000, val/hateful_memes/cross_entropy: 1.5046, val/total_loss: 1.5046, val/hateful_memes/accuracy: 0.7111, val/hateful_memes/binary_f1: 0.5000, val/hateful_memes/roc_auc: 0.7405, num_updates: 1550, epoch: 9, iterations: 1550, max_updates: 3000, val_time: 31s 955ms, best_update: 1200, best_iteration: 1200, best_val/hateful_memes/roc_auc: 0.745956\n",
            "\u001b[32m2021-04-26T19:04:40 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T19:04:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:04:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:04:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:04:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/3000, train/hateful_memes/cross_entropy: 0.1675, train/hateful_memes/cross_entropy/avg: 0.2373, train/total_loss: 0.1675, train/total_loss/avg: 0.2373, max mem: 12854.0, experiment: run, epoch: 9, num_updates: 1600, iterations: 1600, max_updates: 3000, lr: 0.00005, ups: 0.53, time: 03m 09s 705ms, time_since_start: 02h 06m 53s 011ms, eta: 54m 53s 282ms\n",
            "\u001b[32m2021-04-26T19:04:58 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T19:04:58 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T19:05:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:05:17 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-26T19:05:29 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:05:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:05:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/3000, val/hateful_memes/cross_entropy: 1.1783, val/total_loss: 1.1783, val/hateful_memes/accuracy: 0.7130, val/hateful_memes/binary_f1: 0.5777, val/hateful_memes/roc_auc: 0.7500, num_updates: 1600, epoch: 9, iterations: 1600, max_updates: 3000, val_time: 52s 871ms, best_update: 1600, best_iteration: 1600, best_val/hateful_memes/roc_auc: 0.750015\n",
            "\u001b[32m2021-04-26T19:08:17 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T19:08:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:08:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:08:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:08:35 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T19:08:35 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T19:08:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:08:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:09:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:09:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/3000, val/hateful_memes/cross_entropy: 1.4845, val/total_loss: 1.4845, val/hateful_memes/accuracy: 0.7204, val/hateful_memes/binary_f1: 0.5382, val/hateful_memes/roc_auc: 0.7446, num_updates: 1650, epoch: 10, iterations: 1650, max_updates: 3000, val_time: 35s 435ms, best_update: 1600, best_iteration: 1600, best_val/hateful_memes/roc_auc: 0.750015\n",
            "\u001b[32m2021-04-26T19:11:50 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T19:11:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:12:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:12:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:12:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/3000, train/hateful_memes/cross_entropy: 0.1675, train/hateful_memes/cross_entropy/avg: 0.2262, train/total_loss: 0.1675, train/total_loss/avg: 0.2262, max mem: 12854.0, experiment: run, epoch: 10, num_updates: 1700, iterations: 1700, max_updates: 3000, lr: 0.00005, ups: 0.53, time: 03m 07s 150ms, time_since_start: 02h 14m 12s 941ms, eta: 50m 16s 862ms\n",
            "\u001b[32m2021-04-26T19:12:18 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T19:12:18 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T19:12:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:12:36 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:12:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:12:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/3000, val/hateful_memes/cross_entropy: 1.4995, val/total_loss: 1.4995, val/hateful_memes/accuracy: 0.6944, val/hateful_memes/binary_f1: 0.4923, val/hateful_memes/roc_auc: 0.7244, num_updates: 1700, epoch: 10, iterations: 1700, max_updates: 3000, val_time: 31s 872ms, best_update: 1600, best_iteration: 1600, best_val/hateful_memes/roc_auc: 0.750015\n",
            "\u001b[32m2021-04-26T19:15:43 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T19:15:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:16:07 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:16:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:16:19 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T19:16:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T19:16:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:16:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:16:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:16:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/3000, val/hateful_memes/cross_entropy: 1.5796, val/total_loss: 1.5796, val/hateful_memes/accuracy: 0.7019, val/hateful_memes/binary_f1: 0.5251, val/hateful_memes/roc_auc: 0.7208, num_updates: 1750, epoch: 10, iterations: 1750, max_updates: 3000, val_time: 28s 480ms, best_update: 1600, best_iteration: 1600, best_val/hateful_memes/roc_auc: 0.750015\n",
            "\u001b[32m2021-04-26T19:19:01 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T19:19:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:19:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:19:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:19:25 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/3000, train/hateful_memes/cross_entropy: 0.1414, train/hateful_memes/cross_entropy/avg: 0.2158, train/total_loss: 0.1414, train/total_loss/avg: 0.2158, max mem: 12854.0, experiment: run, epoch: 11, num_updates: 1800, iterations: 1800, max_updates: 3000, lr: 0.00005, ups: 0.64, time: 02m 37s 956ms, time_since_start: 02h 21m 20s 230ms, eta: 39m 10s 390ms\n",
            "\u001b[32m2021-04-26T19:19:25 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T19:19:25 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T19:19:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:19:42 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:20:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:20:02 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/3000, val/hateful_memes/cross_entropy: 1.3933, val/total_loss: 1.3933, val/hateful_memes/accuracy: 0.7000, val/hateful_memes/binary_f1: 0.4841, val/hateful_memes/roc_auc: 0.7288, num_updates: 1800, epoch: 11, iterations: 1800, max_updates: 3000, val_time: 36s 835ms, best_update: 1600, best_iteration: 1600, best_val/hateful_memes/roc_auc: 0.750015\n",
            "\u001b[32m2021-04-26T19:22:37 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-26T19:22:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:22:57 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:23:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:23:02 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-26T19:23:02 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-26T19:23:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-26T19:23:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-26T19:23:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-26T19:23:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/3000, val/hateful_memes/cross_entropy: 1.3974, val/total_loss: 1.3974, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.5743, val/hateful_memes/roc_auc: 0.7116, num_updates: 1850, epoch: 11, iterations: 1850, max_updates: 3000, val_time: 32s 548ms, best_update: 1600, best_iteration: 1600, best_val/hateful_memes/roc_auc: 0.750015\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/mmf_run\", line 33, in <module>\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf_cli/run.py\", line 133, in run\n",
            "    main(configuration, predict=predict)\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf_cli/run.py\", line 56, in main\n",
            "    trainer.train()\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/trainers/mmf_trainer.py\", line 141, in train\n",
            "    self.training_loop()\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/trainers/core/training_loop.py\", line 33, in training_loop\n",
            "    self.run_training_epoch()\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/trainers/core/training_loop.py\", line 77, in run_training_epoch\n",
            "    for idx, batch in enumerate(self.train_loader):\n",
            "  File \"/content/drive/MyDrive/School/CS7643/project/mmf/mmf/datasets/multi_dataset_loader.py\", line 199, in __next__\n",
            "    next_batch = next(self.current_iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1182, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1148, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 986, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n",
            "    if not self._poll(timeout):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n",
            "    return self._poll(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n",
            "    r = wait([self], timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6m9JRtgpM8n",
        "outputId": "3f439aaa-4b2b-4ca1-b5c8-913e9335e41b"
      },
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
        "model=visual_bert \\\n",
        "dataset=hateful_memes \\\n",
        "training.batch_size=48 \\\n",
        "env.save_dir=\"$path\"/visual_bert_coco_more_data_tune4 \\\n",
        "training.tensorboard=True \\\n",
        "training.checkpoint_interval=50 \\\n",
        "training.evaluation_interval=50 \\\n",
        "training.max_updates=3000 \\\n",
        "training.log_interval=100 \\\n",
        "training.lr_ratio=0.6 \\\n",
        "training.use_warmup=True \\\n",
        "optimizer.params.lr=5.0e-05 \\\n",
        "evaluation.predict=true \\\n",
        "checkpoint.resume_zoo=visual_bert.pretrained.cc.full \\\n",
        "checkpoint.max_to_keep=1 \\\n",
        "scheduler.params.num_warmup_steps=2000 \\\n",
        "scheduler.type=warmup_cosine \\\n",
        "scheduler.params.num_training_steps=5000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txRGeyyojHcH",
        "outputId": "680858cc-aa1a-4780-be56-8b788c8bedee"
      },
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
        "model=visual_bert \\\n",
        "dataset=hateful_memes \\\n",
        "training.batch_size=48 \\\n",
        "env.save_dir=\"$path\"/visual_bert_coco_more_data_roberta1 \\\n",
        "training.tensorboard=True \\\n",
        "training.checkpoint_interval=50 \\\n",
        "training.evaluation_interval=50 \\\n",
        "training.max_updates=3000 \\\n",
        "training.log_interval=100 \\\n",
        "training.lr_ratio=0.6 \\\n",
        "training.use_warmup=True \\\n",
        "optimizer.params.lr=5.0e-05 \\\n",
        "evaluation.predict=true \\\n",
        "checkpoint.resume_zoo=visual_bert.pretrained.cc.full \\\n",
        "checkpoint.max_to_keep=1 \\\n",
        "scheduler.params.num_warmup_steps=1000 \\\n",
        "scheduler.type=warmup_cosine \\\n",
        "scheduler.params.num_training_steps=5000 \\\n",
        "dataset_config.hateful_memes.processors.text_processor.type=roberta_tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fatal Python error: initsite: Failed to import the site module\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/site.py\", line 596, in <module>\n",
            "    main()\n",
            "  File \"/usr/lib/python3.7/site.py\", line 583, in main\n",
            "    known_paths = addsitepackages(known_paths)\n",
            "  File \"/usr/lib/python3.7/site.py\", line 366, in addsitepackages\n",
            "    addsitedir(sitedir, known_paths)\n",
            "  File \"/usr/lib/python3.7/site.py\", line 213, in addsitedir\n",
            "    addpackage(sitedir, name, known_paths)\n",
            "  File \"/usr/lib/python3.7/site.py\", line 169, in addpackage\n",
            "    for n, line in enumerate(f):\n",
            "  File \"/usr/lib/python3.7/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTt9G-GyfDkW",
        "outputId": "53dd2c6d-c85b-46e0-98b2-f2d74380d251"
      },
      "source": [
        "!mmf_run config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
        "model=visual_bert \\\n",
        "dataset=hateful_memes \\\n",
        "training.batch_size=48 \\\n",
        "env.save_dir=\"$path\"/visual_bert_coco_more_data_roberta2 \\\n",
        "training.tensorboard=True \\\n",
        "training.checkpoint_interval=50 \\\n",
        "training.evaluation_interval=50 \\\n",
        "training.max_updates=3000 \\\n",
        "training.log_interval=100 \\\n",
        "training.lr_ratio=0.6 \\\n",
        "training.use_warmup=True \\\n",
        "optimizer.params.lr=1.0e-05 \\\n",
        "evaluation.predict=true \\\n",
        "checkpoint.resume_zoo=visual_bert.pretrained.cc.full \\\n",
        "checkpoint.max_to_keep=1 \\\n",
        "scheduler.params.num_warmup_steps=1000 \\\n",
        "scheduler.type=warmup_cosine \\\n",
        "scheduler.params.num_training_steps=5000 \\\n",
        "dataset_config.hateful_memes.processors.text_processor.type=roberta_tokenizer \\\n",
        "dataset_config.hateful_memes.processors.text_processor.params=roberta_tokenizer.tokenizer_config=roberta-base"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-27 19:17:18.099255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/hateful_memes/configs/visual_bert/from_coco.yaml\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option training.batch_size to 48\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option env.save_dir to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_roberta2\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option training.tensorboard to True\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option training.checkpoint_interval to 50\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option training.evaluation_interval to 50\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option training.max_updates to 3000\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option training.log_interval to 100\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option training.lr_ratio to 0.6\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option training.use_warmup to True\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option optimizer.params.lr to 1.0e-05\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_zoo to visual_bert.pretrained.cc.full\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.max_to_keep to 1\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option scheduler.params.num_warmup_steps to 1000\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option scheduler.type to warmup_cosine\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option scheduler.params.num_training_steps to 5000\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.processors.text_processor.type to roberta_tokenizer\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf: \u001b[0mLogging to: /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_roberta2/train.log\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/visual_bert/from_coco.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'training.batch_size=48', 'env.save_dir=/content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_roberta2', 'training.tensorboard=True', 'training.checkpoint_interval=50', 'training.evaluation_interval=50', 'training.max_updates=3000', 'training.log_interval=100', 'training.lr_ratio=0.6', 'training.use_warmup=True', 'optimizer.params.lr=1.0e-05', 'evaluation.predict=true', 'checkpoint.resume_zoo=visual_bert.pretrained.cc.full', 'checkpoint.max_to_keep=1', 'scheduler.params.num_warmup_steps=1000', 'scheduler.type=warmup_cosine', 'scheduler.params.num_training_steps=5000', 'dataset_config.hateful_memes.processors.text_processor.type=roberta_tokenizer', 'dataset_config.hateful_memes.processors.text_processor.params=roberta_tokenizer.tokenizer_config=roberta-base'])\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf_cli.run: \u001b[0mTorch version: 1.8.1+cu102\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla P100-PCIE-16GB\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf_cli.run: \u001b[0mUsing seed 26035513\n",
            "\u001b[32m2021-04-27T19:17:25 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "\u001b[32m2021-04-27T19:17:28 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-27T19:17:28 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-27T19:17:28 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-27T19:17:28 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2021-04-27T19:17:43 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2021-04-27T19:17:43 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T19:17:43 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T19:17:43 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[32m2021-04-27T19:17:43 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T19:17:51 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T19:17:51 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T19:17:51 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-27T19:17:51 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.word_embeddings.weight from model.bert.embeddings.word_embeddings.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings.weight from model.bert.embeddings.position_embeddings.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings.weight from model.bert.embeddings.token_type_embeddings.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.weight from model.bert.embeddings.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.LayerNorm.bias from model.bert.embeddings.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.token_type_embeddings_visual.weight from model.bert.embeddings.token_type_embeddings_visual.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.position_embeddings_visual.weight from model.bert.embeddings.position_embeddings_visual.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.weight from model.bert.embeddings.projection.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.embeddings.projection.bias from model.bert.embeddings.projection.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.weight from model.bert.encoder.layer.0.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.query.bias from model.bert.encoder.layer.0.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.weight from model.bert.encoder.layer.0.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.key.bias from model.bert.encoder.layer.0.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.weight from model.bert.encoder.layer.0.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.self.value.bias from model.bert.encoder.layer.0.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.weight from model.bert.encoder.layer.0.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.dense.bias from model.bert.encoder.layer.0.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.weight from model.bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.attention.output.LayerNorm.bias from model.bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.weight from model.bert.encoder.layer.0.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.intermediate.dense.bias from model.bert.encoder.layer.0.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.weight from model.bert.encoder.layer.0.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.dense.bias from model.bert.encoder.layer.0.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.weight from model.bert.encoder.layer.0.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.0.output.LayerNorm.bias from model.bert.encoder.layer.0.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.weight from model.bert.encoder.layer.1.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.query.bias from model.bert.encoder.layer.1.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.weight from model.bert.encoder.layer.1.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.key.bias from model.bert.encoder.layer.1.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.weight from model.bert.encoder.layer.1.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.self.value.bias from model.bert.encoder.layer.1.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.weight from model.bert.encoder.layer.1.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.dense.bias from model.bert.encoder.layer.1.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.weight from model.bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.attention.output.LayerNorm.bias from model.bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.weight from model.bert.encoder.layer.1.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.intermediate.dense.bias from model.bert.encoder.layer.1.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.weight from model.bert.encoder.layer.1.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.dense.bias from model.bert.encoder.layer.1.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.weight from model.bert.encoder.layer.1.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.1.output.LayerNorm.bias from model.bert.encoder.layer.1.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.weight from model.bert.encoder.layer.2.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.query.bias from model.bert.encoder.layer.2.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.weight from model.bert.encoder.layer.2.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.key.bias from model.bert.encoder.layer.2.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.weight from model.bert.encoder.layer.2.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.self.value.bias from model.bert.encoder.layer.2.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.weight from model.bert.encoder.layer.2.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.dense.bias from model.bert.encoder.layer.2.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.weight from model.bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.attention.output.LayerNorm.bias from model.bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.weight from model.bert.encoder.layer.2.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.intermediate.dense.bias from model.bert.encoder.layer.2.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.weight from model.bert.encoder.layer.2.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.dense.bias from model.bert.encoder.layer.2.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.weight from model.bert.encoder.layer.2.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.2.output.LayerNorm.bias from model.bert.encoder.layer.2.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.weight from model.bert.encoder.layer.3.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.query.bias from model.bert.encoder.layer.3.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.weight from model.bert.encoder.layer.3.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.key.bias from model.bert.encoder.layer.3.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.weight from model.bert.encoder.layer.3.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.self.value.bias from model.bert.encoder.layer.3.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.weight from model.bert.encoder.layer.3.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.dense.bias from model.bert.encoder.layer.3.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.weight from model.bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.attention.output.LayerNorm.bias from model.bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.weight from model.bert.encoder.layer.3.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.intermediate.dense.bias from model.bert.encoder.layer.3.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.weight from model.bert.encoder.layer.3.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.dense.bias from model.bert.encoder.layer.3.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.weight from model.bert.encoder.layer.3.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.3.output.LayerNorm.bias from model.bert.encoder.layer.3.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.weight from model.bert.encoder.layer.4.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.query.bias from model.bert.encoder.layer.4.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.weight from model.bert.encoder.layer.4.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.key.bias from model.bert.encoder.layer.4.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.weight from model.bert.encoder.layer.4.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.self.value.bias from model.bert.encoder.layer.4.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.weight from model.bert.encoder.layer.4.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.dense.bias from model.bert.encoder.layer.4.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.weight from model.bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.attention.output.LayerNorm.bias from model.bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.weight from model.bert.encoder.layer.4.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.intermediate.dense.bias from model.bert.encoder.layer.4.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.weight from model.bert.encoder.layer.4.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.dense.bias from model.bert.encoder.layer.4.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.weight from model.bert.encoder.layer.4.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.4.output.LayerNorm.bias from model.bert.encoder.layer.4.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.weight from model.bert.encoder.layer.5.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.query.bias from model.bert.encoder.layer.5.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.weight from model.bert.encoder.layer.5.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.key.bias from model.bert.encoder.layer.5.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.weight from model.bert.encoder.layer.5.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.self.value.bias from model.bert.encoder.layer.5.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.weight from model.bert.encoder.layer.5.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.dense.bias from model.bert.encoder.layer.5.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.weight from model.bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.attention.output.LayerNorm.bias from model.bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.weight from model.bert.encoder.layer.5.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.intermediate.dense.bias from model.bert.encoder.layer.5.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.weight from model.bert.encoder.layer.5.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.dense.bias from model.bert.encoder.layer.5.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.weight from model.bert.encoder.layer.5.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.5.output.LayerNorm.bias from model.bert.encoder.layer.5.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.weight from model.bert.encoder.layer.6.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.query.bias from model.bert.encoder.layer.6.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.weight from model.bert.encoder.layer.6.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.key.bias from model.bert.encoder.layer.6.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.weight from model.bert.encoder.layer.6.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.self.value.bias from model.bert.encoder.layer.6.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.weight from model.bert.encoder.layer.6.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.dense.bias from model.bert.encoder.layer.6.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.weight from model.bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.attention.output.LayerNorm.bias from model.bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.weight from model.bert.encoder.layer.6.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.intermediate.dense.bias from model.bert.encoder.layer.6.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.weight from model.bert.encoder.layer.6.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.dense.bias from model.bert.encoder.layer.6.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.weight from model.bert.encoder.layer.6.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.6.output.LayerNorm.bias from model.bert.encoder.layer.6.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.weight from model.bert.encoder.layer.7.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.query.bias from model.bert.encoder.layer.7.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.weight from model.bert.encoder.layer.7.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.key.bias from model.bert.encoder.layer.7.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.weight from model.bert.encoder.layer.7.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.self.value.bias from model.bert.encoder.layer.7.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.weight from model.bert.encoder.layer.7.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.dense.bias from model.bert.encoder.layer.7.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.weight from model.bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.attention.output.LayerNorm.bias from model.bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.weight from model.bert.encoder.layer.7.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.intermediate.dense.bias from model.bert.encoder.layer.7.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.weight from model.bert.encoder.layer.7.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.dense.bias from model.bert.encoder.layer.7.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.weight from model.bert.encoder.layer.7.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.7.output.LayerNorm.bias from model.bert.encoder.layer.7.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.weight from model.bert.encoder.layer.8.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.query.bias from model.bert.encoder.layer.8.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.weight from model.bert.encoder.layer.8.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.key.bias from model.bert.encoder.layer.8.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.weight from model.bert.encoder.layer.8.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.self.value.bias from model.bert.encoder.layer.8.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.weight from model.bert.encoder.layer.8.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.dense.bias from model.bert.encoder.layer.8.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.weight from model.bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.attention.output.LayerNorm.bias from model.bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.weight from model.bert.encoder.layer.8.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.intermediate.dense.bias from model.bert.encoder.layer.8.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.weight from model.bert.encoder.layer.8.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.dense.bias from model.bert.encoder.layer.8.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.weight from model.bert.encoder.layer.8.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.8.output.LayerNorm.bias from model.bert.encoder.layer.8.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.weight from model.bert.encoder.layer.9.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.query.bias from model.bert.encoder.layer.9.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.weight from model.bert.encoder.layer.9.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.key.bias from model.bert.encoder.layer.9.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.weight from model.bert.encoder.layer.9.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.self.value.bias from model.bert.encoder.layer.9.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.weight from model.bert.encoder.layer.9.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.dense.bias from model.bert.encoder.layer.9.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.weight from model.bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.attention.output.LayerNorm.bias from model.bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.weight from model.bert.encoder.layer.9.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.intermediate.dense.bias from model.bert.encoder.layer.9.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.weight from model.bert.encoder.layer.9.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.dense.bias from model.bert.encoder.layer.9.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.weight from model.bert.encoder.layer.9.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.9.output.LayerNorm.bias from model.bert.encoder.layer.9.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.weight from model.bert.encoder.layer.10.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.query.bias from model.bert.encoder.layer.10.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.weight from model.bert.encoder.layer.10.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.key.bias from model.bert.encoder.layer.10.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.weight from model.bert.encoder.layer.10.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.self.value.bias from model.bert.encoder.layer.10.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.weight from model.bert.encoder.layer.10.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.dense.bias from model.bert.encoder.layer.10.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.weight from model.bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.attention.output.LayerNorm.bias from model.bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.weight from model.bert.encoder.layer.10.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.intermediate.dense.bias from model.bert.encoder.layer.10.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.weight from model.bert.encoder.layer.10.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.dense.bias from model.bert.encoder.layer.10.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.weight from model.bert.encoder.layer.10.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.10.output.LayerNorm.bias from model.bert.encoder.layer.10.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.weight from model.bert.encoder.layer.11.attention.self.query.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.query.bias from model.bert.encoder.layer.11.attention.self.query.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.weight from model.bert.encoder.layer.11.attention.self.key.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.key.bias from model.bert.encoder.layer.11.attention.self.key.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.weight from model.bert.encoder.layer.11.attention.self.value.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.self.value.bias from model.bert.encoder.layer.11.attention.self.value.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.weight from model.bert.encoder.layer.11.attention.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.dense.bias from model.bert.encoder.layer.11.attention.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.weight from model.bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.attention.output.LayerNorm.bias from model.bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.weight from model.bert.encoder.layer.11.intermediate.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.intermediate.dense.bias from model.bert.encoder.layer.11.intermediate.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.weight from model.bert.encoder.layer.11.output.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.dense.bias from model.bert.encoder.layer.11.output.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.weight from model.bert.encoder.layer.11.output.LayerNorm.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.encoder.layer.11.output.LayerNorm.bias from model.bert.encoder.layer.11.output.LayerNorm.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.weight from model.bert.pooler.dense.weight\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCopying model.bert.pooler.dense.bias from model.bert.pooler.dense.bias\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mPretrained model loaded\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 0\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 0\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 0\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.trainers.mmf_trainer: \u001b[0m===== Model =====\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.trainers.mmf_trainer: \u001b[0mVisualBERT(\n",
            "  (model): VisualBERTForClassification(\n",
            "    (bert): VisualBERTBase(\n",
            "      (embeddings): BertVisioLinguisticEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (token_type_embeddings_visual): Embedding(2, 768)\n",
            "        (position_embeddings_visual): Embedding(512, 768)\n",
            "        (projection): Linear(in_features=2048, out_features=768, bias=True)\n",
            "      )\n",
            "      (encoder): BertEncoderJit(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayerJit(\n",
            "            (attention): BertAttentionJit(\n",
            "              (self): BertSelfAttentionJit(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Sequential(\n",
            "      (0): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (1): Linear(in_features=768, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (losses): Losses(\n",
            "    (losses): ModuleList(\n",
            "      (0): MMFLoss(\n",
            "        (loss_criterion): CrossEntropyLoss(\n",
            "          (loss_fn): CrossEntropyLoss()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.utils.general: \u001b[0mTotal Parameters: 112044290. Trained Parameters: 112044290\n",
            "\u001b[32m2021-04-27T19:17:51 | mmf.trainers.core.training_loop: \u001b[0mStarting training...\n",
            "\u001b[32m2021-04-27T19:20:55 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:20:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:21:15 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:21:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:21:22 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:21:23 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:21:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:21:43 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T19:21:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:22:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:22:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 50/3000, val/hateful_memes/cross_entropy: 0.8523, val/total_loss: 0.8523, val/hateful_memes/accuracy: 0.4019, val/hateful_memes/binary_f1: 0.5418, val/hateful_memes/roc_auc: 0.4940, num_updates: 50, epoch: 1, iterations: 50, max_updates: 3000, val_time: 51s 301ms, best_update: 50, best_iteration: 50, best_val/hateful_memes/roc_auc: 0.494044\n",
            "\u001b[32m2021-04-27T19:24:58 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:24:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:25:04 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:25:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:25:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/3000, train/hateful_memes/cross_entropy: 0.6365, train/hateful_memes/cross_entropy/avg: 0.6365, train/total_loss: 0.6365, train/total_loss/avg: 0.6365, max mem: 12854.0, experiment: run, epoch: 1, num_updates: 100, iterations: 100, max_updates: 3000, lr: 0., ups: 0.56, time: 02m 59s 583ms, time_since_start: 07m 29s 926ms, eta: 01h 47m 37s 816ms\n",
            "\u001b[32m2021-04-27T19:25:13 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:25:13 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:25:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:25:38 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T19:25:50 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:26:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:26:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 100/3000, val/hateful_memes/cross_entropy: 0.6727, val/total_loss: 0.6727, val/hateful_memes/accuracy: 0.6019, val/hateful_memes/binary_f1: 0.1365, val/hateful_memes/roc_auc: 0.5118, num_updates: 100, epoch: 1, iterations: 100, max_updates: 3000, val_time: 54s 797ms, best_update: 100, best_iteration: 100, best_val/hateful_memes/roc_auc: 0.511838\n",
            "\u001b[32m2021-04-27T19:28:57 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:28:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:29:21 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:29:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:29:27 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:29:27 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:29:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:29:47 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T19:30:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:30:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:30:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 150/3000, val/hateful_memes/cross_entropy: 0.6686, val/total_loss: 0.6686, val/hateful_memes/accuracy: 0.6278, val/hateful_memes/binary_f1: 0.0822, val/hateful_memes/roc_auc: 0.5125, num_updates: 150, epoch: 1, iterations: 150, max_updates: 3000, val_time: 52s 634ms, best_update: 150, best_iteration: 150, best_val/hateful_memes/roc_auc: 0.512529\n",
            "\u001b[32m2021-04-27T19:32:33 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:32:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:32:39 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:32:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:32:49 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/3000, train/hateful_memes/cross_entropy: 0.6365, train/hateful_memes/cross_entropy/avg: 0.6701, train/total_loss: 0.6365, train/total_loss/avg: 0.6701, max mem: 12854.0, experiment: run, epoch: 2, num_updates: 200, iterations: 200, max_updates: 3000, lr: 0., ups: 0.67, time: 02m 29s 499ms, time_since_start: 15m 05s 633ms, eta: 01h 26m 30s 616ms\n",
            "\u001b[32m2021-04-27T19:32:49 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:32:49 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:33:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:33:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:33:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:33:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 200/3000, val/hateful_memes/cross_entropy: 0.6655, val/total_loss: 0.6655, val/hateful_memes/accuracy: 0.6241, val/hateful_memes/binary_f1: 0.0645, val/hateful_memes/roc_auc: 0.5098, num_updates: 200, epoch: 2, iterations: 200, max_updates: 3000, val_time: 33s 769ms, best_update: 150, best_iteration: 150, best_val/hateful_memes/roc_auc: 0.512529\n",
            "\u001b[32m2021-04-27T19:36:09 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:36:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:36:25 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:36:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:36:30 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:36:30 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:37:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:37:07 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T19:37:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:37:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:37:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 250/3000, val/hateful_memes/cross_entropy: 0.6625, val/total_loss: 0.6625, val/hateful_memes/accuracy: 0.6296, val/hateful_memes/binary_f1: 0.1071, val/hateful_memes/roc_auc: 0.5202, num_updates: 250, epoch: 2, iterations: 250, max_updates: 3000, val_time: 01m 04s 391ms, best_update: 250, best_iteration: 250, best_val/hateful_memes/roc_auc: 0.520191\n",
            "\u001b[32m2021-04-27T19:40:26 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:40:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:40:35 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:40:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:40:50 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/3000, train/hateful_memes/cross_entropy: 0.6762, train/hateful_memes/cross_entropy/avg: 0.6721, train/total_loss: 0.6762, train/total_loss/avg: 0.6721, max mem: 12854.0, experiment: run, epoch: 2, num_updates: 300, iterations: 300, max_updates: 3000, lr: 0., ups: 0.51, time: 03m 15s 764ms, time_since_start: 23m 07s 181ms, eta: 01h 49m 14s 187ms\n",
            "\u001b[32m2021-04-27T19:40:50 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:40:50 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:40:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:41:03 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T19:41:16 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:41:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:41:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 300/3000, val/hateful_memes/cross_entropy: 0.6645, val/total_loss: 0.6645, val/hateful_memes/accuracy: 0.6278, val/hateful_memes/binary_f1: 0.0651, val/hateful_memes/roc_auc: 0.5400, num_updates: 300, epoch: 2, iterations: 300, max_updates: 3000, val_time: 47s 102ms, best_update: 300, best_iteration: 300, best_val/hateful_memes/roc_auc: 0.539985\n",
            "\u001b[32m2021-04-27T19:44:32 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:44:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:44:44 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:44:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:44:51 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:44:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:44:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:45:13 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T19:45:25 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:45:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:45:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 350/3000, val/hateful_memes/cross_entropy: 0.6709, val/total_loss: 0.6709, val/hateful_memes/accuracy: 0.6278, val/hateful_memes/binary_f1: 0.0651, val/hateful_memes/roc_auc: 0.5581, num_updates: 350, epoch: 2, iterations: 350, max_updates: 3000, val_time: 54s 450ms, best_update: 350, best_iteration: 350, best_val/hateful_memes/roc_auc: 0.558088\n",
            "\u001b[32m2021-04-27T19:47:56 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:47:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:48:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:48:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:48:17 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/3000, train/hateful_memes/cross_entropy: 0.6365, train/hateful_memes/cross_entropy/avg: 0.6625, train/total_loss: 0.6365, train/total_loss/avg: 0.6625, max mem: 12854.0, experiment: run, epoch: 3, num_updates: 400, iterations: 400, max_updates: 3000, lr: 0., ups: 0.67, time: 02m 30s 972ms, time_since_start: 30m 33s 349ms, eta: 01h 21m 07s 341ms\n",
            "\u001b[32m2021-04-27T19:48:17 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:48:17 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:48:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:48:35 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T19:48:52 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:49:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:49:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 400/3000, val/hateful_memes/cross_entropy: 0.6939, val/total_loss: 0.6939, val/hateful_memes/accuracy: 0.6333, val/hateful_memes/binary_f1: 0.1316, val/hateful_memes/roc_auc: 0.5611, num_updates: 400, epoch: 3, iterations: 400, max_updates: 3000, val_time: 52s 039ms, best_update: 400, best_iteration: 400, best_val/hateful_memes/roc_auc: 0.561074\n",
            "\u001b[32m2021-04-27T19:51:49 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:51:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:52:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:52:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:52:23 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:52:23 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:52:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:52:38 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T19:52:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:53:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:53:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 450/3000, val/hateful_memes/cross_entropy: 0.6771, val/total_loss: 0.6771, val/hateful_memes/accuracy: 0.6204, val/hateful_memes/binary_f1: 0.2146, val/hateful_memes/roc_auc: 0.5734, num_updates: 450, epoch: 3, iterations: 450, max_updates: 3000, val_time: 45s 006ms, best_update: 450, best_iteration: 450, best_val/hateful_memes/roc_auc: 0.573368\n",
            "\u001b[32m2021-04-27T19:55:55 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:55:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:56:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:56:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:56:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/3000, train/hateful_memes/cross_entropy: 0.6762, train/hateful_memes/cross_entropy/avg: 0.6659, train/total_loss: 0.6762, train/total_loss/avg: 0.6659, max mem: 12854.0, experiment: run, epoch: 3, num_updates: 500, iterations: 500, max_updates: 3000, lr: 0.00001, ups: 0.53, time: 03m 10s 928ms, time_since_start: 38m 35s 798ms, eta: 01h 38m 38s 775ms\n",
            "\u001b[32m2021-04-27T19:56:19 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:56:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:56:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:56:31 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:56:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:56:47 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 500/3000, val/hateful_memes/cross_entropy: 0.6942, val/total_loss: 0.6942, val/hateful_memes/accuracy: 0.6241, val/hateful_memes/binary_f1: 0.3473, val/hateful_memes/roc_auc: 0.5732, num_updates: 500, epoch: 3, iterations: 500, max_updates: 3000, val_time: 27s 563ms, best_update: 450, best_iteration: 450, best_val/hateful_memes/roc_auc: 0.573368\n",
            "\u001b[32m2021-04-27T19:58:57 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T19:58:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:59:11 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T19:59:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T19:59:25 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T19:59:25 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T19:59:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T19:59:39 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T19:59:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:00:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:00:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 550/3000, val/hateful_memes/cross_entropy: 0.7220, val/total_loss: 0.7220, val/hateful_memes/accuracy: 0.6148, val/hateful_memes/binary_f1: 0.2464, val/hateful_memes/roc_auc: 0.5875, num_updates: 550, epoch: 4, iterations: 550, max_updates: 3000, val_time: 44s 363ms, best_update: 550, best_iteration: 550, best_val/hateful_memes/roc_auc: 0.587485\n",
            "\u001b[32m2021-04-27T20:02:48 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:02:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:03:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:03:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:03:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/3000, train/hateful_memes/cross_entropy: 0.6365, train/hateful_memes/cross_entropy/avg: 0.6391, train/total_loss: 0.6365, train/total_loss/avg: 0.6391, max mem: 12854.0, experiment: run, epoch: 4, num_updates: 600, iterations: 600, max_updates: 3000, lr: 0.00001, ups: 0.53, time: 03m 08s 244ms, time_since_start: 45m 34s 667ms, eta: 01h 33m 22s 143ms\n",
            "\u001b[32m2021-04-27T20:03:18 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:03:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:03:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:03:36 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:03:51 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:04:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:04:09 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 600/3000, val/hateful_memes/cross_entropy: 0.6822, val/total_loss: 0.6822, val/hateful_memes/accuracy: 0.6222, val/hateful_memes/binary_f1: 0.4000, val/hateful_memes/roc_auc: 0.6056, num_updates: 600, epoch: 4, iterations: 600, max_updates: 3000, val_time: 50s 873ms, best_update: 600, best_iteration: 600, best_val/hateful_memes/roc_auc: 0.605574\n",
            "\u001b[32m2021-04-27T20:06:49 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:06:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:07:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:07:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:07:17 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:07:17 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:07:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:07:31 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:07:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:08:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:08:00 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 650/3000, val/hateful_memes/cross_entropy: 0.7450, val/total_loss: 0.7450, val/hateful_memes/accuracy: 0.6407, val/hateful_memes/binary_f1: 0.2240, val/hateful_memes/roc_auc: 0.6181, num_updates: 650, epoch: 4, iterations: 650, max_updates: 3000, val_time: 42s 950ms, best_update: 650, best_iteration: 650, best_val/hateful_memes/roc_auc: 0.618103\n",
            "\u001b[32m2021-04-27T20:10:55 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:10:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:11:07 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:11:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:11:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/3000, train/hateful_memes/cross_entropy: 0.6365, train/hateful_memes/cross_entropy/avg: 0.6279, train/total_loss: 0.6365, train/total_loss/avg: 0.6279, max mem: 12854.0, experiment: run, epoch: 4, num_updates: 700, iterations: 700, max_updates: 3000, lr: 0.00001, ups: 0.51, time: 03m 18s 932ms, time_since_start: 53m 35s 675ms, eta: 01h 34m 33s 563ms\n",
            "\u001b[32m2021-04-27T20:11:19 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:11:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:11:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:11:35 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:11:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:12:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:12:05 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 700/3000, val/hateful_memes/cross_entropy: 0.6840, val/total_loss: 0.6840, val/hateful_memes/accuracy: 0.6259, val/hateful_memes/binary_f1: 0.4628, val/hateful_memes/roc_auc: 0.6333, num_updates: 700, epoch: 4, iterations: 700, max_updates: 3000, val_time: 46s 224ms, best_update: 700, best_iteration: 700, best_val/hateful_memes/roc_auc: 0.633309\n",
            "\u001b[32m2021-04-27T20:14:05 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:14:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:14:10 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:14:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:14:22 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:14:22 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:14:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:14:37 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:14:58 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:15:11 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:15:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 750/3000, val/hateful_memes/cross_entropy: 0.7627, val/total_loss: 0.7627, val/hateful_memes/accuracy: 0.6444, val/hateful_memes/binary_f1: 0.3043, val/hateful_memes/roc_auc: 0.6465, num_updates: 750, epoch: 5, iterations: 750, max_updates: 3000, val_time: 48s 741ms, best_update: 750, best_iteration: 750, best_val/hateful_memes/roc_auc: 0.646515\n",
            "\u001b[32m2021-04-27T20:17:46 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:17:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:18:05 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:18:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:18:13 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/3000, train/hateful_memes/cross_entropy: 0.6336, train/hateful_memes/cross_entropy/avg: 0.6278, train/total_loss: 0.6336, train/total_loss/avg: 0.6278, max mem: 12854.0, experiment: run, epoch: 5, num_updates: 800, iterations: 800, max_updates: 3000, lr: 0.00001, ups: 0.55, time: 03m 01s 893ms, time_since_start: 01h 29s 747ms, eta: 01h 22m 42s 058ms\n",
            "\u001b[32m2021-04-27T20:18:13 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:18:13 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:18:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:18:32 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:18:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:18:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 800/3000, val/hateful_memes/cross_entropy: 0.7704, val/total_loss: 0.7704, val/hateful_memes/accuracy: 0.6370, val/hateful_memes/binary_f1: 0.3000, val/hateful_memes/roc_auc: 0.6361, num_updates: 800, epoch: 5, iterations: 800, max_updates: 3000, val_time: 38s 083ms, best_update: 750, best_iteration: 750, best_val/hateful_memes/roc_auc: 0.646515\n",
            "\u001b[32m2021-04-27T20:21:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:21:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:21:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:22:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:22:00 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:22:00 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:22:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:22:21 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:22:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:22:55 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:22:55 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 850/3000, val/hateful_memes/cross_entropy: 0.7523, val/total_loss: 0.7523, val/hateful_memes/accuracy: 0.6519, val/hateful_memes/binary_f1: 0.3380, val/hateful_memes/roc_auc: 0.6532, num_updates: 850, epoch: 5, iterations: 850, max_updates: 3000, val_time: 55s 124ms, best_update: 850, best_iteration: 850, best_val/hateful_memes/roc_auc: 0.653206\n",
            "\u001b[32m2021-04-27T20:25:28 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:25:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:25:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:25:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:25:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/3000, train/hateful_memes/cross_entropy: 0.6336, train/hateful_memes/cross_entropy/avg: 0.6043, train/total_loss: 0.6336, train/total_loss/avg: 0.6043, max mem: 12854.0, experiment: run, epoch: 6, num_updates: 900, iterations: 900, max_updates: 3000, lr: 0.00001, ups: 0.59, time: 02m 50s 983ms, time_since_start: 01h 08m 02s 493ms, eta: 01h 14m 12s 423ms\n",
            "\u001b[32m2021-04-27T20:25:46 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:25:46 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:25:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:26:05 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:26:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:26:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:26:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 900/3000, val/hateful_memes/cross_entropy: 0.8036, val/total_loss: 0.8036, val/hateful_memes/accuracy: 0.6519, val/hateful_memes/binary_f1: 0.3286, val/hateful_memes/roc_auc: 0.6704, num_updates: 900, epoch: 6, iterations: 900, max_updates: 3000, val_time: 51s 839ms, best_update: 900, best_iteration: 900, best_val/hateful_memes/roc_auc: 0.670397\n",
            "\u001b[32m2021-04-27T20:29:09 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:29:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:29:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:29:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:29:46 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:29:46 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:29:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:30:00 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:30:19 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:30:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:30:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 950/3000, val/hateful_memes/cross_entropy: 0.7925, val/total_loss: 0.7925, val/hateful_memes/accuracy: 0.6574, val/hateful_memes/binary_f1: 0.4411, val/hateful_memes/roc_auc: 0.6751, num_updates: 950, epoch: 6, iterations: 950, max_updates: 3000, val_time: 49s 391ms, best_update: 950, best_iteration: 950, best_val/hateful_memes/roc_auc: 0.675147\n",
            "\u001b[32m2021-04-27T20:33:19 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:33:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:33:28 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:33:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:33:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/3000, train/hateful_memes/cross_entropy: 0.6266, train/hateful_memes/cross_entropy/avg: 0.5826, train/total_loss: 0.6266, train/total_loss/avg: 0.5826, max mem: 12854.0, experiment: run, epoch: 6, num_updates: 1000, iterations: 1000, max_updates: 3000, lr: 0.00001, ups: 0.52, time: 03m 11s 282ms, time_since_start: 01h 16m 03s 086ms, eta: 01h 19m 03s 795ms\n",
            "\u001b[32m2021-04-27T20:33:46 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:33:46 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:33:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:33:59 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:34:12 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:34:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:34:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1000/3000, val/hateful_memes/cross_entropy: 0.7468, val/total_loss: 0.7468, val/hateful_memes/accuracy: 0.6500, val/hateful_memes/binary_f1: 0.4933, val/hateful_memes/roc_auc: 0.6822, num_updates: 1000, epoch: 6, iterations: 1000, max_updates: 3000, val_time: 40s 240ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.682235\n",
            "\u001b[32m2021-04-27T20:37:20 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:37:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:37:26 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:37:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:37:45 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:37:45 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:37:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:38:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:38:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:38:12 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1050/3000, val/hateful_memes/cross_entropy: 0.7709, val/total_loss: 0.7709, val/hateful_memes/accuracy: 0.6500, val/hateful_memes/binary_f1: 0.4038, val/hateful_memes/roc_auc: 0.6740, num_updates: 1050, epoch: 6, iterations: 1050, max_updates: 3000, val_time: 27s 436ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.682235\n",
            "\u001b[32m2021-04-27T20:40:04 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:40:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:40:21 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:40:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:40:29 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/3000, train/hateful_memes/cross_entropy: 0.6266, train/hateful_memes/cross_entropy/avg: 0.5542, train/total_loss: 0.6266, train/total_loss/avg: 0.5542, max mem: 12854.0, experiment: run, epoch: 7, num_updates: 1100, iterations: 1100, max_updates: 3000, lr: 0.00001, ups: 0.74, time: 02m 16s 613ms, time_since_start: 01h 22m 45s 622ms, eta: 53m 38s 614ms\n",
            "\u001b[32m2021-04-27T20:40:29 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:40:29 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:40:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:40:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:40:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:40:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1100/3000, val/hateful_memes/cross_entropy: 0.9684, val/total_loss: 0.9684, val/hateful_memes/accuracy: 0.6574, val/hateful_memes/binary_f1: 0.3416, val/hateful_memes/roc_auc: 0.6818, num_updates: 1100, epoch: 7, iterations: 1100, max_updates: 3000, val_time: 27s 720ms, best_update: 1000, best_iteration: 1000, best_val/hateful_memes/roc_auc: 0.682235\n",
            "\u001b[32m2021-04-27T20:43:31 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:43:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:43:55 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:44:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:44:03 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:44:03 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:44:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:44:21 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:44:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:44:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:44:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1150/3000, val/hateful_memes/cross_entropy: 0.7955, val/total_loss: 0.7955, val/hateful_memes/accuracy: 0.6519, val/hateful_memes/binary_f1: 0.3856, val/hateful_memes/roc_auc: 0.6896, num_updates: 1150, epoch: 7, iterations: 1150, max_updates: 3000, val_time: 48s 521ms, best_update: 1150, best_iteration: 1150, best_val/hateful_memes/roc_auc: 0.689647\n",
            "\u001b[32m2021-04-27T20:47:49 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:47:49 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:47:55 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:48:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:48:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/3000, train/hateful_memes/cross_entropy: 0.5607, train/hateful_memes/cross_entropy/avg: 0.5401, train/total_loss: 0.5607, train/total_loss/avg: 0.5401, max mem: 12854.0, experiment: run, epoch: 7, num_updates: 1200, iterations: 1200, max_updates: 3000, lr: 0.00001, ups: 0.50, time: 03m 21s 951ms, time_since_start: 01h 30m 30s 442ms, eta: 01h 15m 07s 547ms\n",
            "\u001b[32m2021-04-27T20:48:14 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:48:14 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:48:20 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:48:25 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:48:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:48:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1200/3000, val/hateful_memes/cross_entropy: 0.8178, val/total_loss: 0.8178, val/hateful_memes/accuracy: 0.6667, val/hateful_memes/binary_f1: 0.3836, val/hateful_memes/roc_auc: 0.6846, num_updates: 1200, epoch: 7, iterations: 1200, max_updates: 3000, val_time: 24s 277ms, best_update: 1150, best_iteration: 1150, best_val/hateful_memes/roc_auc: 0.689647\n",
            "\u001b[32m2021-04-27T20:51:19 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:51:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:51:34 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:51:45 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:51:45 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:51:45 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:51:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:52:03 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:52:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:52:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1250/3000, val/hateful_memes/cross_entropy: 0.6935, val/total_loss: 0.6935, val/hateful_memes/accuracy: 0.6556, val/hateful_memes/binary_f1: 0.5105, val/hateful_memes/roc_auc: 0.6770, num_updates: 1250, epoch: 8, iterations: 1250, max_updates: 3000, val_time: 32s 951ms, best_update: 1150, best_iteration: 1150, best_val/hateful_memes/roc_auc: 0.689647\n",
            "\u001b[32m2021-04-27T20:54:34 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:54:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:54:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:54:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:54:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/3000, train/hateful_memes/cross_entropy: 0.5607, train/hateful_memes/cross_entropy/avg: 0.5118, train/total_loss: 0.5607, train/total_loss/avg: 0.5118, max mem: 12854.0, experiment: run, epoch: 8, num_updates: 1300, iterations: 1300, max_updates: 3000, lr: 0.00001, ups: 0.62, time: 02m 40s 728ms, time_since_start: 01h 37m 15s 658ms, eta: 56m 28s 161ms\n",
            "\u001b[32m2021-04-27T20:54:59 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:54:59 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:55:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:55:24 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:55:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:55:36 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1300/3000, val/hateful_memes/cross_entropy: 0.9066, val/total_loss: 0.9066, val/hateful_memes/accuracy: 0.6630, val/hateful_memes/binary_f1: 0.4383, val/hateful_memes/roc_auc: 0.6870, num_updates: 1300, epoch: 8, iterations: 1300, max_updates: 3000, val_time: 37s 505ms, best_update: 1150, best_iteration: 1150, best_val/hateful_memes/roc_auc: 0.689647\n",
            "\u001b[32m2021-04-27T20:58:18 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T20:58:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:58:43 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:58:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:58:51 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T20:58:51 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T20:59:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T20:59:16 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T20:59:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T20:59:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T20:59:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1350/3000, val/hateful_memes/cross_entropy: 0.8810, val/total_loss: 0.8810, val/hateful_memes/accuracy: 0.6685, val/hateful_memes/binary_f1: 0.3891, val/hateful_memes/roc_auc: 0.6899, num_updates: 1350, epoch: 8, iterations: 1350, max_updates: 3000, val_time: 55s 230ms, best_update: 1350, best_iteration: 1350, best_val/hateful_memes/roc_auc: 0.689868\n",
            "\u001b[32m2021-04-27T21:02:42 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:02:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:03:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:03:11 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:03:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/3000, train/hateful_memes/cross_entropy: 0.5054, train/hateful_memes/cross_entropy/avg: 0.4954, train/total_loss: 0.5054, train/total_loss/avg: 0.4954, max mem: 12854.0, experiment: run, epoch: 8, num_updates: 1400, iterations: 1400, max_updates: 3000, lr: 0.00001, ups: 0.49, time: 03m 24s 488ms, time_since_start: 01h 45m 27s 595ms, eta: 01h 07m 37s 061ms\n",
            "\u001b[32m2021-04-27T21:03:11 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:03:11 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:03:17 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:03:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:03:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:03:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1400/3000, val/hateful_memes/cross_entropy: 0.9057, val/total_loss: 0.9057, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4351, val/hateful_memes/roc_auc: 0.6890, num_updates: 1400, epoch: 8, iterations: 1400, max_updates: 3000, val_time: 29s 096ms, best_update: 1350, best_iteration: 1350, best_val/hateful_memes/roc_auc: 0.689868\n",
            "\u001b[32m2021-04-27T21:05:37 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:05:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:05:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:06:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:06:00 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:06:00 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:06:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:06:16 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T21:06:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:06:52 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:06:52 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1450/3000, val/hateful_memes/cross_entropy: 1.0143, val/total_loss: 1.0143, val/hateful_memes/accuracy: 0.6648, val/hateful_memes/binary_f1: 0.4597, val/hateful_memes/roc_auc: 0.6997, num_updates: 1450, epoch: 9, iterations: 1450, max_updates: 3000, val_time: 51s 910ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:09:33 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:09:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:09:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:09:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:09:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/3000, train/hateful_memes/cross_entropy: 0.5054, train/hateful_memes/cross_entropy/avg: 0.4702, train/total_loss: 0.5054, train/total_loss/avg: 0.4702, max mem: 12854.0, experiment: run, epoch: 9, num_updates: 1500, iterations: 1500, max_updates: 3000, lr: 0.00001, ups: 0.54, time: 03m 05s 944ms, time_since_start: 01h 52m 14s 438ms, eta: 57m 38s 565ms\n",
            "\u001b[32m2021-04-27T21:09:58 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:09:58 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:10:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:10:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:10:22 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:10:22 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1500/3000, val/hateful_memes/cross_entropy: 0.9514, val/total_loss: 0.9514, val/hateful_memes/accuracy: 0.6611, val/hateful_memes/binary_f1: 0.4116, val/hateful_memes/roc_auc: 0.6867, num_updates: 1500, epoch: 9, iterations: 1500, max_updates: 3000, val_time: 24s 197ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:13:14 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:13:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:13:36 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:13:44 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:13:44 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:13:44 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:13:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:14:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:14:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:14:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1550/3000, val/hateful_memes/cross_entropy: 1.0515, val/total_loss: 1.0515, val/hateful_memes/accuracy: 0.6685, val/hateful_memes/binary_f1: 0.4013, val/hateful_memes/roc_auc: 0.6994, num_updates: 1550, epoch: 9, iterations: 1550, max_updates: 3000, val_time: 35s 435ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:17:09 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:17:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:17:15 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:17:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:17:28 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/3000, train/hateful_memes/cross_entropy: 0.4167, train/hateful_memes/cross_entropy/avg: 0.4535, train/total_loss: 0.4167, train/total_loss/avg: 0.4535, max mem: 12854.0, experiment: run, epoch: 9, num_updates: 1600, iterations: 1600, max_updates: 3000, lr: 0.00001, ups: 0.53, time: 03m 08s 800ms, time_since_start: 01h 59m 44s 885ms, eta: 54m 37s 581ms\n",
            "\u001b[32m2021-04-27T21:17:28 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:17:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:17:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:17:46 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:18:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:18:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1600/3000, val/hateful_memes/cross_entropy: 1.0744, val/total_loss: 1.0744, val/hateful_memes/accuracy: 0.6907, val/hateful_memes/binary_f1: 0.4630, val/hateful_memes/roc_auc: 0.6979, num_updates: 1600, epoch: 9, iterations: 1600, max_updates: 3000, val_time: 35s 342ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:20:10 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:20:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:20:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:20:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:20:36 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:20:36 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:20:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:20:50 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:21:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:21:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1650/3000, val/hateful_memes/cross_entropy: 1.1492, val/total_loss: 1.1492, val/hateful_memes/accuracy: 0.6833, val/hateful_memes/binary_f1: 0.4606, val/hateful_memes/roc_auc: 0.6971, num_updates: 1650, epoch: 10, iterations: 1650, max_updates: 3000, val_time: 32s 473ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:23:50 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:23:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:24:14 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:24:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:24:23 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/3000, train/hateful_memes/cross_entropy: 0.4167, train/hateful_memes/cross_entropy/avg: 0.4318, train/total_loss: 0.4167, train/total_loss/avg: 0.4318, max mem: 12854.0, experiment: run, epoch: 10, num_updates: 1700, iterations: 1700, max_updates: 3000, lr: 0.00001, ups: 0.52, time: 03m 14s 883ms, time_since_start: 02h 06m 39s 715ms, eta: 52m 21s 530ms\n",
            "\u001b[32m2021-04-27T21:24:23 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:24:23 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:24:31 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:24:37 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:24:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:24:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1700/3000, val/hateful_memes/cross_entropy: 1.1857, val/total_loss: 1.1857, val/hateful_memes/accuracy: 0.6704, val/hateful_memes/binary_f1: 0.4106, val/hateful_memes/roc_auc: 0.6912, num_updates: 1700, epoch: 10, iterations: 1700, max_updates: 3000, val_time: 33s 958ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:27:51 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:27:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:28:14 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:28:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:28:28 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:28:28 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:28:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:28:44 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:28:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:28:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1750/3000, val/hateful_memes/cross_entropy: 1.1232, val/total_loss: 1.1232, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.4014, val/hateful_memes/roc_auc: 0.6911, num_updates: 1750, epoch: 10, iterations: 1750, max_updates: 3000, val_time: 29s 505ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:31:04 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:31:04 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:31:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:31:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:31:26 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/3000, train/hateful_memes/cross_entropy: 0.3869, train/hateful_memes/cross_entropy/avg: 0.4169, train/total_loss: 0.3869, train/total_loss/avg: 0.4169, max mem: 12854.0, experiment: run, epoch: 11, num_updates: 1800, iterations: 1800, max_updates: 3000, lr: 0.00001, ups: 0.68, time: 02m 28s 934ms, time_since_start: 02h 13m 42s 854ms, eta: 36m 56s 150ms\n",
            "\u001b[32m2021-04-27T21:31:26 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:31:26 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:31:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:31:42 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:32:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:32:03 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1800/3000, val/hateful_memes/cross_entropy: 1.1944, val/total_loss: 1.1944, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4620, val/hateful_memes/roc_auc: 0.6985, num_updates: 1800, epoch: 11, iterations: 1800, max_updates: 3000, val_time: 36s 643ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:34:33 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:34:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:34:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:35:01 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:35:01 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:35:01 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:35:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:35:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:35:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:35:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1850/3000, val/hateful_memes/cross_entropy: 1.1990, val/total_loss: 1.1990, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4587, val/hateful_memes/roc_auc: 0.6969, num_updates: 1850, epoch: 11, iterations: 1850, max_updates: 3000, val_time: 30s 492ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:38:29 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:38:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:38:51 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:38:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:38:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/3000, train/hateful_memes/cross_entropy: 0.3869, train/hateful_memes/cross_entropy/avg: 0.4027, train/total_loss: 0.3869, train/total_loss/avg: 0.4027, max mem: 12854.0, experiment: run, epoch: 11, num_updates: 1900, iterations: 1900, max_updates: 3000, lr: 0.00001, ups: 0.49, time: 03m 25s 911ms, time_since_start: 02h 21m 14s 325ms, eta: 46m 48s 626ms\n",
            "\u001b[32m2021-04-27T21:38:58 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:38:58 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:39:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:39:26 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:39:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:39:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1900/3000, val/hateful_memes/cross_entropy: 1.3609, val/total_loss: 1.3609, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4122, val/hateful_memes/roc_auc: 0.6821, num_updates: 1900, epoch: 11, iterations: 1900, max_updates: 3000, val_time: 41s 537ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:42:35 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:42:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:42:56 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:43:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:43:08 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:43:08 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:43:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:43:23 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:43:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:43:37 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 1950/3000, val/hateful_memes/cross_entropy: 1.1867, val/total_loss: 1.1867, val/hateful_memes/accuracy: 0.6796, val/hateful_memes/binary_f1: 0.5234, val/hateful_memes/roc_auc: 0.6980, num_updates: 1950, epoch: 11, iterations: 1950, max_updates: 3000, val_time: 28s 604ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:45:33 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:45:33 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:45:51 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:45:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:45:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/3000, train/hateful_memes/cross_entropy: 0.3854, train/hateful_memes/cross_entropy/avg: 0.3879, train/total_loss: 0.3854, train/total_loss/avg: 0.3879, max mem: 12854.0, experiment: run, epoch: 12, num_updates: 2000, iterations: 2000, max_updates: 3000, lr: 0.00001, ups: 0.71, time: 02m 20s 399ms, time_since_start: 02h 28m 14s 114ms, eta: 29m 953ms\n",
            "\u001b[32m2021-04-27T21:45:57 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:45:57 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:46:02 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:46:13 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:46:34 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:46:34 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2000/3000, val/hateful_memes/cross_entropy: 1.3957, val/total_loss: 1.3957, val/hateful_memes/accuracy: 0.6778, val/hateful_memes/binary_f1: 0.4759, val/hateful_memes/roc_auc: 0.6905, num_updates: 2000, epoch: 12, iterations: 2000, max_updates: 3000, val_time: 36s 334ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:49:11 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:49:11 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:49:35 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:49:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:49:43 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:49:43 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:49:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:50:00 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:50:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:50:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2050/3000, val/hateful_memes/cross_entropy: 1.3867, val/total_loss: 1.3867, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.4248, val/hateful_memes/roc_auc: 0.6943, num_updates: 2050, epoch: 12, iterations: 2050, max_updates: 3000, val_time: 35s 203ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:53:08 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:53:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:53:33 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:53:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:53:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/3000, train/hateful_memes/cross_entropy: 0.2814, train/hateful_memes/cross_entropy/avg: 0.3711, train/total_loss: 0.2814, train/total_loss/avg: 0.3711, max mem: 12854.0, experiment: run, epoch: 12, num_updates: 2100, iterations: 2100, max_updates: 3000, lr: 0.00001, ups: 0.50, time: 03m 20s 878ms, time_since_start: 02h 35m 56s 288ms, eta: 37m 21s 803ms\n",
            "\u001b[32m2021-04-27T21:53:40 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:53:40 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:54:03 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:54:09 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:54:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:54:21 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2100/3000, val/hateful_memes/cross_entropy: 1.3193, val/total_loss: 1.3193, val/hateful_memes/accuracy: 0.6759, val/hateful_memes/binary_f1: 0.4373, val/hateful_memes/roc_auc: 0.6958, num_updates: 2100, epoch: 12, iterations: 2100, max_updates: 3000, val_time: 41s 582ms, best_update: 1450, best_iteration: 1450, best_val/hateful_memes/roc_auc: 0.699691\n",
            "\u001b[32m2021-04-27T21:56:40 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T21:56:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:56:54 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:57:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:57:06 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T21:57:06 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T21:57:12 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T21:57:25 | mmf.utils.checkpoint: \u001b[0mSaving best checkpoint\n",
            "\u001b[32m2021-04-27T21:57:38 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T21:57:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T21:57:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2150/3000, val/hateful_memes/cross_entropy: 1.3453, val/total_loss: 1.3453, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.4430, val/hateful_memes/roc_auc: 0.7052, num_updates: 2150, epoch: 13, iterations: 2150, max_updates: 3000, val_time: 51s 989ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:00:40 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:00:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:01:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:01:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:01:14 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/3000, train/hateful_memes/cross_entropy: 0.2705, train/hateful_memes/cross_entropy/avg: 0.3572, train/total_loss: 0.2705, train/total_loss/avg: 0.3572, max mem: 12854.0, experiment: run, epoch: 13, num_updates: 2200, iterations: 2200, max_updates: 3000, lr: 0.00001, ups: 0.51, time: 03m 16s 398ms, time_since_start: 02h 43m 31s 269ms, eta: 32m 28s 269ms\n",
            "\u001b[32m2021-04-27T22:01:14 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:01:15 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:01:19 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:01:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:01:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:01:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2200/3000, val/hateful_memes/cross_entropy: 1.5943, val/total_loss: 1.5943, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.3701, val/hateful_memes/roc_auc: 0.6832, num_updates: 2200, epoch: 13, iterations: 2200, max_updates: 3000, val_time: 33s 752ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:04:35 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:04:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:05:01 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:05:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:05:08 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:05:08 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:05:15 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:05:27 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:05:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:05:40 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2250/3000, val/hateful_memes/cross_entropy: 1.4557, val/total_loss: 1.4557, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4486, val/hateful_memes/roc_auc: 0.7020, num_updates: 2250, epoch: 13, iterations: 2250, max_updates: 3000, val_time: 31s 587ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:08:40 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:08:40 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:09:02 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:09:11 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:09:11 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/3000, train/hateful_memes/cross_entropy: 0.2028, train/hateful_memes/cross_entropy/avg: 0.3451, train/total_loss: 0.2028, train/total_loss/avg: 0.3451, max mem: 12854.0, experiment: run, epoch: 13, num_updates: 2300, iterations: 2300, max_updates: 3000, lr: 0.00001, ups: 0.48, time: 03m 30s 541ms, time_since_start: 02h 51m 27s 276ms, eta: 30m 27s 502ms\n",
            "\u001b[32m2021-04-27T22:09:11 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:09:11 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:09:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:09:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:09:48 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:09:48 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2300/3000, val/hateful_memes/cross_entropy: 1.4535, val/total_loss: 1.4535, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4748, val/hateful_memes/roc_auc: 0.6941, num_updates: 2300, epoch: 13, iterations: 2300, max_updates: 3000, val_time: 37s 068ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:11:37 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:11:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:11:51 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:11:56 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:11:56 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:11:56 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:12:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:12:18 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:12:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:12:32 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2350/3000, val/hateful_memes/cross_entropy: 1.6036, val/total_loss: 1.6036, val/hateful_memes/accuracy: 0.6796, val/hateful_memes/binary_f1: 0.4252, val/hateful_memes/roc_auc: 0.6890, num_updates: 2350, epoch: 14, iterations: 2350, max_updates: 3000, val_time: 35s 282ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:15:09 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:15:09 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:15:32 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:15:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:15:41 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/3000, train/hateful_memes/cross_entropy: 0.1721, train/hateful_memes/cross_entropy/avg: 0.3331, train/total_loss: 0.1721, train/total_loss/avg: 0.3331, max mem: 12854.0, experiment: run, epoch: 14, num_updates: 2400, iterations: 2400, max_updates: 3000, lr: 0.00001, ups: 0.53, time: 03m 09s 320ms, time_since_start: 02h 57m 57s 824ms, eta: 23m 28s 548ms\n",
            "\u001b[32m2021-04-27T22:15:41 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:15:41 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:15:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:15:57 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:16:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:16:10 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2400/3000, val/hateful_memes/cross_entropy: 1.5057, val/total_loss: 1.5057, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4819, val/hateful_memes/roc_auc: 0.6865, num_updates: 2400, epoch: 14, iterations: 2400, max_updates: 3000, val_time: 28s 971ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:19:06 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:19:06 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:19:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:19:37 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:19:37 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:19:37 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:20:00 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:20:06 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:20:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:20:18 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2450/3000, val/hateful_memes/cross_entropy: 1.6275, val/total_loss: 1.6275, val/hateful_memes/accuracy: 0.6796, val/hateful_memes/binary_f1: 0.3972, val/hateful_memes/roc_auc: 0.6797, num_updates: 2450, epoch: 14, iterations: 2450, max_updates: 3000, val_time: 40s 658ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:22:50 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:22:50 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:23:03 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:23:16 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:23:16 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/3000, train/hateful_memes/cross_entropy: 0.1636, train/hateful_memes/cross_entropy/avg: 0.3224, train/total_loss: 0.1636, train/total_loss/avg: 0.3224, max mem: 12854.0, experiment: run, epoch: 15, num_updates: 2500, iterations: 2500, max_updates: 3000, lr: 0.00001, ups: 0.56, time: 02m 58s 203ms, time_since_start: 03h 05m 32s 766ms, eta: 18m 24s 860ms\n",
            "\u001b[32m2021-04-27T22:23:16 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:23:16 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:23:21 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:23:31 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:23:46 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:23:46 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2500/3000, val/hateful_memes/cross_entropy: 1.6877, val/total_loss: 1.6877, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.3875, val/hateful_memes/roc_auc: 0.6774, num_updates: 2500, epoch: 15, iterations: 2500, max_updates: 3000, val_time: 29s 953ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:26:05 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:26:05 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:26:25 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:26:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:26:30 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:26:30 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:26:36 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:26:42 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:26:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:26:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2550/3000, val/hateful_memes/cross_entropy: 1.4361, val/total_loss: 1.4361, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4925, val/hateful_memes/roc_auc: 0.6913, num_updates: 2550, epoch: 15, iterations: 2550, max_updates: 3000, val_time: 28s 296ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:29:47 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:29:47 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:30:11 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:30:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:30:24 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/3000, train/hateful_memes/cross_entropy: 0.1485, train/hateful_memes/cross_entropy/avg: 0.3106, train/total_loss: 0.1485, train/total_loss/avg: 0.3106, max mem: 12854.0, experiment: run, epoch: 15, num_updates: 2600, iterations: 2600, max_updates: 3000, lr: 0.00001, ups: 0.49, time: 03m 25s 032ms, time_since_start: 03h 12m 40s 469ms, eta: 16m 56s 961ms\n",
            "\u001b[32m2021-04-27T22:30:24 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:30:24 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:30:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:30:48 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:30:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:30:58 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2600/3000, val/hateful_memes/cross_entropy: 1.7104, val/total_loss: 1.7104, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4333, val/hateful_memes/roc_auc: 0.6827, num_updates: 2600, epoch: 15, iterations: 2600, max_updates: 3000, val_time: 34s 300ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:33:54 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:33:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:34:17 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:34:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:34:27 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:34:27 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:34:32 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:34:45 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:34:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:34:59 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2650/3000, val/hateful_memes/cross_entropy: 1.7528, val/total_loss: 1.7528, val/hateful_memes/accuracy: 0.6815, val/hateful_memes/binary_f1: 0.4267, val/hateful_memes/roc_auc: 0.6847, num_updates: 2650, epoch: 15, iterations: 2650, max_updates: 3000, val_time: 32s 128ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:36:57 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:36:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:37:08 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:37:18 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:37:19 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/3000, train/hateful_memes/cross_entropy: 0.1179, train/hateful_memes/cross_entropy/avg: 0.3016, train/total_loss: 0.1179, train/total_loss/avg: 0.3016, max mem: 12854.0, experiment: run, epoch: 16, num_updates: 2700, iterations: 2700, max_updates: 3000, lr: 0.00001, ups: 0.71, time: 02m 20s 094ms, time_since_start: 03h 19m 35s 660ms, eta: 08m 41s 150ms\n",
            "\u001b[32m2021-04-27T22:37:19 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:37:19 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:37:25 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:37:37 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:37:51 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:37:51 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2700/3000, val/hateful_memes/cross_entropy: 1.5199, val/total_loss: 1.5199, val/hateful_memes/accuracy: 0.6722, val/hateful_memes/binary_f1: 0.4272, val/hateful_memes/roc_auc: 0.6979, num_updates: 2700, epoch: 16, iterations: 2700, max_updates: 3000, val_time: 32s 016ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:40:28 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:40:28 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:40:51 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:40:58 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:40:58 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:40:58 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:41:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:41:14 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:41:35 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:41:35 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2750/3000, val/hateful_memes/cross_entropy: 1.6933, val/total_loss: 1.6933, val/hateful_memes/accuracy: 0.6889, val/hateful_memes/binary_f1: 0.4717, val/hateful_memes/roc_auc: 0.6868, num_updates: 2750, epoch: 16, iterations: 2750, max_updates: 3000, val_time: 37s 027ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:44:23 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:44:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:44:49 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:44:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:44:57 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/3000, train/hateful_memes/cross_entropy: 0.1058, train/hateful_memes/cross_entropy/avg: 0.2925, train/total_loss: 0.1058, train/total_loss/avg: 0.2925, max mem: 12854.0, experiment: run, epoch: 16, num_updates: 2800, iterations: 2800, max_updates: 3000, lr: 0.00001, ups: 0.50, time: 03m 21s 908ms, time_since_start: 03h 27m 13s 458ms, eta: 08m 20s 732ms\n",
            "\u001b[32m2021-04-27T22:44:57 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:44:57 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:45:24 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:45:30 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:45:43 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:45:43 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2800/3000, val/hateful_memes/cross_entropy: 1.7813, val/total_loss: 1.7813, val/hateful_memes/accuracy: 0.6741, val/hateful_memes/binary_f1: 0.4534, val/hateful_memes/roc_auc: 0.6926, num_updates: 2800, epoch: 16, iterations: 2800, max_updates: 3000, val_time: 45s 949ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:48:29 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:48:29 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:48:42 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:48:54 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:48:54 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:48:54 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:48:59 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:49:11 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:49:27 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:49:27 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2850/3000, val/hateful_memes/cross_entropy: 1.7076, val/total_loss: 1.7076, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4817, val/hateful_memes/roc_auc: 0.6963, num_updates: 2850, epoch: 17, iterations: 2850, max_updates: 3000, val_time: 33s 232ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:51:42 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:51:42 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:51:59 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:52:08 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:52:08 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/3000, train/hateful_memes/cross_entropy: 0.0843, train/hateful_memes/cross_entropy/avg: 0.2846, train/total_loss: 0.0843, train/total_loss/avg: 0.2846, max mem: 12854.0, experiment: run, epoch: 17, num_updates: 2900, iterations: 2900, max_updates: 3000, lr: 0.00001, ups: 0.62, time: 02m 41s 077ms, time_since_start: 03h 34m 25s 027ms, eta: 03m 19s 735ms\n",
            "\u001b[32m2021-04-27T22:52:08 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:52:08 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:52:13 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:52:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:52:39 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:52:39 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2900/3000, val/hateful_memes/cross_entropy: 1.7711, val/total_loss: 1.7711, val/hateful_memes/accuracy: 0.6870, val/hateful_memes/binary_f1: 0.4702, val/hateful_memes/roc_auc: 0.6861, num_updates: 2900, epoch: 17, iterations: 2900, max_updates: 3000, val_time: 30s 427ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:55:26 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:55:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:55:50 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:55:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:55:57 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T22:55:57 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T22:56:10 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:56:16 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T22:56:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T22:56:31 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 2950/3000, val/hateful_memes/cross_entropy: 1.8770, val/total_loss: 1.8770, val/hateful_memes/accuracy: 0.6685, val/hateful_memes/binary_f1: 0.4353, val/hateful_memes/roc_auc: 0.6805, num_updates: 2950, epoch: 17, iterations: 2950, max_updates: 3000, val_time: 33s 112ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T22:59:30 | mmf.trainers.callbacks.checkpoint: \u001b[0mCheckpoint time. Saving a checkpoint.\n",
            "\u001b[32m2021-04-27T22:59:30 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T22:59:53 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T23:00:07 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T23:00:07 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/3000, train/hateful_memes/cross_entropy: 0.0789, train/hateful_memes/cross_entropy/avg: 0.2773, train/total_loss: 0.0789, train/total_loss/avg: 0.2773, max mem: 12854.0, experiment: run, epoch: 17, num_updates: 3000, iterations: 3000, max_updates: 3000, lr: 0.00001, ups: 0.46, time: 03m 36s 234ms, time_since_start: 03h 42m 23s 598ms, eta: 0ms\n",
            "\u001b[32m2021-04-27T23:00:07 | mmf.trainers.core.training_loop: \u001b[0mEvaluation time. Running on full validation set...\n",
            "\u001b[32m2021-04-27T23:00:07 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "\u001b[32m2021-04-27T23:00:14 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation started!\n",
            "\u001b[32m2021-04-27T23:00:20 | mmf.utils.checkpoint: \u001b[0mSaving current checkpoint\n",
            "\u001b[32m2021-04-27T23:00:38 | mmf.utils.checkpoint: \u001b[0mCheckpoint save operation finished!\n",
            "\u001b[32m2021-04-27T23:00:38 | mmf.trainers.callbacks.logistics: \u001b[0mprogress: 3000/3000, val/hateful_memes/cross_entropy: 1.9152, val/total_loss: 1.9152, val/hateful_memes/accuracy: 0.6852, val/hateful_memes/binary_f1: 0.4371, val/hateful_memes/roc_auc: 0.6853, num_updates: 3000, epoch: 17, iterations: 3000, max_updates: 3000, val_time: 31s 239ms, best_update: 2150, best_iteration: 2150, best_val/hateful_memes/roc_auc: 0.705221\n",
            "\u001b[32m2021-04-27T23:00:39 | mmf.trainers.core.training_loop: \u001b[0mStepping into final validation check\n",
            "\u001b[32m2021-04-27T23:00:39 | mmf.utils.checkpoint: \u001b[0mRestoring checkpoint\n",
            "\u001b[32m2021-04-27T23:00:39 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[32m2021-04-27T23:00:57 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2021-04-27T23:00:57 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 2150\n",
            "\u001b[32m2021-04-27T23:00:57 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 2150\n",
            "\u001b[32m2021-04-27T23:00:57 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 13\n",
            "\u001b[32m2021-04-27T23:01:00 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting test inference predictions\n",
            "\u001b[32m2021-04-27T23:01:00 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 42/42 [02:46<00:00,  3.96s/it]\n",
            "\u001b[32m2021-04-27T23:03:47 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_roberta2/hateful_memes_visual_bert_26035513/reports/hateful_memes_run_test_2021-04-27T23:03:47.csv\n",
            "\u001b[32m2021-04-27T23:03:47 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0piGu9d9Z6o",
        "outputId": "3f2a96bb-d3dd-4a18-fd03-83e3e085962d"
      },
      "source": [
        "# eval\n",
        "!mmf_predict config=\"$path\"/visual_bert_coco_more_data_tune3/config.yaml model=visual_bert dataset=hateful_memes \\\n",
        "run_type=val checkpoint.resume_file=\"$path\"/visual_bert_coco_more_data_tune1/best.ckpt checkpoint.resume_pretrained=False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-29 05:36:26.156907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[32m2021-04-29T05:37:37 | mmf.utils.configuration: \u001b[0mOverriding option config to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune3/config.yaml\n",
            "\u001b[32m2021-04-29T05:37:37 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2021-04-29T05:37:37 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2021-04-29T05:37:37 | mmf.utils.configuration: \u001b[0mOverriding option run_type to val\n",
            "\u001b[32m2021-04-29T05:37:37 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune1/best.ckpt\n",
            "\u001b[32m2021-04-29T05:37:37 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n",
            "\u001b[32m2021-04-29T05:37:37 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n",
            "\u001b[32m2021-04-29T05:37:38 | mmf: \u001b[0mLogging to: /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune3/train.log\n",
            "\u001b[32m2021-04-29T05:37:38 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=/content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune3/config.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=val', 'checkpoint.resume_file=/content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune1/best.ckpt', 'checkpoint.resume_pretrained=False', 'evaluation.predict=true'])\n",
            "\u001b[32m2021-04-29T05:37:38 | mmf_cli.run: \u001b[0mTorch version: 1.8.1+cu102\n",
            "\u001b[32m2021-04-29T05:37:38 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla V100-SXM2-16GB\n",
            "\u001b[32m2021-04-29T05:37:38 | mmf_cli.run: \u001b[0mUsing seed 13575765\n",
            "\u001b[32m2021-04-29T05:37:38 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz ]\n",
            "Downloading features.tar.gz: 100% 10.3G/10.3G [13:02<00:00, 13.1MB/s]\n",
            "[ Starting checksum for features.tar.gz]\n",
            "[ Checksum successful for features.tar.gz]\n",
            "Unpacking features.tar.gz\n",
            "[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n",
            "Downloading extras.tar.gz: 100% 211k/211k [00:01<00:00, 176kB/s] \n",
            "[ Starting checksum for extras.tar.gz]\n",
            "[ Checksum successful for extras.tar.gz]\n",
            "Unpacking extras.tar.gz\n",
            "\u001b[32m2021-04-29T05:54:45 | filelock: \u001b[0mLock 140199570452368 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "Downloading: 100% 433/433 [00:00<00:00, 339kB/s]\n",
            "\u001b[32m2021-04-29T05:54:45 | filelock: \u001b[0mLock 140199570452368 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "\u001b[32m2021-04-29T05:54:46 | filelock: \u001b[0mLock 140199564931024 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 677kB/s]\n",
            "\u001b[32m2021-04-29T05:54:46 | filelock: \u001b[0mLock 140199564931024 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "\u001b[32m2021-04-29T05:54:47 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-29T05:54:47 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-29T05:54:47 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-29T05:54:47 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "\u001b[32m2021-04-29T05:54:47 | filelock: \u001b[0mLock 140199563984720 acquired on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "Downloading: 100% 440M/440M [00:06<00:00, 68.3MB/s]\n",
            "\u001b[32m2021-04-29T05:54:53 | filelock: \u001b[0mLock 140199563984720 released on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2021-04-29T05:55:04 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2021-04-29T05:55:04 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-29T05:55:04 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-29T05:55:04 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[32m2021-04-29T05:55:04 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-29T05:55:23 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-29T05:55:23 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[32m2021-04-29T05:55:23 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2021-04-29T05:55:23 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 1300\n",
            "\u001b[32m2021-04-29T05:55:23 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 1300\n",
            "\u001b[32m2021-04-29T05:55:23 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 5\n",
            "\u001b[32m2021-04-29T05:55:23 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting val inference predictions\n",
            "\u001b[32m2021-04-29T05:55:23 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 12/12 [00:33<00:00,  2.76s/it]\n",
            "\u001b[32m2021-04-29T05:55:56 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune3/hateful_memes_visual_bert_13575765/reports/hateful_memes_run_val_2021-04-29T05:55:56.csv\n",
            "\u001b[32m2021-04-29T05:55:56 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asGURixAS0sa",
        "outputId": "0561d3e9-4468-4980-8563-ed554b9a9816"
      },
      "source": [
        "# submit\n",
        "!mmf_predict config=\"$path\"/visual_bert_coco_more_data_tune4/config.yaml \\\n",
        "model=visual_bert \\\n",
        "dataset=hateful_memes \\\n",
        "run_type=test \\\n",
        "training.batch_size=16 \\\n",
        "checkpoint.resume_file=\"$path\"/visual_bert_coco_more_data_tune4/best.ckpt \\\n",
        "checkpoint.resume_pretrained=False \\\n",
        "dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl \\\n",
        "dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-29 06:06:51.641701: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option config to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune4/config.yaml\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option run_type to test\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option training.batch_size to 16\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_file to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune4/best.ckpt\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.val[0] to hateful_memes/defaults/annotations/dev_seen.jsonl\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.test[0] to hateful_memes/defaults/annotations/test_seen.jsonl\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n",
            "\u001b[32m2021-04-29T06:06:57 | mmf: \u001b[0mLogging to: /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune4/train.log\n",
            "\u001b[32m2021-04-29T06:06:58 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=/content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune4/config.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=test', 'training.batch_size=16', 'checkpoint.resume_file=/content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune4/best.ckpt', 'checkpoint.resume_pretrained=False', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl', 'evaluation.predict=true'])\n",
            "\u001b[32m2021-04-29T06:06:58 | mmf_cli.run: \u001b[0mTorch version: 1.8.1+cu102\n",
            "\u001b[32m2021-04-29T06:06:58 | mmf.utils.general: \u001b[0mCUDA Device 0 is: Tesla V100-SXM2-16GB\n",
            "\u001b[32m2021-04-29T06:06:58 | mmf_cli.run: \u001b[0mUsing seed 55277151\n",
            "\u001b[32m2021-04-29T06:06:58 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n",
            "\u001b[32m2021-04-29T06:07:00 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-29T06:07:00 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-29T06:07:00 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n",
            "\u001b[32m2021-04-29T06:07:00 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n",
            "Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[32m2021-04-29T06:07:07 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n",
            "\u001b[32m2021-04-29T06:07:07 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-29T06:07:07 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-29T06:07:07 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n",
            "Use OmegaConf.to_yaml(cfg)\n",
            "\n",
            "  category=UserWarning,\n",
            "\n",
            "\u001b[32m2021-04-29T06:07:07 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-29T06:07:26 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-29T06:07:26 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n",
            "\u001b[32m2021-04-29T06:07:26 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n",
            "\u001b[32m2021-04-29T06:07:26 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 1050\n",
            "\u001b[32m2021-04-29T06:07:26 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 1050\n",
            "\u001b[32m2021-04-29T06:07:26 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 6\n",
            "\u001b[32m2021-04-29T06:07:27 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting test inference predictions\n",
            "\u001b[32m2021-04-29T06:07:27 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n",
            "100% 63/63 [00:07<00:00,  8.05it/s]\n",
            "\u001b[32m2021-04-29T06:07:35 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/drive/MyDrive/School/CS7643/project/visual_bert_coco_more_data_tune4/hateful_memes_visual_bert_55277151/reports/hateful_memes_run_test_2021-04-29T06:07:35.csv\n",
            "\u001b[32m2021-04-29T06:07:35 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnQovRa67N_F",
        "outputId": "e0065bd3-fef6-4c1b-83e2-1c39959794d3"
      },
      "source": [
        "!ls /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev_seen.jsonl\t  test_seen.jsonl    train.jsonl\n",
            "dev_unseen.jsonl  test_unseen.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp6Y6mUCJ7dt"
      },
      "source": [
        "Scratch Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3pYdOs57NG6"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "\n",
        "def load_jsonl(input_path) -> list:\n",
        "    \"\"\"\n",
        "    Read list of objects from a JSON lines file.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
        "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
        "    return data\n",
        "\n",
        "def jsonl_to_df(path):\n",
        "    data = load_jsonl(path)\n",
        "    df = pd.json_normalize(data)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T45zBS8h9PT0",
        "outputId": "601786a8-c0b0-440f-8553-c0bd95bd6aa3"
      },
      "source": [
        "df_dev_seen = jsonl_to_df('/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/dev_seen.jsonl')\n",
        "df_test_seen = jsonl_to_df('/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/test_seen.jsonl')\n",
        "df_train = jsonl_to_df('/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/train.jsonl')\n",
        "df_dev_unseen = jsonl_to_df('/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/dev_unseen.jsonl')\n",
        "df_test_unseen = jsonl_to_df('/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/test_unseen.jsonl')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 500 records from /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/dev_seen.jsonl\n",
            "Loaded 1000 records from /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/test_seen.jsonl\n",
            "Loaded 8500 records from /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/train.jsonl\n",
            "Loaded 540 records from /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/dev_unseen.jsonl\n",
            "Loaded 2000 records from /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations/test_unseen.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXDnUHqq_jd9",
        "outputId": "cabdd926-7153-40d7-af6b-e316a62ba609"
      },
      "source": [
        "len(set(df_dev_seen.id) & set(df_dev_unseen.id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "PUWufNPGI10b",
        "outputId": "5875aff4-89bf-47ad-f71e-b7e6072330c2"
      },
      "source": [
        "df_dev_unseen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>76432</td>\n",
              "      <td>img/76432.png</td>\n",
              "      <td>0</td>\n",
              "      <td>you thinking what i'm thinking?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14270</td>\n",
              "      <td>img/14270.png</td>\n",
              "      <td>0</td>\n",
              "      <td>a brilliant mind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56947</td>\n",
              "      <td>img/56947.png</td>\n",
              "      <td>0</td>\n",
              "      <td>pro gamer 6.000.000 kills, 1 death</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35174</td>\n",
              "      <td>img/35174.png</td>\n",
              "      <td>0</td>\n",
              "      <td>lets end poaching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39264</td>\n",
              "      <td>img/39264.png</td>\n",
              "      <td>0</td>\n",
              "      <td>my wife called me a good husband thats a huge ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>83675</td>\n",
              "      <td>img/83675.png</td>\n",
              "      <td>0</td>\n",
              "      <td>i'm gonna be like phelps one day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>37198</td>\n",
              "      <td>img/37198.png</td>\n",
              "      <td>0</td>\n",
              "      <td>when you're so relaxed you can feel yourself g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>48670</td>\n",
              "      <td>img/48670.png</td>\n",
              "      <td>0</td>\n",
              "      <td>look at this sandwich maker club i found on wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>9863</td>\n",
              "      <td>img/09863.png</td>\n",
              "      <td>0</td>\n",
              "      <td>diverse group of women</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>97320</td>\n",
              "      <td>img/97320.png</td>\n",
              "      <td>0</td>\n",
              "      <td>\"when your dishwasher is broken so you take it...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>540 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                               text\n",
              "0    76432  ...                    you thinking what i'm thinking?\n",
              "1    14270  ...                                   a brilliant mind\n",
              "2    56947  ...                 pro gamer 6.000.000 kills, 1 death\n",
              "3    35174  ...                                  lets end poaching\n",
              "4    39264  ...  my wife called me a good husband thats a huge ...\n",
              "..     ...  ...                                                ...\n",
              "535  83675  ...                   i'm gonna be like phelps one day\n",
              "536  37198  ...  when you're so relaxed you can feel yourself g...\n",
              "537  48670  ...  look at this sandwich maker club i found on wi...\n",
              "538   9863  ...                             diverse group of women\n",
              "539  97320  ...  \"when your dishwasher is broken so you take it...\n",
              "\n",
              "[540 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VxayEhM_dvg",
        "outputId": "f2c6d16f-8a85-4f0b-df6f-6aa21aeaab15"
      },
      "source": [
        "df_md = jsonl_to_df(path+'/hateful_memes-hate_detectron/utils/label_memotion.jsonl')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 328 records from /content/drive/MyDrive/School/CS7643/project/hateful_memes-hate_detectron/utils/label_memotion.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjaUXcHAEjTe",
        "outputId": "b9f31dba-ea9f-40a3-c201-6e9c8a7d4a97"
      },
      "source": [
        "df_md.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    221\n",
              "1    107\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTCUL9z1EkCU",
        "outputId": "0a0e675c-a055-4f67-d324-3ac99145acc5"
      },
      "source": [
        "df_train.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5481\n",
              "1    3019\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEjnZPvNGXGp",
        "outputId": "cf958e7e-44ab-4b95-dd37-ea05ad6ccab8"
      },
      "source": [
        "5481/3019"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8155018217952965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7HU7kJZGc6h",
        "outputId": "1426f2eb-92a8-4a3b-da8d-cb958b46d773"
      },
      "source": [
        "221/107"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0654205607476634"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhR3gxhjGeJW",
        "outputId": "b1f86724-40f2-4276-d416-7a1c69e7aade"
      },
      "source": [
        "df_dev_unseen.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    340\n",
              "1    200\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHXr0l2AGpOs",
        "outputId": "00d93821-1269-4abe-a3ac-e25896680b59"
      },
      "source": [
        "df_dev_seen.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    253\n",
              "1    247\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYLSVm0RGtDL",
        "outputId": "82442c10-ff84-48ad-8f9f-88392a36f35a"
      },
      "source": [
        "len(set(df_dev_seen.id) - set(df_dev_unseen.id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHn54afJIkOF",
        "outputId": "bcc8a9c9-e358-40f5-a1fe-5856896d6c6c"
      },
      "source": [
        "len(set(df_dev_unseen.id) - set(df_dev_seen.id))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cl5CamuhxsXF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}