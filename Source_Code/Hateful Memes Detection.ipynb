{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of Hateful Memes Detection.ipynb","provenance":[{"file_id":"1IrbgnrySPvftd5W3PXRbvQlBVycJF2q0","timestamp":1618594240445},{"file_id":"https://github.com/facebookresearch/mmf/blob/notebooks/notebooks/mmf_hm_example.ipynb","timestamp":1618476523864}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python383jvsc74a57bd04fce8d4cd2ca892340f1247d5180d32c8e47823f34c01a078f67b31c433a79a4","display_name":"Python 3.8.3 64-bit ('base': conda)"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lwCc6zN1BkIE"},"source":["# Frozen Wasteland Team for Hateful Memes Detection FB Project Phase 1\n","\n","This notebook provides step-by-step instructions on how to use MMF to build new models and uses the Hateful Memes (HM) dataset for this specific tutorial.\n","\n","Follow these links to learn more about MMF:\n","- [MMF Blog Post]()\n","- [GitHub repo](https://github.com/facebookresearch/mmf)\n","- [Website](https://mmf.sh) and [Documentation](https://mmf.rtfd.io)\n","\n","In general, the notebook demonstrates how to:\n","\n","1. [Download MMF](#scrollTo=l7Eo9ZqTDW3I)\n","2. [Download the HM dataset](#scrollTo=nYyXt9dzEBEU&line=12&uniqifier=1)\n","3. [Test pretrained models on HM](#scrollTo=nYyXt9dzEBEU&line=12&uniqifier=1)\n","4. [Submit a prediction](#scrollTo=uhKvYHtWHlyr&line=3&uniqifier=1)\n","5. [Train existing model on HM](#scrollTo=) \n","6. [Build your model](#scrollTo=)\n","7. [Train your model on HM](#scrollTo=) "]},{"source":["## Pre-Setup"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WAfaIFBI4uTY","executionInfo":{"status":"ok","timestamp":1619710968506,"user_tz":420,"elapsed":1080,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}},"outputId":"9945d908-7a16-48e8-940f-9f95405fe94f"},"source":["# Show GPU Info\n","!nvidia-smi"],"execution_count":null,"outputs":[]},{"source":["For *Linux* `HOME` would be: `\"/home\"`\n","\n","For *Colab* `HOME` would be: `\"/content\"`"],"cell_type":"markdown","metadata":{}},{"source":["# Setup Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jA6QD1p5dtRk","executionInfo":{"status":"ok","timestamp":1619710993273,"user_tz":420,"elapsed":20965,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}},"outputId":"0bea90e7-c9c6-43b2-c4da-dc3d6a43b298"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UqQQQRy8d-uI","executionInfo":{"status":"ok","timestamp":1619711018059,"user_tz":420,"elapsed":1314,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}}},"source":["# Setup Saving Path\n","path = '/content/drive/MyDrive/CS7643/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l7Eo9ZqTDW3I"},"source":["## Download MMF\n","\n","In this section, we will download the MMF package and required dependencies.\n","\n","### Prerequisites \n","Please enable GPU in this notebook: Runtime > Change runtime type > Hardware Accelerator > Set to GPU\n","\n","First we will install the MMF package and required dependencies\n","\n","Install from source [Recommended]\n","\n","https://mmf.sh/docs/challenges/hateful_memes_challenge/#predicting-for-phase-1"]},{"cell_type":"code","metadata":{"id":"PBbnmvjredOg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619711039711,"user_tz":420,"elapsed":3507,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}},"outputId":"ac64f3d6-8271-4fa2-dcbc-ed62b9c761de"},"source":["!git clone https://github.com/facebookresearch/mmf.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q6USNo8IfkIS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619712403540,"user_tz":420,"elapsed":10979,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}},"outputId":"286c69a9-6244-4975-89f4-8642c078caea"},"source":["# %cd /home/jupyter/mmf/\n","%cd /content/mmf/\n","!pip install --editable .\n","# run if run into PyYAML version error   \n","!pip install PyYAML==5.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nYyXt9dzEBEU"},"source":["## Download dataset\n","\n","We will now download the Hateful Memes dataset. You will require two things to download the datasets: (i) URL (ii) Password to the zip file. To get both of these follow these steps:\n","\n","1. Go to [DrivenData challenge page](https://www.drivendata.org/competitions/64/hateful-memes/)\n","2. Register, read and acknowledge the agreements for data access.\n","3. Go to the [data page](https://www.drivendata.org/competitions/64/hateful-memes/data), right click on the \"Hateful Memes challenge dataset\" link and \"Copy Link Address\" as shown in the image. This will copy the URL for the zip file to your clipboard which you will use in the next step.\n","![data](https://i.imgur.com/JQx2hPm.png)\n","4. Also, note the password provided in the description.\n","5. Run the next code block, fill in the URL and the zipfile's password when prompted.\n","\n","The code blocks after that will download, convert and visualize the dataset."]},{"source":["from getpass import getpass, getuser\n","url = getpass(\"Enter the Hateful Memes data URL:\")\n","password = getpass(\"Enter ZIP file's Password:\")"],"cell_type":"code","metadata":{"id":"ulosPHAE-eto","executionInfo":{"status":"ok","timestamp":1619712409025,"user_tz":420,"elapsed":416,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i5Y8wI6BoNN6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619712493549,"user_tz":420,"elapsed":81756,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}},"outputId":"855b9667-e644-4dcd-f745-3f336c611c91"},"source":["# !curl -o /home/jupyter/hm.zip \"$url\" -H 'Referer: https://www.drivendata.org/competitions/64/hateful-memes/data/' --compressed\n","!curl -o /content/hm.zip \"$url\" -H 'Referer: https://www.drivendata.org/competitions/64/hateful-memes/data/' --compressed"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xPYBxsyRFUUb"},"source":["The next command will convert the zip file into required MMF format."]},{"cell_type":"code","metadata":{"id":"NsMmmOB3_rdY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619712647616,"user_tz":420,"elapsed":133316,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}},"outputId":"2dc17b8d-e4fc-439c-bf95-073a23927460"},"source":["!mmf_convert_hm --zip_file=/content/hm.zip --password $password --bypass_checksum=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_JiwZ7WMkGz","executionInfo":{"status":"ok","timestamp":1619713924809,"user_tz":420,"elapsed":588,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}},"outputId":"173bef39-b601-47c2-baf6-1f6f7e62f296"},"source":["# Check how many images we have in total\n","!ls /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ | wc -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pVJjgvbHel1P"},"source":["That means there are `12.140` **'uniquely named'** images in total and you might recall that the sizes of each set was the following:\n","\n","- `|train.jsonl| = 8.500`\n","- `|dev_seen.jsonl| = 500`\n","- `|dev_unseen.jsonl| = 540`\n","- `|test_seen.jsonl| = 1.000`\n","- `|test_unseen.jsonl| = 2.000`\n","\n","Well, this makes `8.500 + 500 + 540 + 1.000 + 2.000 = 12.540` in total. \\\n","> *Is there something wrong?*\\\n","> **TL;DR:** Nope. Some images in `dev_seen` are used in `dev_unseen`, too. To be specific, they have `400` common images. Hence, in total we have `12.540 - 400 = 12.140` *'unique'* images.\\\n","See <font color='orange'> <b> Extras </b> </font> --> <font color='Gold'><b> Number of 'unique' (based on file names) images </b></font> at the end of this script to see the explanation in detail."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Free up the disk by removing .zip, .tar files\n","!rm -rf /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/XjiOc5ycDBRRNwbhRlgH.zip\n","!rm -rf $home/mmf/XjiOc5ycDBRRNwbhRlgH.zip"]},{"cell_type":"markdown","metadata":{"id":"mDDnTlQZV46f"},"source":["## Train an existing model\n","\n","We will use MMF to train an existing baseline from MMF's model zoo on the Hateful Memes dataset. Run the next code cell to start training MMBT-Grid model on the dataset. You can adjust the batch size, maximum number of updates, log and evaluation interval among other things by using command line overrides. Read more about MMF's configuration system at https://github.com/facebookresearch/mmf/tree/master/projects/hateful_memes#reproducing-baselines"]},{"cell_type":"code","metadata":{"id":"1nwebqtdWOfZ"},"source":["!mmf_run config=projects/hateful_memes/configs/mmbt/defaults.yaml \\\n","  model=mmbt \\\n","  dataset=hateful_memes \\\n","  training.log_interval=50 \\\n","  training.max_updates=3000 \\\n","  training.batch_size=16 \\\n","  training.evaluation_interval=500"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ViLBERT\n","!mmf_run config=projects/hateful_memes/configs/vilbert/defaults.yaml \\\n","    model=vilbert \\\n","    dataset=hateful_memes \\\n","    env.save_dir=\"$path\"/vilbert_tune \\\n","    checkpoint.resume_zoo=vilbert.finetuned.hateful_memes.direct \\\n","    training.max_updates=2000 \\\n","    training.batch_size=16"]},{"cell_type":"markdown","metadata":{"id":"uhKvYHtWHlyr"},"source":["## Submit a prediction\n","\n","Now, we will use a pretrained model from MMF to submit a prediction to DrivenData. Run the command in the next block and at the end it will output the path to the csv file generated. Download and upload that file to [DrivenData's submission page](https://www.drivendata.org/competitions/64/hateful-memes/submissions/)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNUoAtfO1E-_","executionInfo":{"status":"ok","timestamp":1619736322748,"user_tz":420,"elapsed":109236,"user":{"displayName":"Stephen Wang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjQmD7NZJbux8rfGFCm-sLlkAnKJAAZzShruYlawQ=s64","userId":"13207354784520637281"}},"outputId":"079a57ac-471b-4c8b-9624-2f7934f2e096"},"source":["# predictions on the validation set\n","!mmf_predict config=\"$path\"/vilbert_tune/config.yaml \\\n","  model=vilbert \\\n","  dataset=hateful_memes \\\n","  run_type=val \\\n","  checkpoint.resume_file=\"$path\"/vilbert_tune/best.ckpt \\\n","  checkpoint.resume_pretrained=False \\\n","  dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl \\\n","  dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u_793CbuwRgZ"},"source":["# predictions on the test set\n","!mmf_predict config=\"$path\"/vilbert_tune/config.yaml \\\n","  model=vilbert \\\n","  dataset=hateful_memes \\\n","  run_type=test \\\n","  checkpoint.resume_file=\"$path\"/vilbert_tune/best.ckpt \\\n","  checkpoint.resume_pretrained=False \\\n","  dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl \\\n","  dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl"],"execution_count":null,"outputs":[]},{"source":["There are 2 options for downloading the dataset: \n","\n","1. download the dataset (a `.zip` file) using `Kaggle API`\n","\n","OR\n","\n","2. download the dataset (a `.zip` file) from [Kaggle](https://www.kaggle.com/williamscott701/memotion-dataset-7k) directly, **(<font color='red' >preferred </font> if you're not familiar with Kaggle API)**\n","\n","Check out the official documentation to get more information on Kaggle API and how to create a Kaggle API Key:\n","- [Link#1](https://github.com/Kaggle/kaggle-api#api-credentials)\n","- [Link#2](https://www.kaggle.com/docs/api)\n","\n","The API Key is stored in a file named `kaggle.jsonl`, which has the folowing line inside: \n","`{\"username\":\"your_user_name\",\"key\":\"some_values_here\"}`\n","\n","> Upload the `kaggle.json` file to your `$HOME` directory and run the following cell."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Install kaggle library\n","!pip install -q kaggle\n","# Create a directory where API key will be stored\n","!mkdir -p ~/.kaggle\n","# Move the API key to where Kaggle expects it to be\n","!mv $home/kaggle.json ~/.kaggle/\n","# Give according rights to the file\n","!chmod 600 /root/.kaggle/kaggle.json\n","# Finally, download the dataset (.zip file)\n","!kaggle datasets download -d williamscott701/memotion-dataset-7k\n","# Unzip the data \n","!unzip -qq memotion-dataset-7k.zip -d $home/"]},{"cell_type":"markdown","metadata":{"id":"1mB-z-6XWdBd"},"source":["## Build your own model\n","\n","Using MMF's encoders, modules and utilities, we can easily build a custom model. In this example, we are building a fusion model which fuses ResNet pooled grid features with fasttext embedding vectors to classify a meme as hateful or not hateful. \n","\n","Steps involved in building the model are:\n","\n","1. Create a new processor to get fasttext sentence embeddings. (Read more on processors [here]())\n","2. Create new model using encoders from MMF.\n","3. Move hardcoded stuff from model to configuration."]},{"cell_type":"code","metadata":{"id":"x2yjX5JxIu2C"},"source":["import torch \n","\n","# We will inherit the FastText Processor already present in MMF\n","from mmf.datasets.processors import FastTextProcessor\n","# registry is needed to register processor and model to be MMF discoverable\n","from mmf.common.registry import registry\n","\n","# Register the processor so that MMF can discover it\n","@registry.register_processor(\"fasttext_sentence_vector\")\n","class FastTextSentenceVectorProcessor(FastTextProcessor):\n","    # Override the call method\n","    def __call__(self, item):\n","        # This function is present in FastTextProcessor class and loads\n","        # fasttext bin\n","        self._load_fasttext_model(self.model_file)\n","        if \"text\" in item:\n","            text = item[\"text\"]\n","        elif \"tokens\" in item:\n","            text = \" \".join(item[\"tokens\"])\n","\n","        # Get a sentence vector for sentence and convert it to torch tensor\n","        sentence_vector = torch.tensor(\n","            self.model.get_sentence_vector(text),\n","            dtype=torch.float\n","        )\n","\n","        # Return back a dict\n","        return {\n","            \"text\": sentence_vector\n","        }\n","    \n","    # Make dataset builder happy, return a random number\n","    def get_vocab_size(self):\n","        return None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rlB4n0nwKWZn"},"source":["import torch\n","\n","# registry is need to register our new model so as to be MMF discoverable\n","from mmf.common.registry import registry\n","# All model using MMF need to inherit BaseModel\n","from mmf.models.base_model import BaseModel\n","# ProjectionEmbedding will act as proxy encoder for FastText Sentence Vector\n","from mmf.modules.embeddings import ProjectionEmbedding\n","# Builder methods for image encoder and classifier\n","from mmf.utils.build import build_classifier_layer, build_image_encoder\n","\n","# Register the model for MMF, \"concat_vl\" key would be used to find the model\n","@registry.register_model(\"concat_vl\")\n","class LanguageAndVisionConcat(BaseModel):\n","    # All models in MMF get first argument as config which contains all\n","    # of the information you stored in this model's config (hyperparameters)\n","    def __init__(self, config, *args, **kwargs):\n","        # This is not needed in most cases as it just calling parent's init\n","        # with same parameters. But to explain how config is initialized we \n","        # have kept this\n","        super().__init__(config, *args, **kwargs)\n","    \n","    # This classmethod tells MMF where to look for default config of this model\n","    @classmethod\n","    def config_path(cls):\n","        # Relative to user dir root\n","        return \"/content/hm_example_mmf/configs/models/concat_vl.yaml\"\n","    \n","    # Each method need to define a build method where the model's modules\n","    # are actually build and assigned to the model\n","    def build(self):\n","        \"\"\"\n","        Config's image_encoder attribute will used to build an MMF image\n","        encoder. This config in yaml will look like:\n","\n","        # \"type\" parameter specifies the type of encoder we are using here. \n","        # In this particular case, we are using resnet152\n","        type: resnet152\n","      \n","        # Parameters are passed to underlying encoder class by \n","        # build_image_encoder\n","        params:\n","          # Specifies whether to use a pretrained version\n","          pretrained: true \n","          # Pooling type, use max to use AdaptiveMaxPool2D\n","          pool_type: avg \n","      \n","          # Number of output features from the encoder, -1 for original\n","          # otherwise, supports between 1 to 9\n","          num_output_features: 1 \n","        \"\"\"\n","        self.vision_module = build_image_encoder(self.config.image_encoder)\n","\n","        \"\"\"\n","        For classifer, configuration would look like:\n","        # Specifies the type of the classifier, in this case mlp\n","        type: mlp\n","        # Parameter to the classifier passed through build_classifier_layer\n","        params:\n","          # Dimension of the tensor coming into the classifier\n","          in_dim: 512\n","          # Dimension of the tensor going out of the classifier\n","          out_dim: 2\n","          # Number of MLP layers in the classifier\n","          num_layers: 0\n","        \"\"\"\n","        self.classifier = build_classifier_layer(self.config.classifier)\n","        \n","        # ProjectionEmbeddings takes in params directly as it is module\n","        # So, pass in kwargs, which are in_dim, out_dim and module\n","        # whose value would be \"linear\" as we want linear layer\n","        self.language_module = ProjectionEmbedding(\n","            **self.config.text_encoder.params\n","        )\n","        # Dropout value will come from config now\n","        self.dropout = torch.nn.Dropout(self.config.dropout)\n","        # Same as Projection Embedding, fusion's layer params (which are param \n","        # for linear layer) will come from config now\n","        self.fusion = torch.nn.Linear(**self.config.fusion.params)\n","        self.relu = torch.nn.ReLU()\n","\n","    # Each model in MMF gets a dict called sample_list which contains\n","    # all of the necessary information returned from the image\n","    def forward(self, sample_list):\n","        # Text input features will be in \"text\" key\n","        text = sample_list[\"text\"]\n","        # Similarly, image input will be in \"image\" key\n","        image = sample_list[\"image\"]\n","\n","        text_features = self.relu(self.language_module(text))\n","        image_features = self.relu(self.vision_module(image))\n","\n","        # Concatenate the features returned from two modality encoders\n","        combined = torch.cat([text_features, image_features.squeeze()], dim=1)\n","\n","        # Pass through the fusion layer, relu and dropout\n","        fused = self.dropout(self.relu(self.fusion(combined)))\n","\n","        # Pass final tensor from classifier to get scores\n","        logits = self.classifier(fused)\n","\n","        # For loss calculations (automatically done by MMF based on loss defined\n","        # in the config), we need to return a dict with \"scores\" key as logits\n","        output = {\"scores\": logits}\n","\n","        # MMF will automatically calculate loss\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G8VCzWStDwkJ"},"source":["Now, we will install the example repo that we have already created on top of MMF and contains code in this colab. We do this so that we don't have to build configs again from scratch"]},{"cell_type":"code","metadata":{"id":"bjvxZYBXTrRG"},"source":["!git clone https://github.com/apsdehal/hm_example_mmf /content/hm_example_mmf"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"taXGqCxQXJbo"},"source":["## Train your model\n","\n","In this step, we will train the model we just built. A dot list can be passed as either a dict or a list to the run to override the configuration parameters."]},{"cell_type":"code","metadata":{"id":"9Aci1mtsURL9"},"source":["import sys\n","from mmf_cli.run import run\n","opts = opts=[\n","    \"config='/content/hm_example_mmf/configs/experiments/defaults.yaml'\", \n","    \"model=concat_vl\", \n","    \"dataset=hateful_memes\", \n","    \"training.num_workers=0\"\n","]\n","run(opts=opts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lTAshObTm1ey"},"source":["## Using your module\n","\n","Since, we have cloned the repo that contains the example we built in this colab notebook we can use it also to run the training from command line by using the `env.user_dir` option or by overriding the environment variable `MMF_USER_DIR`. Expand the cell below the next code cell to see how it can be done."]},{"cell_type":"code","metadata":{"id":"Rwggw7XLUYuO"},"source":["!MMF_USER_DIR=\"/content/hm_example_mmf\" mmf_run \\\n","  config=\"configs/experiments/defaults.yaml\" \\\n","  model=concat_vl \\\n","  dataset=hateful_memes \\\n","  training.num_workers=0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q-Y2aJC_nRpy"},"source":["## Conclusion and Further Steps\n","\n","In this colab notebook, we learned how we can use MMF to train and predict already existing models in MMF's zoo. We also learned how we can build custom models using various modules and goodies provided in MMF easily.\n","\n","If you have any issues, feedback or comments, please reach us out at mmf@fb.com or open up an issue at [GitHub](https://github.com/facebookresearch/mmf/issues/new/choose). We are also accepting PRs if you want to add your cool model to MMF and we are always open to community contributions.\n","\n","At Facebook AI, we’ll continuously improve and expand on the multimodal capabilities available through MMF, and we welcome contributions from the community as well to build this resource. We hope MMF will be the framework of choice and be a catalyst for research in this area by providing a powerful, versatile platform for multimodal research. "]}]}