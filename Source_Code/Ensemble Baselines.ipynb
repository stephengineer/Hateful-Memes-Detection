{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ensemble Baselines.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"pwDmyZ39o5Xe"},"source":["!pip install git+https://github.com/facebookresearch/mmf.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWAvxTWiBVQW"},"source":["from getpass import getpass, getuser\n","url = getpass(\"Enter the Hateful Memes data URL:\")\n","password = getpass(\"Enter ZIP file's Password:\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5h8U4chCF1rQ"},"source":["!curl -o /content/hm.zip \"$url\" -H 'Referer: https://www.drivendata.org/competitions/64/hateful-memes/data/' --compressed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pi9S1FvYGofU"},"source":["!mmf_convert_hm --zip_file /content/hm.zip --password $password --bypass_checksum 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SXuChg_N-7Xw"},"source":["VisualBERT on COCO "]},{"cell_type":"code","metadata":{"id":"bEZiOwxI2do5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619756134130,"user_tz":240,"elapsed":1619388,"user":{"displayName":"Zi Zi5","photoUrl":"","userId":"02858063377345824552"}},"outputId":"f738fe43-5344-4f76-8cba-d56027c9a9d3"},"source":["!mmf_predict config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n","model=visual_bert \\\n","dataset=hateful_memes \\\n","run_type=test \\\n","checkpoint.resume_zoo=visual_bert.finetuned.hateful_memes.from_coco \\\n","checkpoint.resume_pretrained=False \\\n","dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl \\\n","dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-30 03:44:00.592428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[32m2021-04-30T03:44:06 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/hateful_memes/configs/visual_bert/from_coco.yaml\n","\u001b[32m2021-04-30T03:44:06 | mmf.utils.configuration: \u001b[0mOverriding option model to visual_bert\n","\u001b[32m2021-04-30T03:44:06 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n","\u001b[32m2021-04-30T03:44:06 | mmf.utils.configuration: \u001b[0mOverriding option run_type to test\n","\u001b[32m2021-04-30T03:44:06 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_zoo to visual_bert.finetuned.hateful_memes.from_coco\n","\u001b[32m2021-04-30T03:44:06 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n","\u001b[32m2021-04-30T03:44:06 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.val[0] to hateful_memes/defaults/annotations/dev_seen.jsonl\n","\u001b[32m2021-04-30T03:44:06 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.test[0] to hateful_memes/defaults/annotations/test_seen.jsonl\n","\u001b[32m2021-04-30T03:44:06 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n","/usr/local/lib/python3.7/dist-packages/mmf/utils/configuration.py:574: UserWarning: Device specified is 'cuda' but cuda is not present. Switching to CPU version.\n","  \"Device specified is 'cuda' but cuda is not present. \"\n","\u001b[32m2021-04-30T03:44:06 | mmf: \u001b[0mLogging to: ./save/train.log\n","\u001b[32m2021-04-30T03:44:06 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/visual_bert/from_coco.yaml', 'model=visual_bert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_zoo=visual_bert.finetuned.hateful_memes.from_coco', 'checkpoint.resume_pretrained=False', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl', 'evaluation.predict=true'])\n","\u001b[32m2021-04-30T03:44:06 | mmf_cli.run: \u001b[0mTorch version: 1.8.1+cu102\n","\u001b[32m2021-04-30T03:44:06 | mmf_cli.run: \u001b[0mUsing seed 6812030\n","\u001b[32m2021-04-30T03:44:06 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n","[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/features/features.tar.gz ]\n","Downloading features.tar.gz: 100% 10.3G/10.3G [05:14<00:00, 32.7MB/s]\n","[ Starting checksum for features.tar.gz]\n","[ Checksum successful for features.tar.gz]\n","Unpacking features.tar.gz\n","[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz to /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/extras.tar.gz ]\n","Downloading extras.tar.gz: 100% 211k/211k [00:00<00:00, 367kB/s]\n","[ Starting checksum for extras.tar.gz]\n","[ Checksum successful for extras.tar.gz]\n","Unpacking extras.tar.gz\n","\u001b[32m2021-04-30T03:57:11 | filelock: \u001b[0mLock 139984117291792 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n","Downloading: 100% 433/433 [00:00<00:00, 289kB/s]\n","\u001b[32m2021-04-30T03:57:11 | filelock: \u001b[0mLock 139984117291792 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n","\u001b[32m2021-04-30T03:57:12 | filelock: \u001b[0mLock 139984139656016 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","Downloading: 100% 232k/232k [00:00<00:00, 2.00MB/s]\n","\u001b[32m2021-04-30T03:57:12 | filelock: \u001b[0mLock 139984139656016 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:12 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:12 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\n","\u001b[32m2021-04-30T03:57:12 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2021-04-30T03:57:12 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2021-04-30T03:57:12 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2021-04-30T03:57:12 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n","\u001b[32m2021-04-30T03:57:12 | filelock: \u001b[0mLock 139984111996624 acquired on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n","Downloading: 100% 440M/440M [00:14<00:00, 31.1MB/s]\n","\u001b[32m2021-04-30T03:57:27 | filelock: \u001b[0mLock 139984111996624 released on /root/.cache/torch/mmf/distributed_-1/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n","Some weights of VisualBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.token_type_embeddings_visual.weight', 'bert.embeddings.position_embeddings_visual.weight', 'bert.embeddings.projection.weight', 'bert.embeddings.projection.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m2021-04-30T03:57:31 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n","\u001b[32m2021-04-30T03:57:31 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:31 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n","Use OmegaConf.to_yaml(cfg)\n","\n","  category=UserWarning,\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:31 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n","Use OmegaConf.to_yaml(cfg)\n","\n","  category=UserWarning,\n","\n","\u001b[32m2021-04-30T03:57:31 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/models/visual_bert/visual_bert.finetuned.hateful_memes_from_coco.tar.gz to /root/.cache/torch/mmf/data/models/visual_bert.finetuned.hateful_memes.from_coco/visual_bert.finetuned.hateful_memes_from_coco.tar.gz ]\n","Downloading visual_bert.finetuned.hateful_memes_from_coco.tar.gz: 100% 414M/414M [00:13<00:00, 31.1MB/s]\n","[ Starting checksum for visual_bert.finetuned.hateful_memes_from_coco.tar.gz]\n","[ Checksum successful for visual_bert.finetuned.hateful_memes_from_coco.tar.gz]\n","Unpacking visual_bert.finetuned.hateful_memes_from_coco.tar.gz\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:52 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:52 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:52 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:52 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:53 | mmf.utils.checkpoint: \u001b[0mMissing keys ['model.bert.embeddings.position_ids'] in the checkpoint.\n","If this is not your checkpoint, please open up an issue on MMF GitHub. \n","Unexpected keys if any: []\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:53 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/mmf/utils/checkpoint.py:304: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.\n","  \"'optimizer' key is not present in the \"\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:53 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/mmf/utils/checkpoint.py:304: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.\n","  \"'optimizer' key is not present in the \"\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:53 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/mmf/utils/checkpoint.py:347: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.\n","  \"'lr_scheduler' key is not present in the \"\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T03:57:53 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/mmf/utils/checkpoint.py:347: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.\n","  \"'lr_scheduler' key is not present in the \"\n","\n","\u001b[32m2021-04-30T03:57:53 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2021-04-30T03:57:53 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 0\n","\u001b[32m2021-04-30T03:57:53 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 0\n","\u001b[32m2021-04-30T03:57:53 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 0\n","\u001b[32m2021-04-30T03:57:53 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting test inference predictions\n","\u001b[32m2021-04-30T03:57:53 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","100% 16/16 [12:59<00:00, 48.72s/it]\n","\u001b[32m2021-04-30T04:10:52 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/save/hateful_memes_visual_bert_6812030/reports/hateful_memes_run_test_2021-04-30T04:10:52.csv\n","\u001b[32m2021-04-30T04:10:52 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting. Loaded 16\n","\u001b[32m2021-04-30T04:10:52 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7tT39Hxy-0lR"},"source":["VilBERT on CC"]},{"cell_type":"code","metadata":{"id":"bOD44hEGHazw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619757153807,"user_tz":240,"elapsed":1019667,"user":{"displayName":"Zi Zi5","photoUrl":"","userId":"02858063377345824552"}},"outputId":"c35d7fda-8470-44d0-b351-eae4b25cb3cb"},"source":["!mmf_predict config=projects/hateful_memes/configs/vilbert/from_cc.yaml \\\n","model=vilbert \\\n","dataset=hateful_memes \\\n","run_type=test \\\n","checkpoint.resume_zoo=vilbert.finetuned.hateful_memes.from_cc_original \\\n","checkpoint.resume_pretrained=False \\\n","dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl \\\n","dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-04-30 04:11:03.692215: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[32m2021-04-30T04:11:11 | mmf.utils.configuration: \u001b[0mOverriding option config to projects/hateful_memes/configs/vilbert/from_cc.yaml\n","\u001b[32m2021-04-30T04:11:11 | mmf.utils.configuration: \u001b[0mOverriding option model to vilbert\n","\u001b[32m2021-04-30T04:11:11 | mmf.utils.configuration: \u001b[0mOverriding option datasets to hateful_memes\n","\u001b[32m2021-04-30T04:11:11 | mmf.utils.configuration: \u001b[0mOverriding option run_type to test\n","\u001b[32m2021-04-30T04:11:11 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_zoo to vilbert.finetuned.hateful_memes.from_cc_original\n","\u001b[32m2021-04-30T04:11:11 | mmf.utils.configuration: \u001b[0mOverriding option checkpoint.resume_pretrained to False\n","\u001b[32m2021-04-30T04:11:11 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.val[0] to hateful_memes/defaults/annotations/dev_seen.jsonl\n","\u001b[32m2021-04-30T04:11:11 | mmf.utils.configuration: \u001b[0mOverriding option dataset_config.hateful_memes.annotations.test[0] to hateful_memes/defaults/annotations/test_seen.jsonl\n","\u001b[32m2021-04-30T04:11:11 | mmf.utils.configuration: \u001b[0mOverriding option evaluation.predict to true\n","/usr/local/lib/python3.7/dist-packages/mmf/utils/configuration.py:574: UserWarning: Device specified is 'cuda' but cuda is not present. Switching to CPU version.\n","  \"Device specified is 'cuda' but cuda is not present. \"\n","\u001b[32m2021-04-30T04:11:11 | mmf: \u001b[0mLogging to: ./save/train.log\n","\u001b[32m2021-04-30T04:11:11 | mmf_cli.run: \u001b[0mNamespace(config_override=None, local_rank=None, opts=['config=projects/hateful_memes/configs/vilbert/from_cc.yaml', 'model=vilbert', 'dataset=hateful_memes', 'run_type=test', 'checkpoint.resume_zoo=vilbert.finetuned.hateful_memes.from_cc_original', 'checkpoint.resume_pretrained=False', 'dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_seen.jsonl', 'dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_seen.jsonl', 'evaluation.predict=true'])\n","\u001b[32m2021-04-30T04:11:11 | mmf_cli.run: \u001b[0mTorch version: 1.8.1+cu102\n","\u001b[32m2021-04-30T04:11:11 | mmf_cli.run: \u001b[0mUsing seed 11446352\n","\u001b[32m2021-04-30T04:11:11 | mmf.trainers.mmf_trainer: \u001b[0mLoading datasets\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:11:13 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:11:13 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\n","\u001b[32m2021-04-30T04:11:13 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2021-04-30T04:11:13 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2021-04-30T04:11:13 | mmf.datasets.multi_datamodule: \u001b[0mMultitasking disabled by default for single dataset training\n","\u001b[32m2021-04-30T04:11:13 | mmf.trainers.mmf_trainer: \u001b[0mLoading model\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing ViLBERTBase: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing ViLBERTBase from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing ViLBERTBase from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ViLBERTBase were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.LayerNorm.weight', 'bert.v_embeddings.LayerNorm.bias', 'bert.encoder.v_layer.0.attention.self.query.weight', 'bert.encoder.v_layer.0.attention.self.query.bias', 'bert.encoder.v_layer.0.attention.self.key.weight', 'bert.encoder.v_layer.0.attention.self.key.bias', 'bert.encoder.v_layer.0.attention.self.value.weight', 'bert.encoder.v_layer.0.attention.self.value.bias', 'bert.encoder.v_layer.0.attention.output.dense.weight', 'bert.encoder.v_layer.0.attention.output.dense.bias', 'bert.encoder.v_layer.0.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.0.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.0.intermediate.dense.weight', 'bert.encoder.v_layer.0.intermediate.dense.bias', 'bert.encoder.v_layer.0.output.dense.weight', 'bert.encoder.v_layer.0.output.dense.bias', 'bert.encoder.v_layer.0.output.LayerNorm.weight', 'bert.encoder.v_layer.0.output.LayerNorm.bias', 'bert.encoder.v_layer.1.attention.self.query.weight', 'bert.encoder.v_layer.1.attention.self.query.bias', 'bert.encoder.v_layer.1.attention.self.key.weight', 'bert.encoder.v_layer.1.attention.self.key.bias', 'bert.encoder.v_layer.1.attention.self.value.weight', 'bert.encoder.v_layer.1.attention.self.value.bias', 'bert.encoder.v_layer.1.attention.output.dense.weight', 'bert.encoder.v_layer.1.attention.output.dense.bias', 'bert.encoder.v_layer.1.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.1.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.1.intermediate.dense.weight', 'bert.encoder.v_layer.1.intermediate.dense.bias', 'bert.encoder.v_layer.1.output.dense.weight', 'bert.encoder.v_layer.1.output.dense.bias', 'bert.encoder.v_layer.1.output.LayerNorm.weight', 'bert.encoder.v_layer.1.output.LayerNorm.bias', 'bert.encoder.v_layer.2.attention.self.query.weight', 'bert.encoder.v_layer.2.attention.self.query.bias', 'bert.encoder.v_layer.2.attention.self.key.weight', 'bert.encoder.v_layer.2.attention.self.key.bias', 'bert.encoder.v_layer.2.attention.self.value.weight', 'bert.encoder.v_layer.2.attention.self.value.bias', 'bert.encoder.v_layer.2.attention.output.dense.weight', 'bert.encoder.v_layer.2.attention.output.dense.bias', 'bert.encoder.v_layer.2.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.2.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.2.intermediate.dense.weight', 'bert.encoder.v_layer.2.intermediate.dense.bias', 'bert.encoder.v_layer.2.output.dense.weight', 'bert.encoder.v_layer.2.output.dense.bias', 'bert.encoder.v_layer.2.output.LayerNorm.weight', 'bert.encoder.v_layer.2.output.LayerNorm.bias', 'bert.encoder.v_layer.3.attention.self.query.weight', 'bert.encoder.v_layer.3.attention.self.query.bias', 'bert.encoder.v_layer.3.attention.self.key.weight', 'bert.encoder.v_layer.3.attention.self.key.bias', 'bert.encoder.v_layer.3.attention.self.value.weight', 'bert.encoder.v_layer.3.attention.self.value.bias', 'bert.encoder.v_layer.3.attention.output.dense.weight', 'bert.encoder.v_layer.3.attention.output.dense.bias', 'bert.encoder.v_layer.3.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.3.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.3.intermediate.dense.weight', 'bert.encoder.v_layer.3.intermediate.dense.bias', 'bert.encoder.v_layer.3.output.dense.weight', 'bert.encoder.v_layer.3.output.dense.bias', 'bert.encoder.v_layer.3.output.LayerNorm.weight', 'bert.encoder.v_layer.3.output.LayerNorm.bias', 'bert.encoder.v_layer.4.attention.self.query.weight', 'bert.encoder.v_layer.4.attention.self.query.bias', 'bert.encoder.v_layer.4.attention.self.key.weight', 'bert.encoder.v_layer.4.attention.self.key.bias', 'bert.encoder.v_layer.4.attention.self.value.weight', 'bert.encoder.v_layer.4.attention.self.value.bias', 'bert.encoder.v_layer.4.attention.output.dense.weight', 'bert.encoder.v_layer.4.attention.output.dense.bias', 'bert.encoder.v_layer.4.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.4.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.4.intermediate.dense.weight', 'bert.encoder.v_layer.4.intermediate.dense.bias', 'bert.encoder.v_layer.4.output.dense.weight', 'bert.encoder.v_layer.4.output.dense.bias', 'bert.encoder.v_layer.4.output.LayerNorm.weight', 'bert.encoder.v_layer.4.output.LayerNorm.bias', 'bert.encoder.v_layer.5.attention.self.query.weight', 'bert.encoder.v_layer.5.attention.self.query.bias', 'bert.encoder.v_layer.5.attention.self.key.weight', 'bert.encoder.v_layer.5.attention.self.key.bias', 'bert.encoder.v_layer.5.attention.self.value.weight', 'bert.encoder.v_layer.5.attention.self.value.bias', 'bert.encoder.v_layer.5.attention.output.dense.weight', 'bert.encoder.v_layer.5.attention.output.dense.bias', 'bert.encoder.v_layer.5.attention.output.LayerNorm.weight', 'bert.encoder.v_layer.5.attention.output.LayerNorm.bias', 'bert.encoder.v_layer.5.intermediate.dense.weight', 'bert.encoder.v_layer.5.intermediate.dense.bias', 'bert.encoder.v_layer.5.output.dense.weight', 'bert.encoder.v_layer.5.output.dense.bias', 'bert.encoder.v_layer.5.output.LayerNorm.weight', 'bert.encoder.v_layer.5.output.LayerNorm.bias', 'bert.encoder.c_layer.0.biattention.query1.weight', 'bert.encoder.c_layer.0.biattention.query1.bias', 'bert.encoder.c_layer.0.biattention.key1.weight', 'bert.encoder.c_layer.0.biattention.key1.bias', 'bert.encoder.c_layer.0.biattention.value1.weight', 'bert.encoder.c_layer.0.biattention.value1.bias', 'bert.encoder.c_layer.0.biattention.query2.weight', 'bert.encoder.c_layer.0.biattention.query2.bias', 'bert.encoder.c_layer.0.biattention.key2.weight', 'bert.encoder.c_layer.0.biattention.key2.bias', 'bert.encoder.c_layer.0.biattention.value2.weight', 'bert.encoder.c_layer.0.biattention.value2.bias', 'bert.encoder.c_layer.0.biOutput.dense1.weight', 'bert.encoder.c_layer.0.biOutput.dense1.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.0.biOutput.q_dense1.weight', 'bert.encoder.c_layer.0.biOutput.q_dense1.bias', 'bert.encoder.c_layer.0.biOutput.dense2.weight', 'bert.encoder.c_layer.0.biOutput.dense2.bias', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.0.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.0.biOutput.q_dense2.weight', 'bert.encoder.c_layer.0.biOutput.q_dense2.bias', 'bert.encoder.c_layer.0.v_intermediate.dense.weight', 'bert.encoder.c_layer.0.v_intermediate.dense.bias', 'bert.encoder.c_layer.0.v_output.dense.weight', 'bert.encoder.c_layer.0.v_output.dense.bias', 'bert.encoder.c_layer.0.v_output.LayerNorm.weight', 'bert.encoder.c_layer.0.v_output.LayerNorm.bias', 'bert.encoder.c_layer.0.t_intermediate.dense.weight', 'bert.encoder.c_layer.0.t_intermediate.dense.bias', 'bert.encoder.c_layer.0.t_output.dense.weight', 'bert.encoder.c_layer.0.t_output.dense.bias', 'bert.encoder.c_layer.0.t_output.LayerNorm.weight', 'bert.encoder.c_layer.0.t_output.LayerNorm.bias', 'bert.encoder.c_layer.1.biattention.query1.weight', 'bert.encoder.c_layer.1.biattention.query1.bias', 'bert.encoder.c_layer.1.biattention.key1.weight', 'bert.encoder.c_layer.1.biattention.key1.bias', 'bert.encoder.c_layer.1.biattention.value1.weight', 'bert.encoder.c_layer.1.biattention.value1.bias', 'bert.encoder.c_layer.1.biattention.query2.weight', 'bert.encoder.c_layer.1.biattention.query2.bias', 'bert.encoder.c_layer.1.biattention.key2.weight', 'bert.encoder.c_layer.1.biattention.key2.bias', 'bert.encoder.c_layer.1.biattention.value2.weight', 'bert.encoder.c_layer.1.biattention.value2.bias', 'bert.encoder.c_layer.1.biOutput.dense1.weight', 'bert.encoder.c_layer.1.biOutput.dense1.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.1.biOutput.q_dense1.weight', 'bert.encoder.c_layer.1.biOutput.q_dense1.bias', 'bert.encoder.c_layer.1.biOutput.dense2.weight', 'bert.encoder.c_layer.1.biOutput.dense2.bias', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.1.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.1.biOutput.q_dense2.weight', 'bert.encoder.c_layer.1.biOutput.q_dense2.bias', 'bert.encoder.c_layer.1.v_intermediate.dense.weight', 'bert.encoder.c_layer.1.v_intermediate.dense.bias', 'bert.encoder.c_layer.1.v_output.dense.weight', 'bert.encoder.c_layer.1.v_output.dense.bias', 'bert.encoder.c_layer.1.v_output.LayerNorm.weight', 'bert.encoder.c_layer.1.v_output.LayerNorm.bias', 'bert.encoder.c_layer.1.t_intermediate.dense.weight', 'bert.encoder.c_layer.1.t_intermediate.dense.bias', 'bert.encoder.c_layer.1.t_output.dense.weight', 'bert.encoder.c_layer.1.t_output.dense.bias', 'bert.encoder.c_layer.1.t_output.LayerNorm.weight', 'bert.encoder.c_layer.1.t_output.LayerNorm.bias', 'bert.encoder.c_layer.2.biattention.query1.weight', 'bert.encoder.c_layer.2.biattention.query1.bias', 'bert.encoder.c_layer.2.biattention.key1.weight', 'bert.encoder.c_layer.2.biattention.key1.bias', 'bert.encoder.c_layer.2.biattention.value1.weight', 'bert.encoder.c_layer.2.biattention.value1.bias', 'bert.encoder.c_layer.2.biattention.query2.weight', 'bert.encoder.c_layer.2.biattention.query2.bias', 'bert.encoder.c_layer.2.biattention.key2.weight', 'bert.encoder.c_layer.2.biattention.key2.bias', 'bert.encoder.c_layer.2.biattention.value2.weight', 'bert.encoder.c_layer.2.biattention.value2.bias', 'bert.encoder.c_layer.2.biOutput.dense1.weight', 'bert.encoder.c_layer.2.biOutput.dense1.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.2.biOutput.q_dense1.weight', 'bert.encoder.c_layer.2.biOutput.q_dense1.bias', 'bert.encoder.c_layer.2.biOutput.dense2.weight', 'bert.encoder.c_layer.2.biOutput.dense2.bias', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.2.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.2.biOutput.q_dense2.weight', 'bert.encoder.c_layer.2.biOutput.q_dense2.bias', 'bert.encoder.c_layer.2.v_intermediate.dense.weight', 'bert.encoder.c_layer.2.v_intermediate.dense.bias', 'bert.encoder.c_layer.2.v_output.dense.weight', 'bert.encoder.c_layer.2.v_output.dense.bias', 'bert.encoder.c_layer.2.v_output.LayerNorm.weight', 'bert.encoder.c_layer.2.v_output.LayerNorm.bias', 'bert.encoder.c_layer.2.t_intermediate.dense.weight', 'bert.encoder.c_layer.2.t_intermediate.dense.bias', 'bert.encoder.c_layer.2.t_output.dense.weight', 'bert.encoder.c_layer.2.t_output.dense.bias', 'bert.encoder.c_layer.2.t_output.LayerNorm.weight', 'bert.encoder.c_layer.2.t_output.LayerNorm.bias', 'bert.encoder.c_layer.3.biattention.query1.weight', 'bert.encoder.c_layer.3.biattention.query1.bias', 'bert.encoder.c_layer.3.biattention.key1.weight', 'bert.encoder.c_layer.3.biattention.key1.bias', 'bert.encoder.c_layer.3.biattention.value1.weight', 'bert.encoder.c_layer.3.biattention.value1.bias', 'bert.encoder.c_layer.3.biattention.query2.weight', 'bert.encoder.c_layer.3.biattention.query2.bias', 'bert.encoder.c_layer.3.biattention.key2.weight', 'bert.encoder.c_layer.3.biattention.key2.bias', 'bert.encoder.c_layer.3.biattention.value2.weight', 'bert.encoder.c_layer.3.biattention.value2.bias', 'bert.encoder.c_layer.3.biOutput.dense1.weight', 'bert.encoder.c_layer.3.biOutput.dense1.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.3.biOutput.q_dense1.weight', 'bert.encoder.c_layer.3.biOutput.q_dense1.bias', 'bert.encoder.c_layer.3.biOutput.dense2.weight', 'bert.encoder.c_layer.3.biOutput.dense2.bias', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.3.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.3.biOutput.q_dense2.weight', 'bert.encoder.c_layer.3.biOutput.q_dense2.bias', 'bert.encoder.c_layer.3.v_intermediate.dense.weight', 'bert.encoder.c_layer.3.v_intermediate.dense.bias', 'bert.encoder.c_layer.3.v_output.dense.weight', 'bert.encoder.c_layer.3.v_output.dense.bias', 'bert.encoder.c_layer.3.v_output.LayerNorm.weight', 'bert.encoder.c_layer.3.v_output.LayerNorm.bias', 'bert.encoder.c_layer.3.t_intermediate.dense.weight', 'bert.encoder.c_layer.3.t_intermediate.dense.bias', 'bert.encoder.c_layer.3.t_output.dense.weight', 'bert.encoder.c_layer.3.t_output.dense.bias', 'bert.encoder.c_layer.3.t_output.LayerNorm.weight', 'bert.encoder.c_layer.3.t_output.LayerNorm.bias', 'bert.encoder.c_layer.4.biattention.query1.weight', 'bert.encoder.c_layer.4.biattention.query1.bias', 'bert.encoder.c_layer.4.biattention.key1.weight', 'bert.encoder.c_layer.4.biattention.key1.bias', 'bert.encoder.c_layer.4.biattention.value1.weight', 'bert.encoder.c_layer.4.biattention.value1.bias', 'bert.encoder.c_layer.4.biattention.query2.weight', 'bert.encoder.c_layer.4.biattention.query2.bias', 'bert.encoder.c_layer.4.biattention.key2.weight', 'bert.encoder.c_layer.4.biattention.key2.bias', 'bert.encoder.c_layer.4.biattention.value2.weight', 'bert.encoder.c_layer.4.biattention.value2.bias', 'bert.encoder.c_layer.4.biOutput.dense1.weight', 'bert.encoder.c_layer.4.biOutput.dense1.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.4.biOutput.q_dense1.weight', 'bert.encoder.c_layer.4.biOutput.q_dense1.bias', 'bert.encoder.c_layer.4.biOutput.dense2.weight', 'bert.encoder.c_layer.4.biOutput.dense2.bias', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.4.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.4.biOutput.q_dense2.weight', 'bert.encoder.c_layer.4.biOutput.q_dense2.bias', 'bert.encoder.c_layer.4.v_intermediate.dense.weight', 'bert.encoder.c_layer.4.v_intermediate.dense.bias', 'bert.encoder.c_layer.4.v_output.dense.weight', 'bert.encoder.c_layer.4.v_output.dense.bias', 'bert.encoder.c_layer.4.v_output.LayerNorm.weight', 'bert.encoder.c_layer.4.v_output.LayerNorm.bias', 'bert.encoder.c_layer.4.t_intermediate.dense.weight', 'bert.encoder.c_layer.4.t_intermediate.dense.bias', 'bert.encoder.c_layer.4.t_output.dense.weight', 'bert.encoder.c_layer.4.t_output.dense.bias', 'bert.encoder.c_layer.4.t_output.LayerNorm.weight', 'bert.encoder.c_layer.4.t_output.LayerNorm.bias', 'bert.encoder.c_layer.5.biattention.query1.weight', 'bert.encoder.c_layer.5.biattention.query1.bias', 'bert.encoder.c_layer.5.biattention.key1.weight', 'bert.encoder.c_layer.5.biattention.key1.bias', 'bert.encoder.c_layer.5.biattention.value1.weight', 'bert.encoder.c_layer.5.biattention.value1.bias', 'bert.encoder.c_layer.5.biattention.query2.weight', 'bert.encoder.c_layer.5.biattention.query2.bias', 'bert.encoder.c_layer.5.biattention.key2.weight', 'bert.encoder.c_layer.5.biattention.key2.bias', 'bert.encoder.c_layer.5.biattention.value2.weight', 'bert.encoder.c_layer.5.biattention.value2.bias', 'bert.encoder.c_layer.5.biOutput.dense1.weight', 'bert.encoder.c_layer.5.biOutput.dense1.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm1.bias', 'bert.encoder.c_layer.5.biOutput.q_dense1.weight', 'bert.encoder.c_layer.5.biOutput.q_dense1.bias', 'bert.encoder.c_layer.5.biOutput.dense2.weight', 'bert.encoder.c_layer.5.biOutput.dense2.bias', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.weight', 'bert.encoder.c_layer.5.biOutput.LayerNorm2.bias', 'bert.encoder.c_layer.5.biOutput.q_dense2.weight', 'bert.encoder.c_layer.5.biOutput.q_dense2.bias', 'bert.encoder.c_layer.5.v_intermediate.dense.weight', 'bert.encoder.c_layer.5.v_intermediate.dense.bias', 'bert.encoder.c_layer.5.v_output.dense.weight', 'bert.encoder.c_layer.5.v_output.dense.bias', 'bert.encoder.c_layer.5.v_output.LayerNorm.weight', 'bert.encoder.c_layer.5.v_output.LayerNorm.bias', 'bert.encoder.c_layer.5.t_intermediate.dense.weight', 'bert.encoder.c_layer.5.t_intermediate.dense.bias', 'bert.encoder.c_layer.5.t_output.dense.weight', 'bert.encoder.c_layer.5.t_output.dense.bias', 'bert.encoder.c_layer.5.t_output.LayerNorm.weight', 'bert.encoder.c_layer.5.t_output.LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m2021-04-30T04:11:26 | mmf.trainers.mmf_trainer: \u001b[0mLoading optimizer\n","\u001b[32m2021-04-30T04:11:26 | mmf.trainers.mmf_trainer: \u001b[0mLoading metrics\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:11:26 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n","Use OmegaConf.to_yaml(cfg)\n","\n","  category=UserWarning,\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:11:26 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/omegaconf/basecontainer.py:232: UserWarning: cfg.pretty() is deprecated and will be removed in a future version.\n","Use OmegaConf.to_yaml(cfg)\n","\n","  category=UserWarning,\n","\n","\u001b[32m2021-04-30T04:11:26 | mmf.utils.checkpoint: \u001b[0mLoading checkpoint\n","[ Downloading: https://dl.fbaipublicfiles.com/mmf/data/models/vilbert/vilbert.finetuned.hateful_memes_from_cc.tar.gz to /root/.cache/torch/mmf/data/models/vilbert.finetuned.hateful_memes.from_cc_original/vilbert.finetuned.hateful_memes_from_cc.tar.gz ]\n","Downloading vilbert.finetuned.hateful_memes_from_cc.tar.gz: 100% 918M/918M [00:56<00:00, 16.3MB/s]\n","[ Starting checksum for vilbert.finetuned.hateful_memes_from_cc.tar.gz]\n","[ Checksum successful for vilbert.finetuned.hateful_memes_from_cc.tar.gz]\n","Unpacking vilbert.finetuned.hateful_memes_from_cc.tar.gz\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:12:40 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:12:40 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:12:40 | mmf: \u001b[0mKey data_parallel is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:12:40 | mmf: \u001b[0mKey distributed is not present in registry, returning default value of None\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:12:41 | mmf.utils.checkpoint: \u001b[0mMissing keys ['model.bert.embeddings.position_ids'] in the checkpoint.\n","If this is not your checkpoint, please open up an issue on MMF GitHub. \n","Unexpected keys if any: []\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:12:41 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/mmf/utils/checkpoint.py:304: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.\n","  \"'optimizer' key is not present in the \"\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:12:41 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/mmf/utils/checkpoint.py:304: UserWarning: 'optimizer' key is not present in the checkpoint asked to be loaded. Skipping.\n","  \"'optimizer' key is not present in the \"\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:12:41 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/mmf/utils/checkpoint.py:347: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.\n","  \"'lr_scheduler' key is not present in the \"\n","\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m2021-04-30T04:12:41 | py.warnings: \u001b[0m/usr/local/lib/python3.7/dist-packages/mmf/utils/checkpoint.py:347: UserWarning: 'lr_scheduler' key is not present in the checkpoint asked to be loaded. Setting lr_scheduler's last_epoch to current_iteration.\n","  \"'lr_scheduler' key is not present in the \"\n","\n","\u001b[32m2021-04-30T04:12:41 | mmf.utils.checkpoint: \u001b[0mCheckpoint loaded.\n","\u001b[32m2021-04-30T04:12:41 | mmf.utils.checkpoint: \u001b[0mCurrent num updates: 0\n","\u001b[32m2021-04-30T04:12:41 | mmf.utils.checkpoint: \u001b[0mCurrent iteration: 0\n","\u001b[32m2021-04-30T04:12:41 | mmf.utils.checkpoint: \u001b[0mCurrent epoch: 0\n","\u001b[32m2021-04-30T04:12:42 | mmf.trainers.core.evaluation_loop: \u001b[0mStarting test inference predictions\n","\u001b[32m2021-04-30T04:12:42 | mmf.common.test_reporter: \u001b[0mPredicting for hateful_memes\n","100% 32/32 [15:11<00:00, 28.47s/it]\n","\u001b[32m2021-04-30T04:27:53 | mmf.common.test_reporter: \u001b[0mWrote predictions for hateful_memes to /content/save/hateful_memes_vilbert_11446352/reports/hateful_memes_run_test_2021-04-30T04:27:53.csv\n","\u001b[32m2021-04-30T04:27:53 | mmf.trainers.core.evaluation_loop: \u001b[0mFinished predicting. Loaded 32\n","\u001b[32m2021-04-30T04:27:53 | mmf.trainers.core.evaluation_loop: \u001b[0m -- skipped 0 batches.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oD01s5iS6ZxH"},"source":["!ls /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ | wc -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vfPq1Dvv_FPy"},"source":["VisualBERT"]},{"cell_type":"code","metadata":{"id":"-Fh_tWsd7jAJ"},"source":["!mmf_predict config=projects/hateful_memes/configs/visual_bert/direct.yaml \\\n","model=visual_bert \\\n","dataset=hateful_memes \\\n","run_type=val \\\n","checkpoint.resume_zoo=visual_bert.finetuned.hateful_memes.direct \\\n","checkpoint.resume_pretrained=False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UFNFKKgy_LV9"},"source":["VilBERT"]},{"cell_type":"code","metadata":{"id":"453uMg2u-yGt"},"source":["!mmf_predict config=projects/hateful_memes/configs/vilbert/defaults.yaml \\\n","model=vilbert \\\n","dataset=hateful_memes \\\n","run_type=val \\\n","checkpoint.resume_zoo=vilbert.finetuned.hateful_memes.direct \\\n","checkpoint.resume_pretrained=False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n2br49gpGAMV"},"source":["MMBT-Region"]},{"cell_type":"code","metadata":{"id":"9thQxRGZGGR5"},"source":["!mmf_predict config=projects/hateful_memes/configs/mmbt/with_features.yaml \\\n","model=mmbt \\\n","dataset=hateful_memes \\\n","run_type=val \\\n","checkpoint.resume_zoo=mmbt.hateful_memes.features \\\n","checkpoint.resume_pretrained=False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Znvm3v_xJpOd"},"source":["MMBT-Grid"]},{"cell_type":"code","metadata":{"id":"Sj0PZoz1JxZg"},"source":["!mmf_predict config=projects/hateful_memes/configs/mmbt/defaults.yaml \\\n","model=mmbt \\\n","dataset=hateful_memes \\\n","run_type=val \\\n","checkpoint.resume_zoo=mmbt.hateful_memes.images \\\n","checkpoint.resume_pretrained=False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zXtIaR9fMue7"},"source":["ConcatBERT"]},{"cell_type":"code","metadata":{"id":"mjB1dBSFM0cw"},"source":["!mmf_predict config=projects/hateful_memes/configs/concat_bert/defaults.yaml \\\n","model=concat_bert \\\n","dataset=hateful_memes \\\n","run_type=val \\\n","checkpoint.resume_zoo=concat_bert.hateful_memes \\\n","checkpoint.resume_pretrained=False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2RDL5s4MNFCe"},"source":["Late Fusion"]},{"cell_type":"code","metadata":{"id":"HgflUsixNJuU"},"source":["!mmf_predict config=projects/hateful_memes/configs/concat_bert/defaults.yaml \\\n","model=late_fusion \\\n","dataset=hateful_memes \\\n","run_type=val \\\n","checkpoint.resume_zoo=concat_bert.hateful_memes \\\n","checkpoint.resume_pretrained=False"],"execution_count":null,"outputs":[]}]}